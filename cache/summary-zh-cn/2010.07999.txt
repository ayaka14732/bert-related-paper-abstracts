给出一段有对齐对话的视频，人们通常可以推断下一步更可能发生什么。做出这样的预测不仅需要深入理解视频和对话背后的丰富动态，还需要大量的常识知识。在这项工作中，我们探索人工智能模型是否能够学习做出这样的多模态常识下一个事件预测。为了支持这方面的研究，我们收集了一个名为视频和语言事件预测（VLEP）的新数据集，其中包含来自10234个不同电视节目和YouTube生活方式Vlog视频剪辑的28726个未来事件预测示例（及其理据）。为了促进非平凡挑战性示例的收集，我们采用了对抗性的人与模型在环数据收集过程。我们还提供了一个强大的基线，包括来自视频、对话和常识的信息。实验表明，每种类型的信息对于这项具有挑战性的任务都是有用的，并且与VLEP上的高人类性能相比，我们的模型提供了一个良好的起点，但为未来的工作留下了很大的空间。我们的数据集和代码位于：https://github.com/jayleicn/VideoLanguageFuturePred