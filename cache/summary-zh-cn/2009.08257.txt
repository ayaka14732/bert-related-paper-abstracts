许多自然语言处理任务都受益于从语境化单词嵌入中转移知识，但是关于转移的知识类型的描述是不完整的。本文研究了在会话问答（CoQA）任务中，由语言模型描述的语言现象的类型。我们通过系统错误分析——基本算法（计算短语）、合成语义（否定和语义角色标记）和词汇语义（惊奇和反义词），确定了微调后的RoBERTa、BERT和DistilBERT模型存在的问题。当通过多任务学习使用相关的语言知识进行增强时，模型的性能会提高。增强型车型的组合在F1总成绩上提高了2.2到2.7分，在最难的问题类上提高了42.1分。结果表明，罗伯塔、伯特和迪斯蒂尔伯特在表达作文和词汇信息的能力上存在差异。