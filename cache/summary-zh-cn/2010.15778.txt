伯特是一个流行的语言模型，其主要的预训练任务是填空，即根据剩余的单词预测出一个被掩蔽的单词。然而，在某些应用程序中，具有额外的上下文可以帮助模型做出正确的预测，例如，通过考虑域或编写时间。这促使我们通过在固定大小的上下文中添加一个全局状态来改进BERT体系结构。我们提出了两种新颖的方法，并将其应用到一个行业用例中，在该用例中，我们根据特定的客户完成了带有缺失物品的时装套装。与文献中其他方法的实验比较表明，我们的方法显著提高了个性化。