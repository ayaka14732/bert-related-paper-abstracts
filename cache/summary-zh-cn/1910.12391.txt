多项选择阅读理解（MCRC）要求模型阅读文章和问题，并在给定选项中选择正确答案。最近最先进的模型在多个MCRC数据集上取得了令人印象深刻的性能。然而，这种性能可能并不反映模型的真正语言理解和推理能力。在这项工作中，我们采用两种方法来研究BERT从MCRC数据集中学到的东西：1）一种不可读的数据攻击，在这种攻击中，我们添加关键字来混淆BERT，导致显著的性能下降；2）一种不负责任的数据训练，在这种训练中，我们对部分或混合输入进行训练。在不负责任的数据训练下，BERT取得了出人意料的高性能。基于我们对5个关键MCRC数据集（RACE、MCTest、MCScript、MCScript2.0、DREAM）的实验，我们观察到1）微调的BERT主要学习关键词如何导致正确预测，而不是学习语义理解和推理；（2）伯特不需要正确的句法信息来完成任务；3） 这些数据集中存在工件，因此即使没有完整的上下文，也可以解决这些工件。