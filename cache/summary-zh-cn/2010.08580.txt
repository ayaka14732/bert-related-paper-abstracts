尽管大规模的预训练语言模型，如BERT和RoBERTa，在分布内测试集上取得了超人的性能，但在分布外测试集（如对比集）上，它们的性能受到影响。构建对比集通常需要人工专家注释，这既昂贵又难以大规模创建。在这项工作中，我们提出了一种语言信息转换（LIT）方法来自动生成对比集，这使从业者能够探索感兴趣的语言现象以及合成不同的现象。在SNLI和MNLI上用我们的方法进行的实验表明，当前的预训练语言模型尽管被认为包含了足够的语言知识，但在我们自动生成的对比集上仍存在困难。此外，我们在不影响原始数据性能的情况下，通过应用ing LIT增加训练数据，提高了模型在对比度集上的性能。