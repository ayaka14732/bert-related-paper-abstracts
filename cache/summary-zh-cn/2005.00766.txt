Khandelwal等人（2020年）使用k-最近邻（kNN）组件来提高语言模型性能。我们证明了这种思想对开放域问答（QA）是有益的。为了提高对培训过程中遇到的事实的回忆，我们将BERT（Devlin等人，2019）与传统的信息检索步骤（IR）和嵌入文本集合的大型数据库上的kNN搜索相结合。我们的贡献如下：i）BERT kNN在完形填空式QA方面的表现大大优于BERT，无需进一步培训。ii）我们表明，伯特经常识别正确的回答类别（例如，美国城市），但只有kNN恢复了事实上正确的答案（例如，“迈阿密”）。iii）与BERT相比，BERT kNN在稀有事实方面表现出色。iv）BERT kNN可以轻松处理BERT培训集未涵盖的事实，例如最近发生的事件。