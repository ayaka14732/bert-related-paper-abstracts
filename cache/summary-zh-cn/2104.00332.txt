视觉和语言预培训在学习视觉和语言之间的多模态表示方面取得了令人印象深刻的成功。为了将这一成功推广到非英语语言，我们引入了UC2，这是第一个用于跨语言跨模态表示学习的机器翻译增强框架。为了解决图像数据集多语言标题的稀缺性问题，我们首先通过机器翻译（MT）用其他语言扩充现有的纯英语数据集。然后，我们将标准的蒙面语言建模和图像-文本匹配训练目标扩展到多语言设置，其中通过共享的视觉上下文（即使用图像作为轴心）捕获不同语言之间的对齐。为了便于学习图像和所有感兴趣的语言的联合嵌入空间，我们进一步提出了两个新的训练前任务，即掩蔽区域到标记建模（MRTM）和视觉翻译语言建模（VTLM），利用机器翻译增强的翻译数据。对多语言图像文本检索和多语言视觉问答基准的评估表明，我们提出的框架在不同的非英语基准上实现了最新水平，同时在英语任务上保持了与单语预先训练模型相当的性能。