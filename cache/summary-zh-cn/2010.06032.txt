预先训练的模型已经彻底改变了自然语言理解。然而，研究人员发现，他们可以对许多应用程序中不需要的工件进行编码，例如与一种性别相关的职业多于与另一种性别相关的职业。我们探讨了这种性别相关性，作为如何在预先训练的模型中解决意外相关性的案例研究。我们定义了度量，并揭示了具有相似精度的模型可以以非常不同的速率编码相关性。我们展示了如何使用通用技术降低测量相关性，并强调了不同策略的权衡。根据这些结果，我们提出了训练稳健模型的建议：（1）仔细评估意外相关性，（2）注意看似无害的配置差异，（3）关注一般缓解措施。