我们首次证明，仅从语音音频中学习强大的表示，然后对转录语音进行微调，可以在概念上更简单的同时，胜过最佳的半监督方法。wav2vec 2.0屏蔽潜在空间中的语音输入，并解决在联合学习的潜在表征量化上定义的对比任务。使用Librispeech所有标记数据的实验在干净/其他测试集上达到1.8/3.3 WER。当将标记数据量降低到1小时时，wav2vec 2.0在100小时子集上的性能优于以前的技术状态，同时使用的标记数据减少了100倍。仅使用10分钟的标记数据和对53k小时的未标记数据进行预训练，仍然可以达到4.8/8.2 WER。这证明了使用有限数量的标记数据进行语音识别的可行性。