本文研究了BERT在排序任务中的性能和行为。我们探索了几种不同的方法来利用预先训练好的BERT，并在两个排名任务上对其进行微调：MARCO女士文章重新排名和TREC Web Track即席文档排名。在MS MARCO上的实验结果证明了BERT在以问答为中心的段落排序任务中的强大有效性，以及BERT是一个基于强交互的seq2seq匹配模型的事实。在TREC上的实验结果表明，预先训练好的基于周围环境的BERT与adhoc文档排序的需求之间存在差距。分析说明了BERT如何在其转换器层中的查询文档标记之间分配注意力，它如何偏好解释标记之间的语义匹配，以及这与通过点击训练的神经ranker学习的软匹配模式有何不同。