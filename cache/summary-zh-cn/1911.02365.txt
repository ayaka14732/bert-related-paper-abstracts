自动生成问题的目的是从上下文中生成问题，相应的答案是给定文章的子跨度。然而，大多数方法大多依赖启发式规则生成问题，最近也提出了神经网络方法。在这项工作中，我们提出了一种变体的自我注意变压器网络架构模型，以产生有意义的和多样化的问题。为此，我们提出了一个易于使用的模型，该模型由转换器-解码器GPT-2模型和转换器-编码器BERT组成，用于下游任务的问答。该模型以端到端的方式进行训练，其中语言模型被训练为产生问题-答案感知的输入表示，这有助于生成以答案为中心的问题。我们在班1.1数据集上从文本生成神经问题的结果表明，我们的方法可以生成语义正确且多样的问题。此外，我们还评估了我们提出的方法在下游问题回答任务中的性能。分析表明，我们提出的生成与应答协作框架相对地改进了这两个任务，并且在半监督环境下尤其强大。研究结果进一步表明，在小数据环境下，一条稳健且相对精简的管道有助于问题的生成。