尽管最近对神经排序结构给予了相当大的关注，但对作为这些模型输入的术语表示的关注却少得多。在这项工作中，我们研究了如何利用两个预先训练的上下文化语言模型（ELMo和BERT）进行临时文档排序。通过在TREC基准测试上的实验，我们发现一些现有的神经排序结构可以受益于上下文化语言模型提供的附加上下文。此外，我们提出了一种联合方法，将BERT的分类向量纳入现有的神经模型中，并表明它优于最先进的ad-hoc排序基线。我们称这种联合方法为CEDR（文档排名的上下文嵌入）。我们还解决了使用这些模型进行排名的实际挑战，包括由BERT施加的最大输入长度以及上下文化语言模型对运行时性能的影响。