训练语法错误纠正模型（GEC）需要一组标记的非语法/语法句子对，但手动注释这类句子对可能代价高昂。最近，Break-It-Fix-It（BIFI）框架在学习在没有任何标记示例的情况下修复损坏的程序方面显示出了强大的效果，但这依赖于一个完美的批评家（例如编译器），它返回一个示例是否有效，而GEC任务中不存在该示例。在这项工作中，我们展示了如何利用预训练语言模型（LM）来定义LM批评家，如果LM赋予句子比其局部扰动更高的概率，则该模型会判断句子是否符合语法。我们应用LM批评家和BIFI以及大量未标记的句子来引导现实的非语法/语法对，以训练纠正者。我们在多个领域（CoNLL-2014、BEA-2019、GMEG wiki和GMEG yahoo）的GEC数据集上评估了我们的方法，并表明它在无监督设置（+7.7 F0.5）和监督设置（+0.5 F0.5）方面都优于现有方法。