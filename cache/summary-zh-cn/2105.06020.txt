较大的语言模型平均具有较高的准确性，但它们是否在每个实例（数据点）上都更好？一些研究表明，较大的模型具有更高的分布外稳健性，而其他研究表明，它们对稀有子群的准确性较低。为了理解这些差异，我们在单个实例的层次上研究这些模型。然而，一个主要的挑战是个体预测对训练随机性中的噪声高度敏感。我们开发了统计上严格的方法来解决这一问题，在考虑了预训练和微调噪声后，我们发现，与总体精度提高2-10%相比，MNLI、SST-2和QQP中至少有1-4%的情况下，我们的BERT-Large比BERT-Mini差。我们还发现，微调噪声随着模型大小的增加而增加，并且实例级精度具有动量：从BERT Mini到BERT Middle的改进与从BERT Middle到BERT Large的改进相关。我们的发现表明，实例级预测提供了丰富的信息来源；因此，我们建议研究人员用模型预测补充模型权重。