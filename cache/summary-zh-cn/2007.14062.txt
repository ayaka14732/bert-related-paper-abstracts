基于变压器的模型，如BERT，已经成为NLP最成功的深度学习模型之一。不幸的是，他们的一个核心限制是，由于他们的完全注意机制，他们对序列长度的二次依赖性（主要是在记忆方面）。为了解决这个问题，我们提出了BigBird，一种稀疏注意机制，将这种二次依赖性降低为线性。我们证明了BigBird是序列函数的通用逼近器，并且是图灵完备的，从而保持了二次全注意模型的这些性质。一路上，我们的理论分析揭示了拥有$O（1）$全局令牌（如CLS）的一些好处，这些令牌作为稀疏注意机制的一部分关注整个序列。建议的稀疏注意可以处理长度为以前使用类似硬件可能处理长度的8倍的序列。由于能够处理更长的上下文，BigBird极大地提高了各种NLP任务（如问答和摘要）的性能。我们还提出了基因组数据的新应用。