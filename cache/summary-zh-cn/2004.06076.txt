阅读理解模型往往过于适应训练数据集的细微差别，在对抗性评估中失败。使用对抗性增强数据集进行训练可以提高对抗性攻击的鲁棒性，但会影响模型的泛化。在这项工作中，我们提出了几种有效的敌手和自动数据扩充策略搜索方法，目的是使阅读理解模型对敌手评估更具鲁棒性，同时提高对源领域以及新领域和语言的泛化能力。我们首先提出了三种新的产生QA对手的方法，它们在上下文中引入了多个混淆点，显示了对干扰词插入位置的依赖，并揭示了将对抗策略与句法和语义解释方法相结合的复合效应。接下来，我们发现，使用统一采样的对手来扩充训练数据集可以提高对抗性攻击的鲁棒性，但会导致原始未经整理数据集的性能下降。我们通过RL和更有效的贝叶斯策略搜索方法来解决这个问题，以便在大的搜索空间中自动学习每个对手转换概率的最佳增强策略组合。利用这些学习到的策略，我们证明了对抗性训练可以显著提高领域内、领域外和跨语言（德语、俄语、土耳其语）的泛化能力。