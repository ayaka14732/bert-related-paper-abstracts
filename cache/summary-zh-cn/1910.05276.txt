大型语言模型可以生成强大的上下文表示，从而改进许多NLP任务。由于这些模型通常由一系列学习到的自我注意机制引导，并且可能包含不希望出现的诱导偏差，因此能够探索注意学到了什么至关重要。虽然对这些模型的静态分析会带来有针对性的见解，但交互式工具更具动态性，可以帮助人们更好地获得模型内部推理过程的直觉。我们介绍了exBERT，一种以流行的BERT语言模型命名的交互式工具，它通过将人类指定的输入与大型注释数据集中的类似上下文进行匹配，从而深入了解上下文表示的含义。通过聚合匹配相似上下文的注释，exBERT可以直观地解释每个注意头都学到了什么。