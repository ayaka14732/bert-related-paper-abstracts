基于转换器的语言模型目前广泛应用于自然语言处理（NLP）。对于英语来说，这一说法尤其正确，近年来，许多使用基于变压器的体系结构的预训练模型已经发布。这推动了各种标准NLP任务（如分类、回归和序列标记）以及文本到文本任务（如机器翻译、问答或摘要）的发展。然而，对于资源不足的语言，如波兰语，情况就不同了。尽管有一些基于transformer的波兰语语言模型可用，但就语料库规模和参数数量而言，没有一个能达到最大英语语言模型的规模。在这项研究中，我们提出了两种基于流行的伯特体系结构的波兰语语言模型。更大的模型是在一个由超过10亿个波兰句子或135GB原始文本组成的数据集上训练的。我们描述了收集数据、准备语料库和预训练模型的方法。然后，我们对13项波兰语言任务评估了我们的模型，并在其中11项任务中展示了与之前方法相比的改进。