虽然最近有很多工作研究语言信息如何编码在预先训练的句子表示中，但对于这些模型在适应于解决下游任务时如何变化的了解相对较少。使用一套分析技术（探测分类器、表征相似性分析和模型烧蚀），我们研究微调如何影响伯特模型的表征。我们发现，虽然微调必然会产生重大变化，但它不会导致语言现象的灾难性遗忘。相反，我们发现微调主要影响BERT的顶层，但在不同的任务中有显著的变化。特别是，依赖解析重新配置了大部分模型，而SQuAD和MNLI似乎涉及更浅的处理。最后，我们还发现，微调对域外句子的表示有较弱的影响，这表明模型泛化还有改进的余地。