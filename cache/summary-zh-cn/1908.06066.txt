我们提出Unicoder VL，这是一种通用编码器，旨在通过预先培训的方式学习视觉和语言的联合表示。借鉴XLM和Unicoder等跨语言预训练模型的思想，将视觉和语言内容输入到跨模式预训练的多层转换器中，其中使用了三个预训练任务，包括蒙面语言建模（MLM）、蒙面对象分类（MOC）和视觉语言匹配（VLM）。前两个任务学习基于语言和视觉内容的输入标记上下文感知表示。最后一项任务试图预测图像和文本是否相互描述。在对大规模图像字幕对进行预训练后，我们将Unicoder VL转换为基于字幕的图像文本检索和视觉常识推理，只需增加一个输出层。我们在这两项任务上都取得了最先进的或可比的结果，并展示了跨模态预训练的强大能力。