三重抽取是自然语言处理和知识图构造中信息抽取的一项重要任务。在本文中，我们回顾了用于序列生成的端到端三重提取任务。由于生成式三重抽取可能难以捕获长期依赖关系并生成不可靠的三重抽取，因此我们引入了一种新模型，即使用生成转换器的对比三重抽取。具体来说，我们介绍了一个用于基于编码器-解码器的生成的单一共享转换器模块。为了得到真实的结果，我们提出了一种新的三重对比训练对象。此外，我们还引入了两种机制来进一步提高模型性能（即批处理动态注意掩蔽和三重校准）。在三个数据集（即NYT、WebNLG和MIE）上的实验结果表明，我们的方法比基线方法获得了更好的性能。