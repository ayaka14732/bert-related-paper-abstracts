我们介绍了fastHan，一个开源工具包，用于中文自然语言处理的四个基本任务：中文分词（CWS）、词性（POS）标记、命名实体识别（NER）和依赖项解析。fastHan的主干是一个基于删减的BERT的多任务模型，它使用BERT中的前8层。我们还提供了从8层模型压缩而来的4层基础模型。该联合模型在四个任务的13个语料库上进行了训练和评估，在依赖项解析和NER方面获得了接近最新水平的（SOTA）性能，在CWS和POS方面实现了SOTA性能。此外，fastHan的可转移性也很强，在非训练语料库上的性能远远好于流行的切分工具。为了更好地满足实际应用的需要，我们允许用户使用自己的标记数据进一步微调fastHan。除了体积小、性能优异外，fastHan还具有良好的用户友好性。fastHan作为一个python包实现，将用户与内部技术细节隔离开来，使用起来很方便。该项目在Github上发布。