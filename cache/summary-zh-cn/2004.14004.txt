机器阅读理解（MRC）是评价模型自然语言理解（NLU）能力的重要测试平台。这一领域进展迅速，新车型在各种基准上取得了令人印象深刻的性能。然而，现有的基准只评估域内测试集上的模型，而没有考虑它们在测试时间扰动或对抗性攻击下的鲁棒性。为了填补这一重要空白，我们构建了一个新的模型不可知基准AdvRACE（对抗性种族），用于评估MRC模型在四种不同类型的对抗性攻击下的鲁棒性，包括我们的新型干扰物提取和生成攻击。我们表明，最先进的（SOTA）模型容易受到所有这些攻击。我们的结论是，构建更稳健的MRC模型有很大的空间，我们的基准可以帮助激励和衡量这一领域的进展。我们在以下位置发布数据和代码：https://github.com/NoviScl/AdvRACE .