大型预训练语言模型（LMs），如GPT-3，已经获得了执行零射击学习的惊人能力。例如，为了在没有任何训练示例的情况下对情绪进行分类，我们可以用评论和标签描述“用户喜欢这部电影吗？”来“提示”LM，并询问下一个单词是“是”还是“否”。然而，下一个单词预测训练目标仍然与目标零射击学习目标不一致。为了解决这个弱点，我们提出了元调优，它通过在一组数据集上微调预先训练的语言模型，直接优化零炮学习目标。我们专注于分类任务，并通过聚合43个现有数据集和以问答（QA）格式注释441个标签描述来构建元数据集。当对看不见的任务进行评估时，元调优模型的性能优于相同大小的QA模型和先前基于自然语言推理的SOTA零镜头学习系统。此外，将参数计数从220M增加到770M，AUC-ROC得分提高了6.3%，我们预测，更大的模型将表现更好。因此，在开箱即用的语言模型上衡量零射击学习成绩可能低估了它们的真正潜力，而社区范围内聚合数据集并统一其格式的努力可以帮助构建更好地回答提示的模型。