我们提出了一个新的视觉语言（VL）预训练模型，称为Kaleido-BERT，该模型引入了一种新的Kaleido策略，用于从变形金刚中进行时装跨模态表示。与最近VL模型的随机掩蔽策略不同，我们设计了对齐引导掩蔽，以共同关注图像-文本语义关系。为此，我们进行了五项新任务，即旋转、拼图、伪装、灰色到颜色和空白到颜色，以在不同规模的补丁上进行自我监督VL预训练。Kaleido-BERT在概念上简单，易于扩展到现有的BERT框架，它在四个下游任务（包括文本检索）上大幅度获得了最新的结果(R@1：4.03%绝对改善），图像检索(R@1：7.13%abs imv.）、类别识别（ACC:3.28%abs imv.）和时尚字幕（Bleu4:1.2 abs imv。）。我们在广泛的电子商务网站上验证了Kaleido BERT的效率，展示了其在现实世界应用中更广泛的潜力。