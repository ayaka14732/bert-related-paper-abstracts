在大量文本上训练的大型神经语言模型已经成为自然语言理解任务的一种强大策略。然而，这些模型作为自然语言生成器的优势还不太清楚。尽管轶事证据表明，这些模型生成的文本质量更好，但尚未对其生成能力进行详细研究。在这项工作中，我们比较了广泛预训练模型OpenAI GPT2-117（Radford et al.，2019）和最先进的神经故事生成模型（Fan et al.，2018）的性能。通过在各种自动度量中评估生成的文本，我们描述了预训练模型是否能够成为更好的故事讲述者的方式。我们发现，尽管GPT2-117的语境条件更强，对事件的顺序更敏感，并且使用了更多不寻常的词，但在使用最大似然解码算法时，它同样可能产生重复的和不完全不同的文本。