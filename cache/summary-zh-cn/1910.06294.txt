低资源命名实体识别任务的培训模型已被证明是一项挑战，特别是在工业应用中，部署更新模型是一项持续的工作，对业务运营至关重要。在这种情况下，通常会有大量未标记的数据，而标记的数据很少或不可用。经过训练从文本中提取上下文特征的预先训练的语言模型显示，通过利用迁移学习，可以改善许多自然语言处理（NLP）任务，包括几乎没有标记的任务。然而，这样的模型带来了沉重的内存和计算负担，因此训练和部署这样的模型用于推理是一个挑战。在这项正在进行的工作中，我们将预先训练的蒙面语言模型提供的迁移学习的有效性与半监督方法相结合，使用标记和未标记的示例来训练快速而紧凑的模型。初步评估表明，与最先进的预先训练的语言模型相比，紧凑型模型能够以36倍的压缩率实现具有竞争力的准确性，并且推理速度显著加快，允许在生产环境或边缘设备上部署此类模型。