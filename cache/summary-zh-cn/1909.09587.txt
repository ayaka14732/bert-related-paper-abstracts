由于收集每种语言的训练数据是不可行的，因此跨语言迁移学习越来越受到人们的关注。本文采用多语种语料库预训练的语言表征模型，系统地探讨了阅读理解任务中的零镜头跨语言迁移学习。实验结果表明，使用预先训练好的语言表示法，零镜头学习是可行的，并且不需要将源数据翻译成目标语言，甚至会降低性能。我们进一步探讨了模型在零镜头设置下学习到了什么。