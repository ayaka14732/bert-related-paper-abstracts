泛化和鲁棒性都是设计机器学习方法的关键要求。对抗性训练可以增强健壮性，但过去的工作经常发现它会损害泛化能力。在自然语言处理（NLP）中，预训练大型神经语言模型（如BERT）在各种任务的泛化方面取得了令人印象深刻的成果，并从对抗性微调中得到了进一步改进。然而，这些模型仍然容易受到敌对攻击。在本文中，我们证明了对抗性预训练可以提高泛化能力和鲁棒性。我们提出了一种通用算法ALUM（大型神经语言模型的对抗训练），该算法通过在嵌入空间中应用最大对抗损失的扰动来调整训练目标。我们首次对所有阶段的对抗性训练进行了全面研究，包括从头开始的预备训练、在训练有素的模型上持续预备训练以及特定任务的微调。ALUM在常规和对抗场景中的NLP任务中都比BERT获得了巨大的收益。即使对于已经在非常大的文本语料库上接受过良好训练的模型，如RoBERTa，ALUM仍然可以从持续的预训练中获得显著的收益，而传统的非对抗性方法则不能。明矾可以进一步与特定任务的微调相结合，以获得额外的收益。明矾代码公开于https://github.com/namisan/mt-dnn.