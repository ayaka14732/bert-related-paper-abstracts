近年来，神经机器翻译（NMT）得到了迅速发展，其核心在于编码器解码器结构。受有限场景下大规模预训练语言模型在机器翻译方面的最新进展的启发，我们首先证明了单语言模型（LM4MT）可以在标准机器翻译基准上实现与强编码器-解码器NMT模型相当的性能，使用相同的训练数据和相似数量的模型参数。LM4MT还可以轻松地利用源端文本作为额外的监督。LM4MT采用相同的机制对源语和目标语文本进行建模，可以为源语和目标语句子提供统一的表示，从而更好地跨语言传递知识。对基于枢轴和零镜头翻译任务的大量实验表明，LM4MT的性能大大优于编码器-解码器NMT模型。