现有的知识库问答（KBQA）研究主要采用标准的i.i.d假设，即问题的训练分布与测试分布相同。然而，i.i.d在大规模KBs上可能既不合理也不可取，因为1）真实的用户分布很难捕获，2）从巨大空间中随机抽样的训练示例数据效率很低。相反，我们建议KBQA模型应该具有三个级别的内置泛化：i.i.d、合成和零炮。为了促进具有更强泛化能力的KBQA模型的开发，我们构建并发布了一个包含64331个问题的大规模高质量数据集GrailQA，并为所有三个泛化级别提供评估设置。此外，我们还提出了一种新的基于BERT的KBQA模型。我们的数据集和模型的结合使我们能够第一次彻底地检查和演示像BERT这样的预先训练的上下文嵌入在KBQA泛化中的关键作用。