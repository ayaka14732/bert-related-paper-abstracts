本文提出了一种XLSR方法，该方法通过从多种语言的原始语音波形中预训练单个模型来学习跨语言语音表征。我们建立在wav2vec 2.0的基础上，通过解决掩盖潜在语音表征的对比任务来训练wav2vec 2.0，并共同学习跨语言共享的潜在语音量化。实验表明，跨语言预训练显著优于单语预训练。在CommonVoice基准测试中，XLSR显示，与最著名的结果相比，相对音素错误率降低了72%。在BABEL上，我们的方法比同类系统提高了16%的字错误率。我们的方法实现了一个单一的多语言语音识别模型，它可以与强大的单个模型竞争。分析表明，潜在的离散语音表示是跨语言共享的，而相关语言的共享则有所增加。我们希望通过发布XLSR-53，这是一个用53种语言预训练的大型模型，来促进低资源语音理解的研究。