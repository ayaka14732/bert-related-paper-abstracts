我们证明，隐藏在一层随机加权神经网络中的子网络可以在机器翻译任务中实现令人印象深刻的性能，而无需修改权重初始化。为了寻找单层随机加权神经网络的子网络，我们对同一权重矩阵应用不同的二元掩码来生成不同的层。隐藏在一层随机加权变压器中，我们发现在IWSLT14/WMT14上可以实现29.45/17.29 BLEU的子网络。使用固定的预训练嵌入层，先前发现的子网络比经过训练的基于IWSLT14/WMT14的小型变压器的性能小，但可以达到98%/92%（34.14/25.24 BLEU）。此外，我们还演示了在此设置中更大和更深变压器的有效性，以及不同初始化方法的影响。我们在上发布了源代码https://github.com/sIncerass/one_layer_lottery_ticket.