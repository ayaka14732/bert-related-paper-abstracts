基于变压器的模型无法处理长序列，因为它们的自我注意操作随序列长度二次缩放。为了解决这一限制，我们引入了Longformer，它具有一种注意机制，该机制随序列长度线性扩展，使得处理数千个或更长令牌的文档变得容易。朗弗雷特的注意机制是标准自我注意的一个替代品，它将局部窗口注意与任务驱动的全局注意相结合。在之前关于长序列转换器的工作之后，我们在字符级语言建模上评估了Longformer，并在text8和enwik8上实现了最先进的结果。与大多数以前的工作相比，我们还对Longformer进行了预训练，并在各种下游任务上对其进行了微调。我们经过培训的Longformer在长文档任务方面始终优于RoBERTa，并在WikiHop和TriviaQA上取得了最新的成果。最后，我们介绍了Longformer编码器-解码器（LED），它是一种支持长文档生成序列到序列任务的Longformer变体，并在arXiv摘要数据集上演示了它的有效性。