对电子健康记录（EHR）中的临床记录进行预培训的大型变压器在预测性临床任务方面的性能有了显著提高。培训此类模型的成本（以及数据访问的必要性）加上它们的实用性，促使参数共享，即发布预培训模型，如。虽然大多数研究都使用了未识别的EHR，但许多研究人员可以获得大量敏感的、未识别的EHR，他们可以使用这些EHR来训练BERT模型（或类似模型）。如果他们这样做，释放这样一个模型的重量是否安全？在这项工作中，我们设计了一组方法，旨在从经过训练的BERT恢复个人健康信息（PHI）。具体来说，我们尝试恢复患者姓名以及与之相关的条件。我们发现，简单的探测方法不能有意义地提取敏感信息从BERT训练超过模仿III语料库的EHR。然而，更复杂的“攻击”可能会成功：为了促进此类研究，我们在https://github.com/elehman16/exposing_patient_data_release