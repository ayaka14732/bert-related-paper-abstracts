现有的预先训练过的大型语言模型已经显示出无与伦比的生成能力。然而，它们是不可控的。在本文中，我们提出了MEGATRON-CNTRL，这是一种新的框架，它使用大规模语言模型，并通过合并外部知识库为文本生成添加控制。我们的框架由关键字预测器、知识检索器、上下文知识检索器和条件文本生成器组成。由于我们无法对知识等级者进行基本真理监督，我们利用了句子嵌入的弱监督。实证结果表明，与之前在ROC故事数据集上的工作相比，我们的模型生成了更流畅、一致和连贯的故事，重复更少，多样性更高。我们通过替换用于生成故事的关键字并重新运行生成过程来展示模型的可控性。人类评估结果显示，77.5%的故事成功地被新关键词控制。此外，通过将我们的模型从1.24亿个参数扩展到83亿个参数，我们证明了较大的模型可以改善发电质量（一致性从74.5%提高到93.0%）和可控性（从77.5%提高到91.5%）。