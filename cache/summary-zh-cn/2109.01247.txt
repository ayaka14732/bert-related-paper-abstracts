最近，大量的论文表明，在使用各种基于提示的模型进行少数镜头学习方面取得了非凡的进展。这样的成功给人的印象是，提示可以帮助模型更快地学习，就像人类在使用自然语言表达的任务指令时学习更快一样。在这项研究中，我们实验了30多个为自然语言推理（NLI）手工编写的提示。我们发现，模型学习的速度与许多有意无关甚至病态误导的提示一样快，就像它们学习有指导意义的“好”提示一样。此外，我们发现模型性能更依赖于LM目标词的选择（即将LM词汇预测转换为类标签的“言语化器”），而不是提示本身的文本。总之，我们发现几乎没有证据表明现有的基于提示的模型真正理解其给定提示的含义。