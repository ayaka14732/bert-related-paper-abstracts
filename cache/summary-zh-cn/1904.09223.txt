我们提出了一种新的由知识增强的语言表示模型，称为ERNIE（通过知识集成增强表示）。受BERT掩蔽策略的启发，ERNIE旨在学习通过知识掩蔽策略增强的语言表示，包括实体级掩蔽和短语级掩蔽。实体级策略屏蔽了通常由多个单词组成的实体。短语级策略屏蔽了由多个单词组成的作为概念单元的整个短语。实验结果表明，ERNIE优于其他基线方法，在自然语言推理、语义相似度、命名实体识别、情感分析和问答等五项中文自然语言处理任务上取得了最新成果。我们还证明了ERNIE在完形填空测试中具有更强大的知识推理能力。