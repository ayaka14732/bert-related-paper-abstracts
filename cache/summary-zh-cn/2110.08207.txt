大型语言模型最近被证明可以在不同的任务集上实现合理的零炮泛化。有人假设这是语言模型训练中内隐多任务学习的结果。零炮泛化能直接由显式多任务学习产生吗？为了大规模地测试这个问题，我们开发了一个系统，可以轻松地将一般自然语言任务映射为人类可读的提示形式。我们使用不同的自然语言转换一大组有监督的数据集，每个数据集都有多个提示。这些提示数据集允许对模型执行自然语言中指定的完全看不见的任务的能力进行基准测试。我们在此多任务混合上微调了一个预训练编码器-解码器模型，该模型涵盖了各种各样的任务。该模型在多个标准数据集上实现了强大的零炮性能，通常比其尺寸大16倍的模型表现更好。此外，我们的方法在大型基准测试中的一部分任务上获得了很好的性能，超过了6倍于其规模的模型。所有提示和经过培训的模型均可在github.com/bigscience workshop/promptsource/上获得。