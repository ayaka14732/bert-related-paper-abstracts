文本生成在过去几年中取得了重大进展。然而，由于最受欢迎的选择（如BLEU和ROUGE）可能与人类的判断关联性较差，因此评估指标落后。我们提出了BLEURT，这是一种基于BERT的学习评估指标，可以用几千个可能有偏差的训练示例来模拟人类的判断。我们方法的一个关键方面是一个新的预训练方案，它使用数百万个合成示例来帮助模型推广。BLEURT提供了过去三年WMT Metrics共享任务和WebNLG竞争数据集的最新结果。与普通的基于BERT的方法相比，即使在训练数据稀少且分布不均的情况下，它也能产生更好的结果。