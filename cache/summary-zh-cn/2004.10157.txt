许多自然语言问题需要在两个实体或事件之间进行定性、定量或逻辑比较。本文通过集成逻辑规则和神经模型来解决提高比较问题回答的准确性和一致性的问题。我们的方法利用逻辑和语言知识来增加标记的训练数据，然后使用基于一致性的正则化器来训练模型。为了提高预测的全局一致性，我们的方法在各种问答（QA）任务（包括多项选择定性推理、因果推理和抽取式机器阅读理解）中比以前的方法有了很大的改进。特别是，我们的方法显著提高了基于RoBERTa的模型在数据集上的性能1-5%。我们将WIQA和QuaRel的最新水平提高了约5-8%，并将HotpotQA的一致性违规降低了58%。我们进一步证明，我们的方法可以从有限的数据中有效地学习。