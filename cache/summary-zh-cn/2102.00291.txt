我们提出了一种通过微调BERT实现自动语音识别（ASR）的简单方法，这是一种在大规模未标记文本数据上训练的语言模型（LM），可以生成丰富的上下文表示。我们的假设是，给定一个历史上下文序列，一个强大的LM可以缩小可能的选择范围，语音信号可以用作简单的线索。因此，与从零开始训练强大声学模型（AM）的传统ASR系统相比，我们相信，通过简单地微调BERT模型，语音识别是可能的。作为一项初步研究，我们在AISHELL数据集上证明了所提出的思想的有效性，并表明在BERT上叠加一个非常简单的AM可以产生合理的性能。