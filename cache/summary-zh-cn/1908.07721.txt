实体和关系抽取是构建医学文本的必要步骤。然而，现有模型中的双向长短时记忆网络的特征提取能力并没有达到最佳效果。同时，该语言模型在越来越多的自然语言处理任务中取得了优异的效果。在本文中，我们提出了一个集中注意模型的联合实体和关系提取任务。该模型通过动态范围注意机制将著名的BERT语言模型集成到联合学习中，从而提高了共享参数层的特征表示能力。在曙光医院采集的冠状动脉造影文本上的实验结果表明，命名实体识别和关系分类任务的F1得分分别达到96.89%和88.51%，分别优于最先进的方法1.65%和1.22%。