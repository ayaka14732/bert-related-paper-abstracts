无监督的预培训在自然语言理解方面取得了很大的进步。在本文中，我们研究了自我训练作为另一种通过半监督学习利用未标记数据的方法。为了获得特定任务的附加数据，我们引入了SentAugment，这是一种数据增强方法，它从标记数据计算特定于任务的查询嵌入，以从从web上抓取的数十亿个未标记句子库中检索句子。与以前的半监督方法不同，我们的方法不需要域内未标记的数据，因此更普遍适用。实验表明，在各种任务中，自我训练与强大的罗伯塔基线是相辅相成的。我们的增强方法实现了可扩展和有效的自我训练，在标准文本分类基准上提高了2.6%。最后，我们还展示了在知识提炼和少量学习方面的强大收益。