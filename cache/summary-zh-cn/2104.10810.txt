构建一个能够与人类自然通信的对话系统是基于agent计算的一个具有挑战性但有趣的问题。这一领域的快速发展通常受到长期存在的数据匮乏问题的阻碍，因为这些系统需要从数量不足的任务特定数据集中学习语法、语法、决策和推理。最近引入的预训练语言模型有可能解决数据稀缺的问题，并通过生成上下文化的单词嵌入带来相当大的优势。这些模型被认为是NLP中ImageNet的对应模型，并已证明能够捕获语言的不同方面，如层次关系、长期依赖性和情感。在这篇简短的调查报告中，我们讨论了预训练语言模型领域的最新进展。我们还讨论了如何利用这些语言模型的优势来设计更具吸引力和更雄辩的会话代理。因此，本文旨在确定这些预先训练的模型是否能够克服与对话系统相关的挑战，以及如何利用它们的架构来克服这些挑战。还审议了对话系统领域的公开挑战。