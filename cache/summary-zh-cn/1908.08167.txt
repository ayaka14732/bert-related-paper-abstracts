BERT模型已成功地应用于开放域QA任务。然而，以前的工作通过查看与独立训练实例相同的问题对应的段落来训练BERT，这可能会导致不同段落的答案得分不可比。为了解决这个问题，我们提出了一个多段落的BERT模型来对同一问题的所有段落的答案分数进行全局标准化，这一变化使我们的QA模型能够利用更多的段落找到更好的答案。此外，我们发现通过滑动窗口将文章拆分为100个单词的段落可以将性能提高4%。通过利用通道ranker选择高质量通道，多通道BERT额外增加2%。在四个标准基准上的实验表明，我们的多通道BERT在所有基准上都优于所有最先进的模型。特别是，在OpenSQuAD数据集上，我们的模型比所有非BERT模型分别提高了21.4%EM和21.5%F_1$，比基于BERT的模型提高了5.8%EM和6.5%F_1$。