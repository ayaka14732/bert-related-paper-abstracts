尽管许多基于BERT的跨模态预训练模型在图像文本检索和VQA等下游理解任务上产生了优异的结果，但它们不能直接应用于生成任务。在本文中，我们提出了一种新的跨模态生成预训练图像字幕的方法XGPT，该方法旨在通过三种新的生成任务，包括图像条件蒙蔽语言建模（IMLM）、图像条件去噪自动编码（IDA）和，和文本条件图像特征生成（TIFG）。因此，预先训练的XGPT可以进行微调，而无需任何特定于任务的体系结构修改，以创建用于图像字幕的最先进模型。实验表明，XGPT在基准数据集上获得了最新的结果，包括COCO字幕和Flickr30k字幕。我们还使用XGPT生成新的图像标题，作为图像检索任务的数据补充，并在所有召回指标上实现显著改进。