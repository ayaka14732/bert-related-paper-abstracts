自然语言处理涵盖了预测语法、语义和信息内容的各种任务，通常每种类型的输出都是通过专门设计的体系结构生成的。在本文中，我们提供了一个简单的见解，即各种各样的任务可以用一个统一的格式表示，该格式由标记范围和范围之间的关系组成，因此单个任务独立模型可以用于不同的任务。我们在10个不同的任务上进行了大量的实验来测试这一洞察力，这些任务包括依赖项解析（语法）、语义角色标记（语义）、关系提取（信息内容）、基于方面的情感分析（情感）和许多其他任务，实现了与最先进的专门模型相当的性能。我们进一步证明了多任务学习的好处，同时也表明所提出的方法可以很容易地分析模型处理不同任务的异同。最后，我们将这些数据集转换成统一的格式来构建基准测试，它为评估广义自然语言分析的未来模型提供了一个全面的测试平台。