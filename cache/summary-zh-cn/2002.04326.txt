最近强大的预训练语言模型在大多数流行的阅读理解数据集上都取得了显著的成绩。现在是引入更具挑战性的数据集的时候了，以推动该领域向更全面的文本推理发展。在本文中，我们介绍了一个新的阅读理解数据集需要逻辑推理（RECOR）提取标准化的研究生入学考试。正如早期的研究所表明的，人类注释的数据集通常包含偏见，模型常常利用这些偏见来实现高精度，而没有真正理解文本。为了全面评估重合闸模型的逻辑推理能力，我们提出识别有偏数据点并将其划分为易集，而将其余数据点划分为硬集。实证结果表明，最先进的模型能够以较高的精度捕捉数据集中包含的偏差，并且易于设置。然而，它们在硬集上挣扎，性能差，接近随机猜测，这表明需要更多的研究来从本质上增强当前模型的逻辑推理能力。