近年来，自然语言处理（NLP）模型在文本分类、机器翻译、认知对话系统、自然语言理解信息检索（NLU）和自然语言生成（NLG）等语言和语义任务中取得了巨大成功。这一壮举主要归功于开创性的变压器架构，导致了诸如BERT、GPT（I、II、III）等设计。尽管这些大型模型取得了前所未有的性能，但它们的计算成本很高。因此，最近的一些NLP体系结构利用了迁移学习、剪枝、量化和知识提取的概念，以实现适度的模型大小，同时保持与前辈几乎相似的性能。此外，为了从知识提取的角度缓解语言模型带来的数据量挑战，已经构建了知识检索器，以便以更高的效率和准确性从大量数据库中提取显式数据文档。最近的研究也集中于通过有效地关注较长的输入序列来进行更好的推理。在本文中，我们总结和检查了当前最先进的（SOTA）NLP模型，这些模型已用于许多NLP任务，以获得最佳性能和效率。我们提供了对不同体系结构的详细理解和功能、NLP设计的分类、比较评估以及NLP的未来方向。