从少量训练数据中快速学习的能力拓宽了机器学习应用的范围。在本文中，我们提出了一个数据高效的图像字幕模型VisualGPT，该模型利用了大型预训练语言模型（LM）中的语言知识。一个关键的挑战是如何在图像中视觉信息的使用和预先训练中获得的语言知识之间取得平衡。我们设计了一种新的自恢复编码器-解码器注意机制，用于在少量域内训练数据上快速适应预训练LM作为语言解码器。建议的自复活激活单元产生稀疏激活，但降低了对零梯度的敏感性。我们在0.1%、0.5%和1%的MSCOCO和概念性字幕训练数据上训练提出的模型VisualGPT。在这些条件下，我们的表现优于最佳基线模型，在MS COCO上高达10.8%的苹果酒，在概念性标题上高达5.4%的苹果酒。此外，VisualGPT在医学报告生成数据集IUX-ray上实现了最先进的结果。据我们所知，这是第一项利用单峰数据预训练的LM提高图像字幕数据效率的工作。我们的代码可从以下网址获得：https://github.com/Vision-CAIR/VisualGPT.