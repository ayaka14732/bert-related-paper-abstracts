最近，大规模预先训练的语言模型在几个常识推理基准数据集上表现出令人印象深刻的性能。然而，用常识构建机器来组成现实可行的句子仍然具有挑战性。在本文中，我们提出了一个约束文本生成任务，CommonGen与一个基准数据集相关联，用于显式测试机器的生成常识推理能力。给定一组常见概念（例如，{狗、飞盘、接球、投掷}）；任务是使用这些概念生成一个连贯的句子来描述日常场景（例如，“一个人扔飞盘，他的狗抓住了它”）。CommonGen任务具有挑战性，因为它本质上需要1）具有背景常识知识的关系推理，以及2）处理看不见的概念组合的合成概括能力。我们的数据集由众包和现有字幕语料库组合而成，由79k个常识描述和35k个独特概念集组成。实验表明，最先进的文本生成模型（如T5）与人类绩效之间存在很大差距。此外，我们还证明了学习到的生成性常识推理能力可以通过生成额外的上下文来转移，以改进下游任务，如常识问答。