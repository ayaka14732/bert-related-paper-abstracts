关系分类是提取实体间关系的一项重要NLP任务。最先进的关系分类方法主要基于卷积或递归神经网络。最近，预训练的BERT模型在许多NLP分类/序列标记任务中取得了非常成功的结果。关系分类不同于那些任务，因为它依赖于句子和两个目标实体的信息。在本文中，我们提出了一个模型，该模型既利用预先训练好的BERT语言模型，又结合来自目标实体的信息来处理关系分类任务。我们定位目标实体并通过预先训练的体系结构传输信息，并合并两个实体的相应编码。我们在SemEval-2010 task 8关系数据集上实现了对最先进方法的显著改进。