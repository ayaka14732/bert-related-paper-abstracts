我们介绍了韩语理解评估（KLUE）基准。KLUE是一个由8项韩国语自然语言理解（NLU）任务组成的集合，包括主题分类、语义-文本相似度、自然语言推理、命名实体识别、关系提取、依存分析、机器阅读理解和对话状态跟踪。在尊重版权的同时，我们从零开始从不同来源的语料库构建所有任务，以确保任何人都可以不受任何限制地访问。出于道德考虑，我们仔细设计注释协议。除了基准任务和数据外，我们还为每个任务的预训练语言模型提供合适的评估指标和微调方法。此外，我们还发布了预训练语言模型（PLM），KLUE-BERT和KLUE-RoBERTa，以帮助在KLUE上复制基线模型，从而促进未来的研究。我们从使用建议的KLUE基准套件的初步实验中得出了一些有趣的观察结果，已经证明了这个新基准套件的有用性。首先，我们发现KLUE RoBERTa large优于其他基线，包括多语言PLM和现有的开源韩国PLM。第二，即使我们从训练前的语料库中替换个人识别信息，我们也能看到性能的最小下降，这表明隐私和NLU能力并不矛盾。最后，我们发现在涉及语素级标记、检测和生成的任务中，将BPE标记化与语素级预标记化结合使用是有效的。除了加速韩国NLP研究，我们关于创建KLUE的全面文档将有助于将来为其他语言创建类似的资源。KLUE可在https://klue-benchmark.com.