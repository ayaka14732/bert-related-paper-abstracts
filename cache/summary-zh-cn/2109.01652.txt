本文探讨了一种提高语言模型零炮学习能力的简单方法。我们展示了指令调优——对通过指令描述的一组任务进行精细调优的语言模型——在看不见的任务上显著提高了零炮性能。我们采用137B参数预训练语言模型，并在通过自然语言教学模板表达的60多个NLP任务上对其进行教学调整。我们对这个指令优化模型（我们称之为FLAN）进行评估，评估的是看不见的任务类型。FLAN大大提高了其未经修改的同类产品的性能，在我们评估的25项任务中，有20项超过了零炮175B GPT-3。FLAN甚至在ANLI、RTE、BoolQ、AI2-ARC、OpenbookQA和StoryCloze上的表现都大大超过了几杆GPT-3。消融研究表明，任务数量和模型规模是教学调整成功的关键因素。