在过去三年中，最大的密集深度学习模型已经增长了1000倍，达到数千亿个参数，而GPU内存只增长了5倍（16 GB到80 GB）。因此，主要通过系统创新来支持模型规模的增长，系统创新使大型模型能够装入多个GPU的聚合GPU内存。然而，我们正在接近GPU内存墙。它需要800个NVIDIA V100 GPU才能适应一个万亿参数的模型进行训练，而这样的集群对于大多数数据科学家来说简直遥不可及。此外，这种规模的模型训练需要复杂的并行技术组合，这给数据科学家重构模型带来了巨大负担。在本文中，我们介绍了ZeRO Infinity，这是一种新的异构系统技术，它利用GPU、CPU和NVMe内存在有限的资源上实现前所未有的模型规模，而无需重构模型代码。同时，它实现了出色的训练吞吐量和可扩展性，不受有限的CPU或NVMe带宽的限制。ZeRO Infinity可以适合具有数十甚至数百万亿参数的模型，用于在当前一代GPU集群上进行训练。它可以用于微调单个NVIDIA DGX-2节点上的万亿参数模型，使大型模型更容易访问。在训练吞吐量和可扩展性方面，它在512个NVIDIA V100 GPU（峰值的40%）上支持超过25 PB的速度，同时还展示了超线性可扩展性。ZeRO Infinity的开源实现可通过DeepSpeed获得，这是一个深度学习优化库，使分布式培训变得简单、高效和有效。