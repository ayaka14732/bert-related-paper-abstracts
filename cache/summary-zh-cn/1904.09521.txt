基于神经网络的从结构化数据或知识生成自然语言（NLG）的端到端方法需要大量数据，这使得它们难以在数据有限的情况下用于实际应用。在这项工作中，我们提出了一个新的任务\texit{now shot natural language generation}。受人们如何总结表格数据的启发，我们提出了一种简单而有效的方法，并表明它不仅表现出强大的性能，而且还提供了跨领域的良好泛化。模型结构的设计基于两个方面：从输入数据中选择内容和从先验知识中获取连贯句子的语言建模。通过200个跨多个领域的培训示例，我们证明了我们的方法实现了非常合理的性能，比最强的基线平均提高了8.0个BLEU点。我们的代码和数据可在\url中找到{https://github.com/czyssrs/Few-Shot-NLG}