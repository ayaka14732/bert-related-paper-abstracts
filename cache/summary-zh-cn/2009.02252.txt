具有挑战性的问题，如开放领域问题回答、事实检查、插槽填充和实体链接，需要访问大型外部知识源。虽然有些模型在单个任务上表现良好，但开发通用模型是困难的，因为除了专用的基础设施之外，每个任务可能还需要对自定义知识源进行昂贵的计算索引。为了促进对以大型文本资源中的特定信息为条件的模型的研究，我们提出了一个知识密集型语言任务（KILT）的基准。KILT中的所有任务都基于Wikipedia的同一快照，通过重用组件减少了工程周期，并加快了对任务无关内存体系结构的研究。我们测试特定任务和一般基线，除了评估模型提供来源的能力外，还评估下游性能。我们发现，共享稠密向量索引与seq2seq模型相结合是一个强大的基线，在事实检查、开放领域问题回答和对话方面优于更多定制方法，并通过生成消除歧义的文本在实体链接和插槽填充方面产生有竞争力的结果。KILT数据和代码可在https://github.com/facebookresearch/KILT.