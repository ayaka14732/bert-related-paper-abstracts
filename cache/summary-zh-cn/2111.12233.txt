近年来，基于视觉语言预训练（VLP）的图像字幕任务取得了显著的性能提升。规模被认为是这一进步的一个重要因素。然而，大多数现有工作只关注大约400万张图像上中等大小（例如12或24层）的预训练变压器。在本文中，我们介绍了LEMON，一个大规模的图像字幕，并提供了第一个关于VLP在图像字幕中缩放行为的实证研究。我们使用最先进的VinVL模型作为参考模型，该模型由图像特征提取程序和变压器模型组成，并对变压器进行上下缩放，模型大小从1300万到6.75亿个参数不等。在数据方面，我们对多达2亿对图像文本进行了实验，这些图像文本对是根据图像的alt属性（称为ALT200M）自动从web上收集的。广泛的分析有助于描述模型大小和训练前数据大小增加时的性能趋势。我们还比较了不同的训练方法，尤其是针对大规模噪声数据的训练。因此，LEMON在几个主要的图像字幕基准上达到了新的水平，包括COCO字幕、nocaps和概念性字幕。我们还展示了LEMON在以零镜头方式使用时，可以生成带有长尾视觉概念的字幕。