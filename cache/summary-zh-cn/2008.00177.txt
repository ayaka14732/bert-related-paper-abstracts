最近，基于转换器的大规模语言模型（如BERT、GPT-2和XLNet）为许多自然语言处理（NLP）任务带来了令人振奋的最新成果。这些最新模型的一个共同趋势是模型复杂性的显著增加，这将引入更多的权重和计算。此外，随着大规模无监督数据集的出现，由于单个训练周期内数据样本量的增加，训练时间进一步延长。因此，为了在合理的时间内训练这些模型，机器学习（ML）程序员通常需要高级硬件设置，如支持高级GPU的NVIDIA DGX工作站或专用加速器，如谷歌的TPU吊舱。我们的工作解决了这一局限性，并证明通过仔细的算法和软件优化，可以在2周内在学术规模的广泛可用GPU集群上对伯特预训练模型进行训练。在本文中，我们针对如何提高单个设备的培训吞吐量、将培训工作量分配到多个节点和GPU以及克服网络上的大型数据交换带来的通信瓶颈提出了这些优化。我们表明，我们能够在合理的时间预算（12天）内，在学术环境中对BERT进行预培训，但硬件资源需求比以前基于NVIDIA DGX机器或谷歌TPU吊舱的工业环境要便宜得多，也不那么苛刻。