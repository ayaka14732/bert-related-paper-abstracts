大型神经模型的无监督预训练最近彻底改变了自然语言处理。通过从公开发布的检查点开始，NLP从业者在多个基准上推动了最先进的技术，同时节省了大量的计算时间。到目前为止，重点主要放在自然语言理解任务上。在本文中，我们证明了预先训练的检查点用于序列生成的有效性。我们开发了一个基于转换器的序列到序列模型，该模型与公开的预训练BERT、GPT-2和RoBERTa检查点兼容，并对使用这些检查点初始化我们的模型（编码器和解码器）的实用性进行了广泛的实证研究。我们的模型在机器翻译、文本摘要、句子分割和句子融合方面取得了最新的成果。