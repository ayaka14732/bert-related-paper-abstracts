自然问题生成（QG）旨在从文章和答案中生成问题。以往关于QG的工作要么（i）忽略文本中隐藏的丰富结构信息，（ii）仅依赖交叉熵损失，导致暴露偏差和训练/测试测量之间的不一致，要么（iii）未能充分利用答案信息。为了解决这些局限性，本文提出了一种基于强化学习（RL）的QG图到序列（Graph2Seq）模型。我们的模型包括一个Graph2Seq生成器和一个基于双向门控图神经网络的编码器来嵌入通道，以及一个混合评估器，该混合评估器具有结合交叉熵和RL损失的混合目标，以确保生成语法和语义有效的文本。我们还引入了一个有效的深度对齐网络，用于在单词和上下文层面将答案信息整合到文章中。我们的模型是端到端可训练的，并取得了新的最先进的分数，比现有的方法在标准阵容基准上有显著的优势。