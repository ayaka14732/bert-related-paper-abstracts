现有的预训练语言模型（PLM）在推理方面的计算成本通常很高，这使得它们在各种资源有限的实际应用中不切实际。为了解决这一问题，我们提出了一种动态令牌缩减方法来加速PLMs的推理，称为TR-BERT，它可以灵活地调整推理中每个令牌的层数，以避免冗余计算。特别地，TR-BERT将令牌缩减过程描述为一个多步骤令牌选择问题，并通过强化学习自动学习选择策略。在几个下游NLP任务上的实验结果表明，TR-BERT能够将BERT速度提高2-5倍，以满足各种性能要求。此外，TR-BERT还可以在一组长文本任务中以较少的计算量获得更好的性能，因为它的令牌层数自适应大大加快了PLMs中的自我注意操作。本文的源代码和实验细节可以从https://github.com/thunlp/TR-BERT.