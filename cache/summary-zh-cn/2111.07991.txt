本文介绍了对比调整，这是一种简单的方法，使用对比训练来对齐图像和文本模型，同时仍然利用它们的预训练。在我们的实证研究中，我们发现锁定的预训练图像模型和解锁的文本模型效果最好。我们将这种对比调整的实例称为“锁定图像调整”（LiT），它只是教文本模型从预先训练好的图像模型中读出新任务的良好表示。LiT模型可以将零镜头转移到新的视觉任务中，如图像分类或检索。建议的LiT具有广泛的适用性；它可以可靠地使用多种预训练方法（有监督和无监督），并跨不同的体系结构（ResNet、Vision Transformers和MLP Mixer），使用三种不同的图像文本数据集。使用基于变压器的预训练ViT-g/14模型，LiT模型在ImageNet测试集上实现了84.5%的零炮传输精度，在具有挑战性的分布外ObjectNet测试集上实现了81.1%的零炮传输精度。