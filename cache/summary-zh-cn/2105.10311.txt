文本生成已成为自然语言处理（NLP）中最重要但最具挑战性的任务之一。深度学习的复兴通过神经生成模型，特别是预训练语言模型（PLM）的范例，极大地推进了这一领域。在本文中，我们概述了在文本生成的PLMs主题中取得的主要进展。作为开场白，我们给出了一般的任务定义，并简要描述了用于文本生成的PLMs的主流体系结构。作为核心内容，我们讨论了如何使现有的PLM适应不同的输入数据并满足生成文本中的特殊属性。我们进一步总结了几种重要的文本生成微调策略。最后，我们提出了未来的几个方向，并对本文进行了总结。我们的调查旨在为文本生成研究人员提供一个综合和相关研究的指针。