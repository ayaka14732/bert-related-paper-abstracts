大规模的预训练语言模型是最近Winograd Schema Challenge性能改进的主要驱动力，Winograd Schema Challenge是一项广泛使用的常识推理能力测试。然而，我们通过一个新的诊断数据集表明，这些模型对Winograd示例的语言干扰非常敏感，这些干扰对人类理解的影响最小。我们的研究结果突出了人类和语言模型之间有趣的差异：语言模型比人类对数字或性别变化以及同义词替换更敏感，人类的预测更稳定一致，保持更高的绝对性能，并且在非关联实例上的性能优于关联实例。总的来说，人类比开箱即用的模型更为正确，而模型有时因为错误的原因是正确的。最后，我们展示了在大型、特定于任务的数据集上进行微调可以为这些问题提供解决方案。