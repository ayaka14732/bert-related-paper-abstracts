使用特定于任务的提示调整预先训练的语言模型（PLM）是一种很有前途的文本分类方法。特别是，以前的研究表明，与带有额外分类器的通用微调方法相比，快速调优在低数据场景中具有显著的优势。提示调优的核心思想是将文本片段（即模板）插入到输入中，并将分类问题转化为蒙面语言建模问题，其中关键步骤是在标签空间和标签词空间之间构建投影（即描述器）。描述者通常是手工制作或通过梯度下降进行搜索，这可能缺乏覆盖范围，并给结果带来相当大的偏差和高度差异。在这项工作中，我们将重点放在将外部知识合并到言语化器中，形成知识丰富的提示调优（KPT），以改进和稳定提示调优。具体地说，我们使用外部知识库（KBs）扩展描述词的标签词空间，并在使用扩展的标签词空间进行预测之前使用PLM本身细化扩展的标签词空间。在零镜头和少量镜头文本分类任务上的大量实验证明了知识提示调整的有效性。