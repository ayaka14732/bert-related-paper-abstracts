自关注神经网络结构的最新进展提高了开放式文本生成的门槛。然而，尽管目前的方法能够产生几百字长的连贯文本，但控制正在生成的内容以及对其进行评估仍然是一个悬而未决的问题。我们提出了一个控制生成任务，该任务基于将自然语言表达的一系列事实扩展为更长的叙述。我们为这项任务引入了基于人的评估指标，以及一种获取大型训练数据集的方法。基于微调预训练模型，我们评估了这项任务的三种方法。我们发现，尽管像GPT2这样的自回归单向语言模型能产生更好的流利性，但它们很难坚持要求的事实。我们提出了一个计划和完形填空模型（使用微调的XLNet），该模型在保持所需内容的同时，能产生有竞争力的流畅性。