预训练模型已被证明对广泛的自然语言处理任务是有效的。受此启发，我们提出了一个新的对话生成预训练框架，以支持各种类型的对话，包括聊天、基于知识的对话和会话问答。在这个框架中，我们采用灵活的注意机制来充分利用双向语境和语言生成的单向特性。我们还引入离散潜在变量来解决响应生成中固有的一对多映射问题。在一个共享网络中，设计并同时执行响应生成和潜在行为识别两个交互任务。在三个公开数据集上的综合实验验证了该框架的有效性和优越性。