最近的工作表明，通过对大量文本进行预训练，然后对特定任务进行微调，在许多NLP任务和基准测试方面取得了实质性进展。虽然这种方法在体系结构中通常是任务不可知的，但仍然需要数千或上万个示例的特定于任务的微调数据集。相比之下，人类通常只能通过几个例子或简单的指令来执行一项新的语言任务，而目前的NLP系统仍然很难做到这一点。在这里，我们展示了扩展语言模型极大地提高了任务无关性、少镜头的性能，有时甚至可以与先前最先进的微调方法相媲美。具体地说，我们训练了GPT-3，一个具有1750亿个参数的自回归语言模型，比以前任何非稀疏语言模型都多10倍，并在少数镜头设置下测试了它的性能。对于所有任务，GPT-3应用时没有任何梯度更新或微调，任务和少量镜头演示仅通过与模型的文本交互指定。GPT-3在许多NLP数据集上实现了强大的性能，包括翻译、问答和完形填空任务，以及一些需要动态推理或领域适应的任务，如解读单词、在句子中使用新单词或执行3位数算术。同时，我们还确定了一些数据集，其中GPT-3的少量镜头学习仍然困难，以及一些GPT-3面临与大型网络语料库培训相关的方法学问题的数据集。最后，我们发现GPT-3可以生成新闻文章的样本，而人类评价者很难将其与人类撰写的文章区分开来。我们讨论了这一发现和GPT-3的广泛社会影响。