口语理解（SLU）将自动语音识别器（ASR）中的假设转换为结构化语义表示。ASR识别错误会严重降低后续SLU模块的性能。为了解决这个问题，单词混淆网络（WCN）被用来编码SLU的输入，它包含比1-best或n-best假设列表更丰富的信息。为了进一步消除歧义，对话上下文的最后一个系统动作也被用作附加输入。本文提出了一种新的基于BERT的SLU模型（WCN-BERT SLU），用于对WCN和对话上下文进行联合编码。它可以将WCN的结构信息和ASR后验概率集成到BERT结构中。在SLU的一个基准DSTC2上的实验表明，该方法是有效的，并且能够显著优于以前的最新模型。