从BERT派生的短语表示通常不表现出复杂的短语组成性，因为该模型依赖于词汇相似性来确定语义关联性。在本文中，我们提出了一个对比微调目标，使伯特能够产生更强大的短语嵌入。我们的方法（短语BERT）依赖于使用释义生成模型自动生成的各种短语释义数据集，以及从Books3语料库中挖掘的大规模上下文短语数据集。短语BERT在各种短语级相似性任务中的表现优于基线，同时也表明向量空间中最近邻之间的词汇多样性增加。最后，作为一个案例研究，我们表明短语BERT嵌入可以很容易地与一个简单的自动编码器集成，以建立一个基于短语的神经主题模型，该模型通过在嵌入空间中执行最近邻搜索将主题解释为词和短语的混合。众包评估表明，这种基于短语的主题模型比基线单词和短语级主题模型产生的主题更加连贯和有意义，进一步验证了短语模型的效用。