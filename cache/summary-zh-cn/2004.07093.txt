近年来，基于变换器的双向编码表示（BERT）模型因其在语言理解相关任务中的高性能而受到自然语言处理领域的广泛关注。BERT模型通过无监督的方式使用大型语料库进行预训练，学习能够适应各种任务的语言表示。本研究提出了使用多模态伯特（lamBERT）模型的语言和动作学习，该模型通过1）将伯特模型扩展到多模态表示，2）将其与强化学习相结合，从而实现语言和动作的学习。为了验证所提出的模型，在网格环境中进行了一个实验，该环境需要理解语言才能使代理正常工作。因此，与其他模型（如基于卷积神经网络的模型和未经预训练的lamBERT模型）相比，lamBERT模型在多任务设置和转移设置中获得了更高的回报。