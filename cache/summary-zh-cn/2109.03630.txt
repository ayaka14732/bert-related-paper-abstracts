在英语学习中，离散和软提示在预训练语言模型（PLM）的少镜头学习中表现得很好。在本文中，我们证明了离散和软提示在多语种情况下的表现优于微调：跨语种迁移和多语种自然语言推理的语言训练。例如，在48个英语培训示例中，FineTunning在跨语言迁移方面获得了33.74%的准确率，几乎没有超过大多数基线（33.33%）。相比之下，离散和软激励的表现优于微调，分别达到36.43%和38.79%。我们还用英语以外的多种语言的训练数据演示了良好的提示性能。