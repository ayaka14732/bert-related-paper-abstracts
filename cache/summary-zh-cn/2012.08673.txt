大规模预先培训的多模式变压器，如维尔伯特和UNITER，将视觉和语言（V+L）研究的最新水平推向了一个新水平。尽管迄今为止在标准任务上取得了令人印象深刻的性能，但这些预先训练的模型的健壮性仍不清楚。为了调查，我们对现有的预训练模型进行了大量的全面评估，评估了4种不同类型的V+L特定模型的稳健性：（i）语言变异；二逻辑推理；（iii）视觉内容操纵；（iv）回答分布转移。有趣的是，通过标准的模型微调，预训练的V+L模型已经比许多任务特定的最新方法表现出更好的鲁棒性。为了进一步增强模型的鲁棒性，我们提出了Mango，这是一种通用而有效的方法，可以在嵌入空间中学习多模态对抗性噪声发生器来愚弄预先训练的V+L模型。与以往专注于一种特定类型的鲁棒性的研究不同，Mango是任务不可知的，能够在不同的任务中提升预先训练的模型的通用性能，以评估鲁棒性的广泛方面。综合实验表明，Mango在9个健壮性基准中有7个达到了最新水平，大大超过了现有方法。作为对V+L稳健性的第一次全面研究，本研究将预训练模型的稳健性置于更加突出的位置，为未来的研究指明了新的方向。