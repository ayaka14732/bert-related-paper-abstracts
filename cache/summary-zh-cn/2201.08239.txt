我们提出了LaMDA：对话应用程序的语言模型。LaMDA是一系列基于变压器的神经语言模型，专门用于对话，其参数高达137B，并基于1.56T的公共对话数据和网络文本进行预训练。虽然模型缩放单独可以提高质量，但在安全性和实际接地方面的改进较少。我们证明，使用注释数据进行微调，并使模型能够参考外部知识源，可以显著改善安全和事实基础这两个关键挑战。第一个挑战是安全，涉及确保模型的响应符合一套人类价值观，如防止有害建议和不公平偏见。我们使用基于一组说明性人类价值观的度量来量化安全性，我们发现使用LaMDA分类器对候选响应进行过滤，并使用少量crowdworker注释数据进行微调，提供了一种很有希望的方法来提高安全性