尽管使用神经网络的语言模型取得了成功，但仍不清楚神经模型在多大程度上具有执行推理的泛化能力。本文介绍了一种评价神经模型是否能够学习自然语言中单调性推理的系统性的方法，即对合成进行泛化的任意推理的规律性。我们考虑单调性推断的四个方面，并检验模型是否能够系统地解释不同训练/测试分裂中的词汇和逻辑现象。一系列实验表明，当训练集和测试集的句子句法结构相似时，三个神经模型系统地对词汇和逻辑现象的不可见组合进行推理。然而，当测试集中的结构发生轻微变化时，模型的性能会显著降低，同时保留训练集中已经出现的所有词汇和成分。这表明神经模型的泛化能力仅限于句法结构与训练集中的句法结构几乎相同的情况。