当前最先进的命名实体识别方法（NER）通常考虑句子级的文本，因此不模拟越过句子边界的信息。但是，基于transformer的NER模型的使用为捕获文档级功能提供了自然的选择。在本文中，我们对文献中常用的两种标准NER体系结构（即“微调”和“基于特征的LSTM-CRF”）中的文档级功能进行了比较评估。我们评估文档级功能的不同超参数，如上下文窗口大小和强制文档位置。我们展示了一些实验，从中我们得出了如何对文档上下文建模的建议，并在几个CoNLL-03基准数据集上展示了新的最先进的分数。我们的方法被集成到Flair框架中，以便于复制我们的实验。