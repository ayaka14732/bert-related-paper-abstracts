机器学习中的评估通常由过去的选择决定，例如使用哪些数据集或指标。这种标准化使得能够使用排行榜在平等的基础上进行比较，但随着更好的备选方案的出现，评估选择变得次优。这个问题在自然语言生成中尤其重要，因为自然语言生成需要不断改进数据集、度量和人类评估套件，才能做出明确的声明。为了简化以下最佳模型评估实践，我们引入了GEMv2。新版本的生成、评估和度量基准为数据集、模型和度量开发人员引入了一个模块化基础设施，以从彼此的工作中受益。GEMv2支持51种语言的40个记录数据集。所有数据集的模型都可以在线评估，我们的交互式数据卡创建和渲染工具可以更轻松地将新数据集添加到实时基准中。