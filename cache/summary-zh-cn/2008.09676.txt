语音摘要是一个困难的问题，因为语音流的自发性、不流畅性以及书面语篇中通常不会遇到的其他问题。我们的工作介绍了BERTSum模型在会话语言中的首次应用。我们生成了从园艺和烹饪到软件配置和运动等各种主题的叙述式教学视频的抽象摘要。为了丰富词汇，我们使用迁移学习，并在几个大型跨领域的书面和口语数据集上预训练该模型。我们还对抄本进行预处理，以恢复ASR系统输出中的句子切分和标点符号。结果通过How2和WikiHow数据集的ROUGE和Content-F1评分进行评估。我们聘请人工评委对从HowTo100M和YouTube策划的数据集中随机选择的一组摘要打分。基于盲评估，我们的文本流畅性和实用性达到了与人类内容创作者撰写的摘要相近的水平。当应用于风格和主题差异很大的WikiHow文章时，该模型优于当前的SOTA，同时在规范的CNN/DailyMail数据集上没有显示性能回归。由于该模型在不同风格和领域的高度通用性，它在提高互联网内容的可访问性和可发现性方面具有巨大潜力。我们将此功能集成到智能虚拟助理中，使他们能够根据要求总结书面和口头教学内容。