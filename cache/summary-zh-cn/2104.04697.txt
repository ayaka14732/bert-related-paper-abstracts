虽然关系提取是知识获取和表示中的一项基本任务，并且新生成的关系在现实世界中很常见，但在预测在训练阶段无法观察到的不可见关系方面所做的努力较少。在本文中，我们通过合并可见和不可见关系的文本描述来描述零镜头关系提取问题。我们提出了一种新的多任务学习模型，零镜头伯特（ZS-BERT），可以直接预测不可见的关系，而无需手工制作属性标签和多重成对分类。给定由输入句子及其关系描述组成的训练实例，ZS-BERT学习将句子和关系描述投影到嵌入空间的两个函数，方法是联合最小化它们之间的距离并对所见关系进行分类。通过基于这两个函数生成不可见关系的嵌入和新出现的句子，我们使用最近邻搜索来获得不可见关系的预测。在两个著名数据集上进行的实验表明，ZS-BERT比现有方法的F1分数至少提高13.54\%。