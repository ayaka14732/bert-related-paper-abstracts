常识推理的最新进展依赖于大规模人工标注的训练数据来实现最高性能。然而，人工整理训练示例的成本很高，并且已经证明会引入注释伪影，神经模型可以很容易地利用和过度拟合这些伪影。我们研究了G-DAUG^C，这是一种新的生成性数据增强方法，旨在在低资源环境下实现更精确、更稳健的学习。我们的方法使用预先训练的语言模型生成合成示例，并选择信息量最大、种类最多的示例集进行数据扩充。在多个常识推理基准测试的实验中，G-DAUG^C始终优于现有的基于反译的数据增强方法，并在WinoGrande、CODAH和CommonsenseQA上建立了一个新的最新技术。此外，除了提高分布精度外，G-DAUG^C增强训练还增强了分布外泛化，显示出更强的对抗性或扰动示例的鲁棒性。我们的分析表明，G-DAUG^C产生了一组不同的流利培训示例，其选择和培训方法对绩效非常重要。我们的发现鼓励了未来对生成性数据增强的研究，以增强分布内学习和分布外泛化。