深度预培训双向变压器的使用在许多应用中取得了显著进展（Devlin等人，2018年）。对于在序列之间进行成对比较、将给定输入与相应标签匹配的任务，有两种方法是常见的：交叉编码器对序列对进行完全自我注意，双编码器对序列对进行单独编码。前者通常性能更好，但实际使用起来太慢。在这项工作中，我们开发了一种新的转换器架构，即Poly编码器，它学习全局而非令牌级别的自我关注特性。我们对这三种方法进行了详细的比较，包括哪些预培训和微调策略最有效。我们展示了我们的模型在三个现有任务上实现了最先进的结果；多边形编码器比交叉编码器更快，比双编码器更准确；通过对类似于下游任务的大型数据集进行预训练，可以获得最佳结果。