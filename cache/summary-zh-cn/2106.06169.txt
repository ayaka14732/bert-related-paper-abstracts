保持一致的人物角色对于对话代理至关重要。尽管已经取得了巨大的进步，但有限的标注角色密集型数据仍然是训练健壮且一致的基于角色的对话模型的障碍。在这项工作中，我们展示了如何通过一个新的BERT-over-BERT（BoB）模型将基于人物角色的对话生成分解为两个子任务来解决这些挑战。具体来说，该模型由一个基于伯特的编码器和两个基于伯特的解码器组成，其中一个解码器用于响应生成，另一个用于一致性理解。特别是，为了从大规模非对话推理数据中学习一致性理解能力，我们以一种不可能的方式训练第二个解码器。在不同的有限数据设置下，自动和人工评估都表明，该模型在响应质量和角色一致性方面优于强基线。