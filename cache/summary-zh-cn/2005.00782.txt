预先训练的语言模型（PTLM）在常识推理基准上取得了令人印象深刻的性能，但它们利用常识进行稳健推理的能力仍存在争议，这对于与人类的有效沟通至关重要。在追求流畅的人工智能通信的过程中，我们提出了一个新的挑战，RICA：基于常识公理的鲁棒推理能力，该能力在文本干扰的情况下评估鲁棒常识推理。为了为这一挑战生成数据，我们使用常识知识库开发了一个系统化和可扩展的程序，并在两个不同的评估环境中探索PTLM。对我们生成的具有超过10k条语句的探测集进行的大量实验表明，PTLM在零炮设置上的性能并不比随机猜测好，受统计偏差的严重影响，并且对扰动攻击不具有鲁棒性。我们还发现，对类似陈述的微调带来的收益有限，因为PTLM仍然无法推广到看不见的推论。我们新的大规模基准暴露了PTLM和人类语言理解之间的巨大差距，并为PTLM展示常识提供了新的挑战。