为了推进多模态环境的模型，我们引入了一种简单但功能强大的数据神经架构，该架构结合了视觉和自然语言。“文本转换器中的边界框”（B2T2）还利用引用信息将单词绑定到单个统一体系结构中的图像部分。B2T2在视觉常识推理基准上非常有效(https://visualcommonsense.com)，实现了新的技术水平，与公布的基线相比，错误率相对降低了25%，并在公共排行榜上获得了迄今为止的最佳表现（截至2019年5月22日）。详细的分析表明，将视觉特征早期集成到文本分析中是新体系结构有效性的关键。提供了我们模型的参考实现(https://github.com/google-research/language/tree/master/language/question_answering/b2t2).