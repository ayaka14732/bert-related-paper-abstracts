我们为视觉语言任务引入了一种新的可预先训练的泛型表示，称为视觉语言BERT（简称VL-BERT）。VL-BERT采用简单但功能强大的变换器模型作为主干，并将其扩展为以视觉和语言嵌入特征作为输入。其中，输入的每个元素要么是来自输入句子的单词，要么是来自输入图像的感兴趣区域（RoI）。它的设计适合大多数视觉语言任务。为了更好地利用泛型表示，我们在大规模概念标题数据集和纯文本语料库上预训练VL-BERT。大量的实证分析表明，预训练过程能够更好地整合视觉语言线索，有利于后续任务，如视觉常识推理、视觉问答和指称表达理解。值得注意的是，VL-BERT在VCR基准测试排行榜上取得了单一型号的第一名。代码发布于\url{https://github.com/jackroos/VL-BERT}.