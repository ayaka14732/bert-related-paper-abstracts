获取多跳问答（QA）的训练数据既耗时又占用大量资源。我们探讨了在不引用任何人类标记的多跳问答对（即无监督的多跳问答）的情况下，训练一个性能良好的多跳问答模型的可能性。我们提出了MQA-QG，这是一个无监督的框架，可以从同质和异构数据源生成类似于人的多跳训练数据。MQA-QG首先从每个数据源选择/生成相关信息，然后集成多个信息以形成多跳问题，从而生成问题。仅使用生成的训练数据，我们就可以训练出一个合格的多跳QA，对于HybridQA和HotpotQA数据集，其监督学习性能分别达到61%和83%。我们还表明，使用生成的数据对QA系统进行预培训将大大减少对人工标注的培训数据的需求。我们的代码可在https://github.com/teacherpeterpan/Unsupervised-Multi-hop-QA.