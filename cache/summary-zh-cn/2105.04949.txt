类比在人类常识推理中起着核心作用。识别类比的能力，如“眼睛是看的，耳朵是听的”，有时被称为类比比例，塑造我们如何构造知识和理解语言。然而，令人惊讶的是，在语言模型时代，识别这种类比的任务还没有得到太多的关注。在本文中，我们使用从教育环境中获得的基准以及更常用的数据集，分析了基于transformer的语言模型在这项无监督任务中的能力。我们发现，现成的语言模型可以在一定程度上识别类比，但难以处理抽象和复杂的关系，并且结果对模型结构和超参数高度敏感。总的来说，GPT-2和RoBERTa获得了最好的结果，而使用BERT的配置无法优于单词嵌入模型。我们的结果为未来的工作提出了重要的问题，即预先训练的语言模型如何以及在多大程度上获取抽象语义关系的知识。