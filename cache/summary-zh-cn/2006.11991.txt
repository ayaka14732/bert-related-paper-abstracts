在基于深度学习模型训练分类器时，医疗保健领域常见的小而不平衡的数据集是一个挑战。因此，我们提出了一个基于BioBERT（生物医学文本挖掘变压器的双向编码器表示）的新框架。具体而言，（i）我们在BERT的每一层中引入标签嵌入以实现自我关注，我们称之为LESA-BERT，（ii）通过将LESA-BERT提取为较小的变量，我们旨在减少处理小数据集时的过度拟合和模型大小。作为一个应用程序，我们的框架用于构建患者门户消息分类模型，该模型将消息的紧急程度分为三类：非紧急、中等和紧急。实验表明，我们的方法在宏F1分数方面比几种强基线分类器有4.3%的显著优势。此项目的代码可在\url公开获取{https://github.com/shijing001/text_classifiers}.