最近的许多研究表明，对于在自然语言推理（NLI）数据集上训练的模型，只需查看假设而完全忽略前提，就可以做出正确的预测。在这项工作中，我们设法从仅假设的偏见中得出对抗性的例子，并探索缓解这种偏见的合适方法。具体来说，我们从训练集中的假设（人工模式）中提取各种短语，并表明它们是特定标签的有力指标。然后，我们从原始测试集中找出“硬”和“易”实例，其标签与这些指示相反或一致。我们还建立了基线，包括预训练模型（BERT、RoBERTa、XLNet）和竞争性非预训练模型（InferSent、DAM、ESIM）。除了基准和基线外，我们还研究了两种利用人工模式建模来缓解这种仅假设偏差的debiasing方法：下采样和对抗性训练。我们相信这些方法可以作为NLI借记任务中的竞争基线。