零冗余优化器（Zero）由于其易用性、高效性和良好的可扩展性，已被用于在大规模GPU集群上训练各种大型语言模型。然而，当在低带宽集群上进行训练时，或者在迫使每个GPU的批处理大小较小的规模上进行训练，ZeRO的有效吞吐量受到限制，因为在前向传递、后向传递和平均梯度中收集权重会产生高通信量。本文介绍了三种通信量减少技术，我们统称为ZeRO++，针对ZeRO中的每个通信集体。首先是基于全聚集的块量化。第二个是数据重映射，用通信换取更多内存。第三是一种新的基于全对全的量化梯度平均范式，作为减少散射集合的替代，它在通信低精度数据的情况下保持了准确性。总的来说，ZeRO++将ZeRO的通信量减少了4倍，使384 GPU规模的吞吐量提高了2.16倍。