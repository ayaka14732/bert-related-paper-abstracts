我们提出了一种简单的方法，通过使用单一生成模型大规模生成多语言问答对。这些合成样本可用于改善目标语言上多语言QA模型的零炮性能。我们提出的生成模型的多任务训练只需要英语中的标记训练样本，因此不需要目标语言中的此类样本，这使得它适用于比有标记数据的语言多得多的语言。人类的评估表明，大多数这样的样本在语法上是正确和合理的。实验结果表明，我们提出的方法可以在XQuAD数据集上获得较大的增益，减少了不同语言上较小QA模型的零拍和监督性能之间的差距。