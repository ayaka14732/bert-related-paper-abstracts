超参数化变压器网络在各种自然语言处理任务中取得了最新成果，如机器翻译、语言建模和问答。这些模型包含数亿个参数，需要大量计算，并且容易过度拟合。在这项工作中，我们探索LayerDrop，一种结构化的辍学形式，它在训练期间具有正则化效果，并允许在推理时进行有效的修剪。特别是，我们表明，可以从一个大型网络中选择任意深度的子网络，而无需对其进行微调，并且对性能的影响有限。我们通过改进机器翻译、语言建模、摘要、问答和语言理解基准的最新技术，证明了我们方法的有效性。此外，我们还表明，与从头开始的训练或使用蒸馏相比，我们的方法可以得到更高质量的小的类伯特模型。