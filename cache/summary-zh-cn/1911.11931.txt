在大量原始文本数据上训练的语境化表征对自然语言处理任务（包括问答和阅读理解）有显著的改善。有研究表明，句法、语义和词义知识包含在这些表示中，这解释了为什么它们有利于这些任务。然而，对语境化表征中包含的常识知识的研究相对较少，语境化表征对于人类的问题回答和阅读理解至关重要。我们通过在七个具有挑战性的基准上测试GPT、BERT、XLNet和RoBERTa的常识能力，发现语言建模及其变体是提升模型常识能力的有效目标，而双向上下文和更大的训练集是额外的。此外，我们还发现，目前的模型在需要更多必要推理步骤的任务上表现不佳。最后，我们通过制作双重测试用例来测试模型的稳健性，这些测试用例相互关联，因此一个样本的正确预测应该导致另一个样本的正确预测。有趣的是，这些模型显示了对这些测试用例的混淆，这表明他们从表面而不是深层次学习常识。我们公开发布了一个名为CATs的测试集，用于未来的研究。