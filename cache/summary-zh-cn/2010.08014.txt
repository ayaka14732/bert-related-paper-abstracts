神经抽象摘要模型是灵活的，可以产生连贯的摘要，但有时不可靠，难以控制。虽然以前的研究试图提供不同类型的指导来控制输出和提高忠诚度，但不清楚这些策略之间如何进行比较和对比。在本文中，我们提出了一个通用的、可扩展的引导式摘要框架（GSum），该框架可以有效地将不同类型的外部引导作为输入，并在不同的种类上进行了实验。实验表明，该模型是有效的，当使用突出显示的句子作为指导时，在4个流行的摘要数据集上根据ROUGE实现了最先进的性能。此外，我们还展示了我们的指导模型可以生成更可靠的摘要，并展示了不同类型的指导如何生成质量不同的摘要，从而为学习模型提供了一定程度的可控性。