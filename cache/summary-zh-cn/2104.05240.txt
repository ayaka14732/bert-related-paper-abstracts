Petroni等人（2019年）证明，通过将世界事实表示为完形填空式提示，可以从预先训练的语言模型中检索世界事实，并将模型的预测精度解释为其编码的事实信息量的下限。随后的工作试图通过搜索更好的提示，使用一组不相交的事实作为训练数据来收紧估计。在这项工作中，我们做出了两个互补的贡献，以更好地理解这些事实探测技术。首先，我们提出OptiPrompt，这是一种在连续嵌入空间中直接优化的新方法。我们发现，这种简单的方法能够预测LAMA基准中另外6.4%的事实。其次，我们提出了一个更重要的问题：我们真的能将这些探测结果解释为下限吗？这些快速搜索方法是否也可以从训练数据中学习？我们发现，有些令人惊讶的是，这些方法使用的训练数据包含潜在事实分布的某些规律性，所有现有的提示方法，包括我们的方法，都能够利用它们进行更好的事实预测。我们进行了一组控制实验，将“学习”与“学习回忆”分开，提供了不同提示可以揭示预训练语言模型的更详细的图片。