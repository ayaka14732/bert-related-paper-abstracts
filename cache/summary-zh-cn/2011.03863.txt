最近在预先训练的神经语言建模方面的发展已经导致了常识性问答基准的准确性飞跃。然而，人们越来越担心模型过于适合特定任务，而没有学习利用外部知识或执行一般语义推理。相比之下，零炮评估显示了作为模型一般推理能力更稳健的衡量标准的前景。在本文中，我们提出了一个新的神经符号框架，用于跨常识任务的零炮问答。在一系列假设的指导下，该框架研究如何将各种预先存在的知识资源转化为对预培训模型最有效的形式。我们改变语言模型、培训制度、知识来源和数据生成策略，并衡量它们在任务中的影响。在前人工作的基础上，我们设计并比较了四种限制性干扰取样策略。我们提供了五个常识性问答任务的实证结果，数据来自五个外部知识资源。我们发现，虽然单个知识图更适合于特定任务，但全局知识图在不同任务中带来一致的收益。此外，保留任务结构以及生成公平且信息丰富的问题都有助于语言模型更有效地学习。