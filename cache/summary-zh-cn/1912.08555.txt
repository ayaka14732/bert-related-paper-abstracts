传统上，神经排序模型是在一系列随机批次上进行训练，从整个训练集中均匀取样。最近的研究表明，课程学习可以通过在训练过程中从易到难的批次进行非均匀采样，从而提高神经模型的有效性。在神经信息检索（IR）的背景下，课程学习尚未探索，因此（1）如何衡量训练实例的难度，以及（2）如何在训练过程中从容易的实例过渡到困难的实例尚不清楚。为了解决这两个挑战并确定课程学习是否有利于神经排名模型，我们需要大规模的数据集和检索任务，以便我们进行广泛的实验。为此，我们求助于会话响应排序的任务：根据会话历史对响应进行排序。为了应对挑战（1），我们探索了基于不同输入空间的评分函数来衡量对话的难度。为了应对挑战（2），我们评估了不同的起搏功能，这些功能决定了我们从容易的情况到困难的情况的速度。我们发现，总的来说，通过对训练数据进行智能排序（即通过执行课程学习），我们可以将检索效率提高2%。