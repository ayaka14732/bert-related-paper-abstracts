在本文中，我们介绍了XGLUE，这是一个新的基准数据集，可用于使用多语言和双语语料库训练大规模跨语言预训练模型，并评估其在不同跨语言任务集上的性能。与GLUE（Wang et al.，2019）相比，XGLUE具有两个主要优势：（1）它提供了11个多样化的任务，涵盖自然语言理解和生成场景；（2） 对于每个任务，它都提供多种语言的标记数据。我们扩展了最近的跨语言预训练模型Unicoder（Huang et al.，2019），以涵盖理解和生成任务，该模型在XGLUE上作为一个强大的基线进行评估。我们还评估了多语言BERT、XLM和XLM-R的基本版本（12层），以进行比较。