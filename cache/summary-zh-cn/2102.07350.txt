将大型生成性语言模型映射到监督任务的主流方法可能无法充分探测模型的新功能。使用GPT-3作为一个案例研究，我们表明0-shot提示可以显著优于少数shot提示。我们建议，在这些情况下，少数镜头示例的功能最好描述为定位已学习的任务，而不是元学习。这种分析促使人们重新思考提示在控制和评估强大的语言模型中的作用。在这项工作中，我们讨论了提示编程的方法，强调了从自然语言的角度考虑提示的有用性。我们探讨了利用叙事和文化锚定的能力来编码细微差别的意图的技术，以及鼓励在做出裁决之前将问题分解为组件的技术。受这一更全面的提示编程理论的启发，我们还引入了元提示的思想，它为模型播种种子，为一系列任务生成自己的自然语言提示。最后，我们将讨论如何将这些与语言模型交互的更通用方法整合到现有和未来的基准测试和实际应用中。