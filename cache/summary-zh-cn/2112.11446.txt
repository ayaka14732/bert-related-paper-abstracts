语言建模通过利用大量人类书面知识库来更好地预测和理解世界，从而向智能通信系统迈出了一步。在本文中，我们分析了基于Transformer的语言模型在各种模型尺度上的性能——从具有数千万个参数的模型到被称为Gopher的2800亿个参数的模型。这些模型在152项不同任务中进行评估，在大多数任务中实现了最先进的性能。在阅读理解、事实核查和有毒语言识别等领域，从量表中获得的收益最大，但逻辑和数学推理的收益较小。我们提供了对训练数据集和模型行为的整体分析，涵盖了模型规模与偏差和毒性的交叉点。最后，我们讨论了语言模型在人工智能安全和减少下游危害方面的应用。