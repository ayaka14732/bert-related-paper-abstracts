知识图（KG）包含关于世界知识、实体和关系的丰富信息。因此，它们可以成为现有预训练语言模型的重要补充。然而，如何将KG中的信息有效地集成到语言建模中仍然是一个挑战。理解知识图需要相关的上下文。我们提出了一个新的联合预训练框架JAKET，对知识图和语言进行建模。知识模块和语言模块提供相互帮助的基本信息：知识模块为文本中的实体生成嵌入，而语言模块为图形中的实体和关系生成上下文感知的初始嵌入。我们的设计使预先训练的模型能够很容易地适应新领域中看不见的知识图。在几个具有知识意识的NLP任务上的实验结果表明，我们提出的框架通过有效地利用语言理解中的知识实现了优异的性能。