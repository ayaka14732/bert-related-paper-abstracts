Transformer成为了最先进的转换模型，但还没有很好地研究每个中间组件对模型性能的贡献，这对设计最佳体系结构提出了重大挑战。在这项工作中，我们通过从不同角度评估培训变压器模型中单个组件（子层）的影响来弥合这一差距。跨语言对、训练策略和模型能力的实验结果表明，某些成分始终比其他成分更重要。我们还报告了一些有趣的发现，这些发现可能有助于人类更好地分析、理解和改进变压器模型。基于这些观察，我们进一步提出了一种新的训练策略，通过区分训练中不重要的部分来提高翻译性能。