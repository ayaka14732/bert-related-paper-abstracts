基于转换器的预训练语言模型BERT有助于提高许多自然语言处理（NLP）任务的最新性能。使用相同的架构和参数，我们开发并评估了一个名为BERTje的单语荷兰语BERT模型。与包括荷兰语但仅基于维基百科文本的多语言BERT模型相比，BERTje基于一个包含24亿代币的大型多样化数据集。BERTje在下游NLP任务（词性标注、命名实体识别、语义角色标注和情感分析）上始终优于同等大小的多语言BERT模型。我们预先培训的荷兰伯特模型在https://github.com/wietsedv/bertje.