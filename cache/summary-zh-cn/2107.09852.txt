最近的工作表明，成功地将预先训练好的模型（如BERT）结合起来，以改进NLP系统。然而，现有的预先训练的模型缺乏因果知识，这使得今天的NLP系统无法像人类一样思考。在本文中，我们研究了将因果知识注入预训练模型的问题。有两个基本问题：1）如何从非结构化文本中收集各种因果对粒度；2） 如何有效地将因果知识注入预先训练的模型。为了解决这些问题，我们从以前的研究中扩展了因果关系的概念，并在各种数据集上进行实验以评估其有效性。此外，我们采用了一种基于正则化的方法，在注入因果知识的同时，用一个额外的正则化项来保存已经学习的知识。在7个数据集（包括4个因果对分类任务、2个因果QA任务和1个因果推理任务）上进行的大量实验表明，因果分析捕获了丰富的因果知识，并优于所有预先训练的基于模型的最新方法，实现了一个新的因果推理基准。