虽然最近的模型在许多NLP数据集上取得了人类水平的分数，但我们观察到它们对输入的微小变化相当敏感。作为通过构造全新示例的训练集来解决此问题的标准方法的替代方法，我们建议通过示例的最小扰动来实现。具体来说，我们的方法包括首先收集一组种子示例，然后应用人类驱动的自然扰动（与基于规则的机器扰动相反），这通常也会改变黄金标签。局部扰动的优点是，与写出全新的例子相比，创建局部扰动相对更容易（因此也更便宜）。为了评估这种现象的影响，我们考虑最近的问题回答数据集（BOOLQ），并研究我们的方法的好处作为扰动成本比的函数，扰动现有问题的相对成本与从头创建新的成本。我们发现，当自然扰动的创建成本较低时，使用它们训练模型更为有效：此类模型表现出更高的鲁棒性和更好的泛化性，同时保留了原始BoolQ数据集的性能。