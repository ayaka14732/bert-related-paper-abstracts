在大型语料库上训练的语言模型已被证明对NLP有用。作为固定的人工制品，它们已成为深入研究的对象，许多研究人员“探索”了它们获得和易于证明的语言抽象、事实和常识知识以及推理能力的程度。在这一系列工作的基础上，我们考虑了一个新的问题：语言类型的知识，学习，当（前）培训时，他们获得的知识类型？我们使用RoBERTa作为案例研究，绘制了跨迭代的探测性能图。我们的发现包括：跨领域快速、稳定、稳健地获取语言知识。事实和常识更慢，对领域更敏感。一般来说，推理能力不是稳定获得的。随着新的数据集、训练前协议和探针的出现，我们相信跨时间分析的探针可以帮助研究人员理解这些模型所经历的复杂、混合的学习，并指导我们更快地实现必要学习的更有效方法。