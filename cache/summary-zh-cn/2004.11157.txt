预训练单词嵌入的成功促使其在生物医学领域的任务中使用。BERT语言模型在命名实体识别（NER）和语义文本相似性（STS）等任务的标准性能指标方面取得了显著的成果，这在NLP领域取得了重大进展。然而，目前尚不清楚这些系统在法律或医疗等关键领域是否运行良好。因此，在这项工作中，我们针对两个著名的医学NER和STS数据集提出了一个对抗性评估方案。我们提出了两种攻击类型，其灵感来自自然拼写错误和人类造成的拼写错误。我们还提出了另一种使用医学术语同义词的攻击。在这些对抗性设置下，模型的准确性显著下降，我们量化了这种性能损失的程度。我们还表明，通过使用对抗性示例对模型进行训练，可以显著提高模型的鲁棒性。我们希望我们的工作将激励使用对抗性示例来评估和开发模型，从而增强医疗任务的鲁棒性。