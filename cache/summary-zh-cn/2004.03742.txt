大规模语言表示模型（如BERT）的最新进展改善了许多NLP任务的最新性能。同时，字符级中文NLP模型，包括用于中文的BERT，也证明了它们的性能优于现有的模型。在本文中，我们表明，然而，这种基于伯特的模型在字符级对抗攻击下是脆弱的。我们提出了一种针对基于BERT分类器的中文字符级攻击方法。本质上，我们在嵌入空间中生成字符级的“小”扰动，并指导字符替换过程。大量实验表明，基于该攻击的中文新闻数据集的分类准确率从91.8%下降到0%，平均操作少于2个字符。人类评估也证实，我们生成的中国对抗性示例几乎不会影响人类在这些NLP任务中的表现。