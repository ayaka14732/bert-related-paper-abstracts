最近关于训练开放领域问答（OpenQA）神经检索器的工作采用了有监督和无监督两种方法。然而，目前尚不清楚无监督和有监督的方法如何最有效地用于神经检索器。在这项工作中，我们系统地研究了猎犬的预训练。我们首先提出了一种无监督的预训练方法，该方法使用反完形填空任务和掩蔽显著跨度，然后使用问题上下文对进行监督微调。在自然问题和TriviaQA数据集的前20名检索准确率中，这种方法比以前的最佳结果绝对提高了2+分。我们还探讨了在OpenQA模型中对读卡器和检索器组件进行端到端监督培训的两种方法。在第一种方法中，读者分别考虑每个检索到的文档，而在第二种方法中，读者一起考虑所有检索到的文档。我们的实验证明了这些方法的有效性，因为我们获得了最新的结果。在自然问题数据集上，我们获得了84的前20名检索准确率，比最近的DPR模型提高了5个点。此外，我们在答案提取方面取得了良好的效果，比最近的REALM和RAG等模型高出3+个百分点。我们进一步将端到端培训扩展到大型机型，并显示出与小型机型相比性能的持续提升。