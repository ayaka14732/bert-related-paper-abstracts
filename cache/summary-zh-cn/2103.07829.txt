大规模图像-文本对的视觉语言预训练（VLP）在跨模态表征的学习方面取得了快速的进展。现有的预训练方法要么直接将特征级的图像表示和文本表示连接起来作为单个流转换器的输入，要么使用两个流交叉模式转换器将图像-文本表示在高级语义空间对齐。在真实的图像-文本数据中，我们观察到，一些图像-文本对很容易在两种模式上对齐简单语义，而其他图像-文本对可能在更高级别的抽象后相关。因此，在本文中，我们提出了一种新的预训练方法SemVLP，它将图像和文本表示之间的低层和高层语义联合起来。该模型采用两种流行的方式进行迭代预训练：单流预训练以在细粒度特征级别上对齐，两流预训练以对齐高级语义，方法是使用带有可插拔跨模态注意模块的共享转换器网络。在四个成熟的视觉语言理解任务上进行了大量的实验，以证明所提出的SemVLP在将跨模态表示与不同语义粒度对齐方面的有效性。