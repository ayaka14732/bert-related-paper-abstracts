像CLIP这样的对比模型可以学习捕捉语义和风格的图像的鲁棒表示。为了利用这些表示生成图像，我们提出了一个两阶段模型：先验生成给定文本标题的剪辑图像嵌入，解码器生成以图像嵌入为条件的图像。我们表明，显式生成图像表示提高了图像多样性，同时减少了照片真实性和字幕相似性的损失。我们的解码器以图像表示为条件，也可以产生图像的变体，保留其语义和风格，同时改变图像表示中缺少的非必要细节。此外，剪辑的联合嵌入空间允许以零拍方式进行语言引导的图像处理。我们使用扩散模型作为译码器，并对自回归和扩散模型进行了实验，发现后者在计算上更高效，并产生了更高质量的样本。