在本文中，我们提出了基于耐心的早期退出，这是一种简单而有效的推理方法，可以作为一种即插即用技术，同时提高预训练语言模型（PLM）的效率和鲁棒性。为了实现这一点，我们的方法将内部分类器与PLM的每一层相耦合，并在内部分类器的中间预测在预定义的步骤数保持不变时动态停止推理。我们的方法提高了推理效率，因为它允许模型使用较少的层进行预测。同时，一个ALBERT模型的实验结果表明，与现有的早期退出方法相比，我们的方法可以通过防止过度思考和利用多个分类器进行预测来提高模型的准确性和鲁棒性，从而获得更好的准确性和速度权衡。