问答（QA）任务的提出使用了多种格式，如提取跨度选择、多项选择等。这导致了格式专门化模型，甚至导致QA社区中的隐式划分。我们认为，这种界限是人为的，也许是不必要的，因为我们试图教授的推理能力不受形式的制约。作为证据，我们使用语言建模的最新进展构建了一个预先训练好的QA模型UnifiedQA，它在跨越4种不同格式的17个QA数据集上表现得出奇地好。UNIFIEDQA与9个不同的模型相匹配，这些模型是在单个数据集上进行训练的。即使面对12个观察到的格式的看不见的数据集，UnifiedQA的表现也出人意料地好，从其非格式的训练数据中显示出了强大的泛化能力。最后，只需将这个预先训练好的QA模型微调为专门的模型，就可以在6个数据集上实现最新水平，从而将UnifiedQA建立为构建QA系统的强大起点。