我们提出了一种简化的、任务无关的多模式预训练方法，可以接受视频或文本输入，也可以同时接受视频或文本输入，用于各种终端任务。现有的预培训是针对特定任务的，通过采用需要两种模式的单个跨模式编码器，限制其用于检索式结束任务，或采用两个单模式编码器进行更复杂的多任务学习，限制早期跨模式融合。相反，我们引入了新的预训练掩蔽方案，可以更好地跨模式混合（例如，通过强制文本掩蔽来预测最近的视频嵌入），同时还保持可分性（例如，有时需要单峰预测，而不使用所有输入）。实验结果表明，与以前的任何方法相比，在更广泛的任务范围内，该方法具有很强的性能，通常优于特定任务的预训练。该守则可于https://github.com/pytorch/fairseq/tree/main/examples/MMPT.