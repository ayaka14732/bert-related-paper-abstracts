最近的视觉语言（VL）研究表明，通过使用转换器模型从海量图像-文本对中学习通用表示，然后对下游VL任务进行微调，取得了显著的进展。虽然现有的研究集中于通过大型预训练模型实现高精度，但构建轻量级模型在实践中具有很大的价值，但探索较少。在本文中，我们提出了一个更小、更快的VL模型MiniVLM，它可以在各种下游任务（如较大的对应任务）上进行微调，并具有良好的性能。MiniVLM由两个模块组成，一个是视觉特征提取模块，一个是基于转换器的视觉语言融合模块。我们设计了一个两阶段高效的特征提取程序（TEE），其灵感来自于一阶段高效的ET网络，与基线模型相比，显著降低了视觉特征提取的时间成本$95\%$。在比较了不同的紧凑型BERT模型后，采用MiniLM结构降低了变压器模块的计算量。此外，我们通过添加700万美元的开放图像数据来改进MiniVLM预训练，这些数据由最先进的字幕模型伪标记。我们还使用从强标记模型获得的高质量图像标记进行预训练，以增强跨模态对齐。大型模型离线使用，不会增加微调和推断的任何开销。通过上述设计选择，我们的MiniVLM将模型尺寸减少了$73\%$，推理时间成本减少了$94\%$，同时能够在多个VL任务上保持$94-97\%$的准确性。我们希望MiniVLM有助于将最先进的VL研究用于边缘应用。