预训练的BERT模型在自然语言处理的广泛任务中达到了卓越的技术水平。为了解决性别代词消解任务中的性别偏见问题，本文提出了一种基于预训练BERT的神经网络模型。该模型是一种提及分数分类器，使用无参数的注意机制计算实体广度的上下文表示，并使用向量表示代词和实体之间的三重语义相似度。在性别代词分辨任务的第1阶段，该模型的一个变体，通过微调方法训练，在训练集的5倍交叉验证中将多类对数损失减少到0.3033，在测试集将多类对数损失减少到0.2795。此外，该变体在任务第二阶段以0.17289分获得第二名。本文中的代码可从以下网址获得：https://github.com/ziliwang/MSnet-for-Gendered-PronounResolution