经过预训练的转换器现在在自然语言处理中无处不在，但尽管它们具有高端任务性能，但从经验上看，对于它们是否经过校准知之甚少。具体地说，这些模型的后验概率是否提供了一个精确的经验度量，来衡量模型在给定示例中的正确性？在这项工作中，我们关注伯特和罗伯塔，并分析他们在三个任务中的校准：自然语言推理、释义检测和常识推理。对于每个任务，我们考虑域和挑战性的域外设置，其中模型面临更多的例子，他们应该是不确定的。我们发现：（1）当使用开箱即用时，预训练模型在域内进行校准，与基线相比，其域外校准误差可低3.5倍；（2） 温度标度在进一步降低域内校准误差方面是有效的，而使用标签平滑故意增加经验不确定度有助于在域外校准后验误差。