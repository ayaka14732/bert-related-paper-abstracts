我们对通用文本表示的分层伯特激活进行了系统研究，以了解它们捕获的语言信息以及它们在不同任务中的可传递性。句子层次的嵌入在SentEval的下游任务和探测任务中根据两种最先进的模型进行评估，而在学习排序问题设置下，在四个问答（QA）数据集上评估段落层次的嵌入。预训练的BERT模型嵌入在语义相似性和句子表面信息探测任务中表现不佳。对自然语言推理数据进行微调可以极大地提高嵌入的质量。组合来自不同层的嵌入可以进一步提高性能。在通道水平上，BERT嵌入在factoid QA数据集上显著优于BM25基线，但在非factoid数据集上的表现不如BM25。对于所有QA数据集，基于嵌入的方法和域内微调BERT（我们报告了两个数据集的最新研究结果）之间存在差距，这表明问答对之间的深度交互对于这些困难任务至关重要。