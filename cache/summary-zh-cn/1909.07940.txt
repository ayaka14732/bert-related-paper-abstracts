理解和处理数字（算术）的能力对于许多复杂的推理任务至关重要。目前，大多数NLP模型以与其他令牌相同的方式处理文本中的数字——它们将数字作为分布式向量嵌入。这是否足以证明算术性？我们首先研究DROP数据集上最先进的问答模型的数值推理能力。我们发现该模型在需要数值推理的问题上表现出色，也就是说，它已经捕捉到了计算能力。为了了解这种能力是如何产生的，我们探索了合成列表最大值、数字解码和加法任务上的令牌嵌入方法（例如，BERT、手套）。在标准嵌入中自然会出现令人惊讶的计算能力。例如，GloVe和word2vec可以精确地编码最大为1000的数字的大小。此外，字符级的嵌入更加精确——埃尔莫在所有预先训练的方法中都能捕捉到最好的运算能力——但使用子单词单位的伯特则不那么精确。