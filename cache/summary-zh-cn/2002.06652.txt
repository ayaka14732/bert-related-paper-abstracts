句子嵌入是自然语言处理（NLP）中的一个重要研究课题，因为它可以将知识传递给下游任务。同时，一种被称为BERT的上下文化单词表示法在很多NLP任务中都达到了最先进的性能。然而，从基于BERT的词模型生成高质量的句子表示是一个开放的问题。先前的研究表明，不同层次的BERT具有不同的语言特性。这使我们能够跨层融合信息，以找到更好的句子表示。在这项工作中，我们研究了深层语境化模型中单词表示的分层模式。然后，通过对单词表示所跨越的空间进行几何分析，对基于BERT的单词模型进行剖析，提出了一种新的句子嵌入方法。它被称为SBERT-WK方法。SBERT-WK无需进一步培训。我们评估了SBERT-WK的语义-文本相似度和下游监督任务。此外，本文还提出了十个句子层次的探测任务，用于详细的语言分析。实验表明，SBERT-WK实现了最先进的性能。我们的代码是公开的。