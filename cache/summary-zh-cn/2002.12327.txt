基于Transformer的模型推动了NLP许多领域的最新发展，但我们对其成功背后的原因的理解仍然有限。本文是对流行的伯特模型的150多项研究的第一次调查。我们回顾了有关BERT如何工作、它学习什么样的信息以及如何表示这些信息、对其训练目标和体系结构的常见修改、过参数化问题和压缩方法的知识现状。然后，我们概述了未来研究的方向。