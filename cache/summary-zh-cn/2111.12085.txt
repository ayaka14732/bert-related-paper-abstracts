在本文中，我们提出了UNICORN，一种视觉语言（VL）模型，它将文本生成和包围盒预测统一到一个单一的体系结构中。具体来说，我们将每个框量化为四个离散的框标记，并将它们序列化为一个序列，可以与文本标记集成。我们将所有VL问题描述为一个生成任务，其中目标序列由集成的文本和框标记组成。然后，我们训练变压器编码器-解码器以自回归的方式预测目标。有了这样一个统一的框架和输入输出格式，UNICORN在7个VL基准上实现了与任务相关的最新水平相当的性能，包括视觉基础、基础字幕、视觉问答和图像字幕任务。当使用多任务微调进行训练时，独角兽可以用一组参数处理不同的VL任务，从而跨越下游任务边界。我们表明，使用单一模型不仅可以节省参数，还可以进一步提高模型在某些任务上的性能。最后，UNICORN展示了推广到ImageNet对象定位等新任务的能力。