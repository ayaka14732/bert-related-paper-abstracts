利用未标记文本进行广泛的自我监督预训练的语言模型，最近已证明在各种语言理解任务中显著提高了最先进的表现。然而，目前尚不清楚是否以及如何利用这些最新模型来进行基于文本的建议。在这项工作中，我们介绍了RecoBERT，一种基于BERT的方法，用于学习基于文本的项目推荐的目录专用语言模型。我们建议采用新的训练和推理程序，对项目之间的相似性进行评分，而不需要项目相似性标签。训练和推理技术都旨在利用文本目录的未标记结构，并尽量减少它们之间的差异。通过在推理过程中加入四个分数，雷科伯特可以比其他技术更准确地推断基于文本的项目间相似性。此外，我们还引入了一个新的语言理解任务，使用基于专业葡萄酒评论的相似性进行葡萄酒推荐。作为另一项贡献，我们发布了由人类葡萄酒专家制作的带注释的推荐数据集。最后，我们评估了雷科伯特，并将其与各种关于葡萄酒和时尚推荐任务的最新NLP模型进行了比较。