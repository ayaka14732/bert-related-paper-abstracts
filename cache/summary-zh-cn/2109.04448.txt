预训练视觉和语言BERTs旨在学习结合两种模式信息的表征。我们提出了一种基于跨模态输入的诊断方法，以评估这些模型实际集成跨模态信息的程度。该方法涉及基于跨模态接地对准，完全或选择性地烧蚀一个模态的输入，并评估另一模态的模型预测性能。模型性能通过反映模型预训练目标的特定于模态的任务来衡量（例如，文本的蒙面语言建模）。当一个模态缺少输入时，已经学会使用这两种模态构造跨模态表示的模型的性能预计会更差。我们发现，最近提出的模型在去除视觉信息时预测文本比在去除文本时预测视觉对象类别相对困难得多，这表明这些模型不是对称的交叉模态模型。