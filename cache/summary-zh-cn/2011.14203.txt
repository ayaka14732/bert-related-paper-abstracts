基于转换器的语言模型（如BERT）为许多自然语言处理（NLP）任务提供了显著的准确性改进。然而，它们巨大的计算和内存需求使得它们难以部署到具有严格延迟要求的资源受限边缘平台。我们介绍了EdgeBERT，一种用于多任务NLP延迟感知能量优化的深入算法硬件协同设计。EdgeBERT采用基于熵的早期退出预测，以便在句子粒度上执行动态电压频率缩放（DVFS），以便在遵守规定的目标延迟的同时将能耗降至最低。通过采用自适应注意广度、选择性网络修剪和浮点量化的校准组合，计算和内存占用开销得到进一步缓解。此外，为了最大限度地发挥这些算法在常开和中间边缘计算环境中的协同效益，我们专门设计了一个12nm可扩展硬件加速器系统，集成了快速开关低压差稳压器（LDO）、全数字锁相环（ADPLL）以及，高密度嵌入式非易失性存储器（ENVM），其中小心地存储共享多任务参数的稀疏浮点位编码。总之，与Nvidia Jetson Tegra X2移动GPU上的传统无提前停止推理、无延迟无限制提前退出方法和CUDA自适应相比，EdgeBERT硬件系统上的延迟感知多任务NLP推理加速产生的能量分别降低了7倍、2.5倍和53倍。