像BERT（Delvin等人，2019年）这样经过深入训练的情境化编码器在一系列下游任务中表现出卓越的性能。最近的一项探索性研究调查了这些模型在训练前所隐含的语言知识。虽然大多数探究工作是在任务层面上进行的，但语言任务很少是统一的，可以用各种形式来表示。因此，任何以语言学为基础的探究性研究都不可避免地要遵循用于注释底层数据的形式主义。形式主义的选择会影响探测结果吗？为了调查，我们在角色语义学中进行了深入的跨形式主义层探索性研究。我们发现，根据形式主义，BERT对语义角色和原型角色信息的编码在语言学上有意义的差异，并证明层探测可以检测相同语言形式主义实现之间的细微差异。我们的研究结果表明，语言形式主义与常用的跨任务和跨语言实验环境一样，是探究研究的一个重要维度。