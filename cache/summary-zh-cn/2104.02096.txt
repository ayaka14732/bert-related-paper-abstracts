尽管在视觉语言（VL）表征的预训练方面取得了令人兴奋的进展，但很少有人渴望使用小型VL模型。在本文中，我们研究了知识蒸馏（KD），以有效地将基于变压器的大型VL模型压缩为小型VL模型。主要的挑战来自于从教师和学生的不同检测器中提取的不一致的区域视觉标记，导致隐藏表征和注意力分布的错位。为了解决这个问题，我们使用来自学生检测器的相同区域建议对教师进行再培训和调整，而特征来自教师自己的对象检测器。通过对齐网络输入，适应的教师能够通过中间表示传递知识。具体地说，我们使用均方误差损失来模拟转换器块内的注意分布，并通过与存储在样本队列中的否定表示进行对比来呈现令牌噪声对比损失来对齐隐藏状态。为此，我们表明，我们提出的蒸馏显著提高了小型VL模型在图像字幕和视觉问答任务上的性能。它在苹果酒中的COCO字幕得分达到120.8分，比未蒸馏的同类产品提高了5.1分；VQA 2.0的准确度为69.8，比基线增加0.8。我们的大量实验和烧蚀证实了VL蒸馏在预训练和微调阶段的有效性。