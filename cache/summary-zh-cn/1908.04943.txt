本文使用最新的上下文嵌入框架BERT，为词性标注、句法分析和语义分析这三项任务提供了最新的模型。对于每个任务，我们首先复制和简化当前最先进的方法，以提高其模型效率。然后，我们使用BERT生成的令牌嵌入来评估这三个任务的简化方法。我们的实验使用了12个中英文数据集。BERT模型的平均表现优于之前表现最好的模型2.5%（最显著的情况下为7.5%）。此外，还利用自我注意对伯特嵌入的影响进行了深入分析，这有助于理解这种丰富的表达方式。所有模型和源代码都可以公开获取，以便研究人员能够改进并利用它们为下一个十年建立强有力的基线。