神经网络最近在各种具有挑战性的自然语言处理（NLP）任务上取得了人类水平的性能，但众所周知，很难理解神经网络为什么会产生特定的预测。在本文中，我们利用Raffel et al.（2019）提出的文本到文本框架来训练语言模型，以便在预测的同时输出自然的文本解释。关键的是，这不需要修改损失函数或训练和解码过程——我们只需训练模型，在生成（自然文本）预测后输出解释。我们表明，这种方法不仅在可解释性基准上获得了最新的结果，而且允许从有限的一组标记解释中学习，并在数据集之间传递合理化能力。为了促进再现性和未来的工作，我们发布了用于训练模型的代码。