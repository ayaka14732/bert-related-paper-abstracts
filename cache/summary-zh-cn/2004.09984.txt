针对离散数据（如文本）的对抗性攻击已被证明比连续数据（如图像）更具挑战性，因为使用基于梯度的方法很难生成对抗性样本。目前成功的文本攻击方法通常在字符或单词层面上采用启发式替换策略，在大量可能的替换组合空间中寻找最优解，同时保持语义一致性和语言流畅性仍然是一个挑战。在本文中，我们提出了\textbf{BERT-Attack}，这是一种使用预先训练的蒙面语言模型生成对抗性样本的高质量和有效的方法，以BERT为例。我们在下游任务中将BERT与其微调模型和其他深度神经模型对立起来，这样我们就可以成功地误导目标模型进行错误预测。我们的方法在成功率和干扰百分比方面都优于最先进的攻击策略，同时生成的对抗性样本流畅且语义保持。此外，计算成本较低，因此可以进行大规模发电。该守则可于https://github.com/LinyangLee/BERT-Attack.