大多数使用长自然语言查询进行相似文本检索和排序的方法在某种程度上依赖于具有共同单词的查询和响应。最近，基于变换器的神经语言模型在文本检索和排序问题上的应用非常有前景，但仍然涉及一个两步过程，在这个过程中，首先通过基于词包的方法获得候选结果，然后通过神经变换器重新排序。在本文中，我们介绍了一种新的方法来有效地将神经变压器模型应用于相似文本的检索和排序，而无需基于初始词包的步骤。通过消除基于单词包的步骤，我们的方法能够准确地检索和排序结果，即使它们与查询没有共同的非停止词。我们通过使用来自转换器的双向编码器表示（BERT）来创建句子长度文本的矢量化表示，以及矢量最近邻搜索索引来实现这一点。我们演示了使用BERT来完成此任务的有监督和无监督方法。