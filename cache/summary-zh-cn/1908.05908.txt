在本文中，我们报告了2019年语言与智能挑战赛中信息提取任务的方法。我们将BERT纳入多头部选择框架，用于联合实体关系提取。该模型从三个角度扩展了现有方法。首先，采用BERT作为多头选择框架底部的特征提取层。我们通过在训练前引入语义增强任务来进一步优化训练前训练。第二，我们引入了一个大规模的百度白克语料库进行实体识别预训练，由于没有实际的命名实体标签，因此该语料库是每周监督学习的。第三，提出了软标签嵌入方法，有效地在实体识别和关系提取之间传递信息。结合这三个贡献，我们增强了多头选择模型的信息提取能力，并用单个模型在testset-1上实现了F1得分0.876。通过整合我们模型的四个变体，我们最终在testset-1上获得F1得分0.892（第一名），在testset-2上获得F1得分0.8924（第二名）。