CLIP的巨大成功（Radford等人，2021）促进了对比学习在视觉语言预训练中的研究和应用。在这项工作中，我们构建了一个大规模的中文图像文本对数据集，其中大多数数据都是从公开可用的数据集中检索的，我们在新数据集上预处理了中文CLIP模型。我们开发了5种不同大小的中国CLIP模型，参数范围从7700万到9.58亿。此外，我们提出了一种两阶段预训练方法，其中首先使用冻结的图像编码器对模型进行训练，然后对所有参数进行优化，以实现增强的模型性能。我们的综合实验表明，中国CLIP可以在零镜头学习和微调设置中在MUGE、Flickr30K CN和COCO-CN上实现最先进的性能，并且能够基于对ELEVATER基准的评估在零镜头图像分类中实现有竞争力的性能（Li等人，2022）。我们已经在https://github.com/OFA-Sys/Chinese-CLIP