对预先训练好的变压器模型进行微调已成为解决常见NLP任务的标准方法。现有的大多数方法都依赖于这种网络上的随机初始化分类器。我们认为，这种微调过程是次优的，因为预先训练的模型没有特定分类器标签的先验知识，而它可能已经学习了任务的内在文本表示。在本文中，我们介绍了一种新的评分方法，该方法以全文格式对合理性排序任务进行评分，并利用在训练前阶段调整的蒙面语言建模头。我们研究常识推理任务，其中模型必须对给定前提的一组假设进行排序，重点关注COPA、Swag、HellaSwag和常识QA数据集。通过利用我们的评分方法而不进行微调，我们能够产生与监督方法相当的强基线（例如，COPA测试准确率为80%）。此外，当直接对建议的评分函数进行微调时，我们表明，我们的方法在随机重新启动过程中提供了更稳定的训练阶段（例如，COPA测试精度的$\乘以10$标准偏差减少），并且需要比标准分类器方法更少的注释数据才能达到同等性能。