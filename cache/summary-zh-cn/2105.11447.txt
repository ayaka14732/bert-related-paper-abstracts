预训练语言模型（LMs）在许多任务中表现良好，即使是从几个例子中学习，但之前的工作使用了许多突出的例子来调整学习的各个方面，如超参数、训练目标和自然语言模板（“提示”）。在这里，我们评估了LMs在无法获得此类示例时的少数镜头能力，我们称之为真正的少数镜头学习。我们测试了两个模型选择标准，交叉验证和最小描述长度，用于在真少数镜头设置中选择LM提示和超参数。平均而言，两者的表现都略好于随机选择，也大大低于基于所举例子的选择。此外，选择标准通常更倾向于性能比随机选择的模型差得多的模型。即使考虑到我们在选择过程中模型真实性能的不确定性，以及改变计算量和用于选择的示例数量，我们也会发现类似的结果。总的来说，我们的研究结果表明，鉴于少数镜头模型选择的困难，先前的工作明显高估了LMs的真实少数镜头能力。