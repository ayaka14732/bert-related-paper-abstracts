在过去几年中，基于变压器的模型取得了成功，其规模和应用场景继续大幅增长。变压器模型的现状越来越多样化：模型大小千差万别，最大的有1000亿个参数；由于混合专家引入的稀疏性，模型特征不同；目标应用场景可以是延迟关键的或面向吞吐量的；部署硬件可以是具有不同类型的存储器和存储等的单GPU或多GPU系统。随着变压器模型的日益多样化和快速发展，设计高性能和高效的推理系统极具挑战性。在本文中，我们提出了DeepSpeed推理，这是一种用于变压器模型推理的综合系统解决方案，以解决上述挑战。DeepSpeed推理包括（1）多GPU推理解决方案，当密集和稀疏变换器模型适合聚合GPU内存时，以及（2）异构推理解决方案，其利用CPU和NVMe存储器以及GPU存储器和计算。对于面向延迟的场景，DeepSpeed Inference比最先进的延迟降低了7.3倍，对于面向吞吐量的场景，吞吐量提高了1.5倍以上。此外，它通过利用数百个GPU，在实时延迟约束下实现了万亿参数规模的推理，这是前所未有的推理规模。它可以推断出比仅GPU解决方案大25倍的模型，同时提供84 TFLOPS的高吞吐量（超过A6000峰值的50%）。