最近的NLP任务从预先训练的语言模型（LM）中受益匪浅，因为它们能够对各个方面的知识进行编码。然而，目前的LM评估侧重于下游绩效，因此缺乏全面检查他们在哪些方面以及在多大程度上编码了知识。本文通过提出四项关于句法、语义、常识和事实知识的任务来解决这两个问题，总计39308美元，涵盖汉语的语言和世界知识。在整个实验过程中，我们的探针和知识数据被证明是评估预先训练的中国LMs的可靠基准。我们的工作公开于https://github.com/ZhiruoWang/ChnEval.