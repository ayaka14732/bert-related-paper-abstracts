大型语言模型在一系列任务中实现了最先进的准确性。然而，有效地训练这些模型具有挑战性，原因有两个：a）GPU内存容量有限，无法在多GPU服务器上安装大型模型；b）训练这些模型所需的计算操作数量可能导致训练时间过长。因此，提出了新的模型并行方法，如张量并行和流水线并行。不幸的是，这些方法的简单使用导致了数千个GPU的根本性扩展问题，例如，由于昂贵的跨节点通信或设备花费大量时间等待其他设备取得进展。在本文中，我们展示了如何组合不同类型的并行方法（张量、管道和数据并行），以扩展到数千个GPU和具有数万亿参数的模型。我们对流水线并行技术进行了综述，并提出了一种新的交错流水线并行调度方案，该方案可将吞吐量提高10%+，内存占用与现有方法相当。我们定量地研究了张量、管道和数据并行性之间的权衡，并提供了如何配置大型模型的分布式训练的直观性。我们的方法允许我们在3072 GPU上以502 petaFLOP/s的速度对1万亿个参数的模型执行训练迭代，每个GPU的吞吐量达到理论峰值的52%。我们的代码是开源的https://github.com/nvidia/megatron-lm.