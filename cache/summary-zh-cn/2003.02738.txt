在许多学习框架中，根据一组参考来衡量生成序列的质量是一个中心问题，无论是计算分数、分配奖励还是进行区分。尽管在模型架构方面取得了巨大的进步，但独立于参考数量的度量仍然基于n-gram估计。我们证明了底层操作，计数字和比较计数，可以提升到嵌入字和比较嵌入。对BERT嵌入的深入分析从经验上表明，上下文嵌入可以用来捕获所需的依赖关系，同时通过适当的修剪和平滑技术保持必要的可伸缩性。我们将无条件生成转化为强化学习问题，并表明在这种具有挑战性的环境中，我们的奖励函数确实比n-gram奖励提供了更有效的学习信号。