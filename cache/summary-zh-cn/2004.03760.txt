解纠缠是一个多个对话同时发生在同一频道的问题，听者应该决定哪一个话语是他将回应的对话的一部分。我们提出了一个新的模型，名为DialBERT（DialBERT），它将本地和全局语义集成到单个消息流中，以分离混合在一起的会话。我们使用BERT在话语层捕获每个话语对中的匹配信息，并使用BiLSTM聚合和合并上下文层信息。根据F1成绩，与BERT相比，参数仅增加了3%，提高了12%。该模型在IBM提出的一个新数据集上实现了最先进的结果，大大超过了以前的工作。