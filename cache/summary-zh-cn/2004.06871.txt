一般文本和任务型对话之间语言模式的潜在差异使得现有的预先训练的语言模式在实践中不太有用。在这项工作中，我们统一了九个面向人类和多回合任务的对话数据集，用于语言建模。为了在培训前更好地建模对话行为，我们将用户和系统标记合并到屏蔽语言建模中。我们提出了一个对比目标函数来模拟反应选择任务。我们预先训练的面向任务的对话BERT（TOD-BERT）在四个下游面向任务的对话应用程序（包括意图识别、对话状态跟踪、对话行为预测和反应选择）上优于类似BERT的强基线。我们还表明，TOD-BERT具有更强的少镜头能力，可以缓解面向任务对话的数据稀缺问题。