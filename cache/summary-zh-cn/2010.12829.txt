我们提出了一种简单而有效的方法，通过预训练语音编码器和文本解码器的有效迁移学习来构建多语种语音到文本（ST）的翻译。我们的主要发现是，一个最低限度的LNA（LayerNorm and Attention）微调可以通过微调小于10%的预训练参数来实现零镜头跨语言和跨模态传输能力。这可以有效地利用大型预训练模型，降低训练成本。使用wav2vec 2.0进行声学建模，使用mBART生成多语言文本，我们的方法在大规模多语言ST基准CoVoST 2上为34个翻译方向（其中23个方向超过级联ST）提供了最新技术（+6.4 BLEU在15个En-X方向上的平均值，以及+5.1 BLEU在19个X-En方向上的平均值）。我们的方法在多对多语言模型中展示了强大的零炮性能（+5.7 BLEU在18个非英语方向上的平均值），使其成为获得高质量语音翻译并提高参数和数据效率的吸引人的方法。