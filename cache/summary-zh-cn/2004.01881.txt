在本文中，我们为自然语言理解中的意图检测任务制定了一个更为现实和困难的问题设置，即广义少镜头意图检测（GFSID）。GFSID旨在区分一个联合标签空间，该空间由具有足够标记数据的现有意图和每个类只有少量示例的新意图组成。为了解决这个问题，我们提出了一种新的模型，即基于BERT的条件文本生成（CG-BERT）。CG-BERT有效地利用预先训练好的大型语言模型生成以意图标签为条件的文本。CG-BERT通过变分推理对话语分布进行建模，即使只有很少的话语可用，也能为小说意图生成不同的话语。实验结果表明，CG-BERT在两个真实数据集上的单镜头和五镜头设置下，在GFSID任务上实现了最先进的性能。