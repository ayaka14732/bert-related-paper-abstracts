近年来，随着生物医学文档数量的增加，加上自然语言处理算法的进步，生物医学命名实体识别（BioNER）的研究呈指数级增长。然而，BioNER研究具有挑战性，因为生物医学领域中的NER是：（i）由于训练数据有限，通常受到限制，（ii）实体可以根据其上下文引用多种类型和概念，（iii）严重依赖于特定于子领域的首字母缩略词。现有的BioNER方法往往忽视这些问题，直接采用在一般语料库中训练的最先进（SOTA）模型，结果往往不令人满意。我们提出了生物医学ALBERT（来自生物医学文本挖掘变压器的Lite双向编码器表示）bioALBERT，这是一种在大规模生物医学语料库上训练的有效领域特定语言模型，旨在捕获生物医学上下文相关的NER。我们采用了ALBERT中使用的一种自我监督损失模型，该模型侧重于句子间连贯性建模，以更好地学习上下文相关表示，并结合了参数缩减技术，以降低记忆消耗，提高BioNER中的训练速度。在我们的实验中，BioALBERT在八个具有四种不同实体类型的生物医学NER基准数据集上的表现优于比较SOTA-BioNER模型。我们训练了四种不同的BioALBERT模型，可供研究社区在未来研究中使用。