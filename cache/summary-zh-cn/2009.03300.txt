我们提出了一个新的测试来衡量文本模型的多任务准确性。该测试涵盖57项任务，包括初等数学、美国历史、计算机科学、法律等。为了在测试中获得高精度，模型必须具备广泛的世界知识和解决问题的能力。我们发现，虽然最新的模型具有接近随机机会的准确性，但最大的GPT-3模型比随机机会平均提高了近20个百分点。然而，在57项任务中的每一项上，最好的模型在达到专家级精度之前仍然需要大量改进。模型也有不平衡的表现，常常不知道什么时候是错的。更糟糕的是，他们在一些重要的社会问题上，如道德和法律，仍然具有近乎随机的准确性。通过全面评估模型的学术和专业理解的广度和深度，我们的测试可以用于跨多个任务分析模型，并识别重要的缺陷。