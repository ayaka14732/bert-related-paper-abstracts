语义等价性评估是指通过二元判断（即释义识别）或分级（即语义文本相似性度量）来评估句子对中语义等价性的任务。它构成了自然语言理解研究的一系列关键任务。最近，BERT在句子表征学习方面取得了突破性进展（Devlin等人，2019年），这种学习方法可广泛应用于各种NLP任务。虽然BERT的性能通过增加其模型大小而得到改善，但所需的计算能力是实际应用无法采用该技术的障碍。在此，我们建议将短语释义关系注入到BERT中，以生成合适的语义等价性评估表示，而不是增加模型的大小。在标准自然语言理解任务上的实验证实，我们的方法在保持模型大小的同时有效地改进了较小的BERT模型。生成的模型在语义等价性评估任务上表现出比更大的BERT模型更好的性能。此外，它在训练数据集有限的任务上获得了更大的性能增益，这是迁移学习所需要的特性。