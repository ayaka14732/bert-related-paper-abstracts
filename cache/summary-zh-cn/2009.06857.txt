我们分类并重新检查了一些当前的方法，以改进语言模型的性能计算权衡，包括（1）非因果模型（如掩蔽语言模型），（2）有效注意的批次长度扩展，（3）重复性，（4）条件计算和（5）检索。我们确定了（1）-（4）遭受的一些限制。例如，（1）由于需要一个特定的微调数据集，目前正在努力实现开放式文本生成，输出受到输入的松散约束，并执行GPT-2/3等一般文本任务。（2） 和（3）不改进第一个$\sim 10^3$令牌的预测。放大模型大小（例如，使用（4）进行有效缩放）仍然会导致某些任务的性能缩放效果不佳。我们认为（5）将解决许多这些限制，并且它可以（a）减少监督的数量，（b）有效地扩展整个训练数据集和当前样本的整个过去的上下文。我们推测如何修改MARGE以执行无监督因果建模，从而实现（b）与联合训练的寻回犬。