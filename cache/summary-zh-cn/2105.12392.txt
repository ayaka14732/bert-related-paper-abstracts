在这项工作中，我们提出了蒙面名词短语预测（MNPP），这是一种在完全无监督的环境下处理代词分解的预训练策略。首先，我们在没有任何微调的情况下，在各种代词分辨率数据集上评估我们预先训练的模型。我们的方法在所有数据集上都比以前的无监督方法有很大的优势。其次，我们继续进行一些镜头设置，分别在WinoGrande-S和XS上微调预先训练的模型。我们的方法比RoBERTa large baseline具有更大的利润，同时，在对WinoGrande剩余的三次官方拆分进行进一步微调后，获得了更高的AUC分数。