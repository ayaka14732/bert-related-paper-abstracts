经过预训练的语言模型最近为NLP任务的重大进展做出了贡献。最近，已经开发了多模态版本的BERT，使用大量的预训练，依赖于大量对齐的文本和图像数据，主要应用于分类任务，如VQA。在本文中，我们感兴趣的是通过避免对补充数据进行预训练来评估BERT开箱即用的视觉能力。我们选择研究视觉问题生成，这是扎根对话非常感兴趣的一项任务，能够研究每种模式的影响（因为输入可以是视觉和/或文本）。此外，任务的生成方面需要自适应，因为BERT主要设计为编码器。我们介绍了BERT-gen，一种基于BERT的文本生成体系结构，能够利用单模态或多模态表示。在不同配置下报告的结果表明，BERT gen具有天生的适应多模态数据和文本生成的能力，即使可用数据很少，也可以避免昂贵的预训练。在两个已建立的VG数据集上，所提出的模型比最新技术有了实质性的改进。