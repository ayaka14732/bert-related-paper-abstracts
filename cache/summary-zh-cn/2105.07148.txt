由于词汇信息和预训练模型（如BERT）各自的优势，已将它们结合起来探索汉语序列标记任务。然而，现有的方法仅仅通过一个浅层的随机初始化序列层来融合词典特征，而没有将它们集成到BERT的底层。在本文中，我们提出了一种用于中文序列标注的词典增强型BERT（LEBERT），它通过词典适配器层将外部词典知识直接集成到BERT层中。与现有的方法相比，我们的模型有助于在底层进行深层词汇知识融合。在命名实体识别、分词和词性标注三个任务的十个中文数据集上的实验表明，LEBERT达到了最先进的结果。