近年来，由于新闻产生和消费方式的技术和社会变化，宣传的自动识别变得越来越重要。使用BERT（一种功能强大的新体系结构，可以对文本分类任务进行微调）可以有效地解决这一任务，这并不奇怪。然而，与处理新闻文档和其他形式的非文本化社会传播（如情绪分析）的其他任务一样，宣传检测本质上是处理类别同时不平衡和不同的数据。我们表明，虽然BERT能够处理不平衡的类，而无需额外的数据扩充，但当训练和测试数据足够不相似时（新闻来源的情况通常如此，其主题随着时间的推移而变化），BERT不能很好地泛化。我们展示了如何通过提供数据集之间相似性的统计度量以及在训练集和测试集不相似时将成本加权纳入BERT的方法来解决这个问题。我们在宣传技巧语料库（PTC）上测试了这些方法，并在句子层面的宣传分类中获得了第二高分。