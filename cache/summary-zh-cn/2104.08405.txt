文档布局包括结构和视觉（例如字体大小）信息，这些信息非常重要，但常常被机器学习模型忽略。现有的几种使用布局信息的模型只考虑文本内容，忽视了图像等其他形式的内容的存在。此外，版面中呈现内容的空间交互从未真正得到充分利用。为了弥补这一差距，我们将文档解析为内容块（如文本、表格、图像），并提出一种新颖的布局感知多模态层次结构框架LAMPreT，对这些块和整个文档进行建模。我们的LAMPreT在较低级别使用多模式转换器对每个块进行编码，并在较高级别使用专门设计的转换器聚合块级表示和连接。我们设计了分层的预训练目标，其中低层模型的训练与多模态接地模型类似，而高层模型的训练与我们提出的新的布局感知目标类似。我们在两个布局感知任务——文本块填充和图像建议上对所提出的模型进行了评估，并展示了我们所提出的层次结构和预训练技术的有效性。