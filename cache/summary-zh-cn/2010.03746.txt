疾病知识包括疾病的各个方面的信息，如症状和体征、诊断和治疗。这种疾病知识对于许多与健康相关的生物医学任务至关重要，包括消费者健康问题回答、医学语言推理和疾病名称识别。虽然像BERT这样的预先训练过的语言模型在从文本中获取句法、语义和世界知识方面取得了成功，但我们发现它们可以通过症状、诊断、治疗和其他疾病方面的知识等特定信息得到进一步补充。因此，我们将BERT与疾病知识相结合，以改进这些重要任务。具体地说，我们提出了一种新的疾病知识注入训练程序，并在一组伯特模型上对其进行评估，包括伯特、BioBERT、SciBERT、ClinicalBERT、BlueBERT和ALBERT。对这三项任务的实验表明，这些模型在几乎所有情况下都能得到增强，证明了疾病知识灌输的可行性。例如，BioBERT在消费者健康问题回答方面的准确率从68.29%提高到72.09%，同时在两个数据集中观察到了新的SOTA结果。我们免费提供我们的数据和代码。