来自大规模神经语言模型的上下文词表示在一组不同的NLP任务中是成功的，这表明它们编码了语言的有用和可转移的特征。为了阐明他们所获取的语言知识，我们研究了最近几个经过预训练的语境化者（ELMo的变体、OpenAI transformer语言模型和BERT）通过一系列17种不同的探测任务所产生的表征。我们发现，在许多情况下，在冻结的上下文表示之上训练的线性模型与最先进的任务特定模型具有竞争性，但在需要细粒度语言知识（例如，联合识别）的任务上失败。为了研究语境词表征的可转移性，我们量化了语境化者中各个层面的可转移性差异，特别是递归神经网络（RNN）和变换器之间的差异。例如，RNN的更高层更具有任务特定性，而transformer层并没有表现出相同的单调趋势。此外，为了更好地理解语境词表征的可转移性，我们将语言模型预训练与11项有监督的预训练任务进行了比较。对于任何给定的任务，当预训练数据集固定时，对密切相关的任务进行预训练比语言模型预训练（平均而言更好）产生更好的性能。然而，语言模型对更多的数据进行预训练会得到最好的结果。