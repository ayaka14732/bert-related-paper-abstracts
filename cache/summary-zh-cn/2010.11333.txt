在实体链接中，原始文本中提到的命名实体会根据知识库（KB）消除歧义。这项工作的重点是链接到不可见的知识库，这些知识库没有训练数据，并且在训练期间其模式是未知的。我们的方法依赖于将具有多个属性值对的任意KBs中的实体灵活转换为平面字符串的方法，我们将其与最先进的零快照链接模型结合使用。为了提高模型的通用性，我们使用了两种基于实体属性洗牌和不可见属性处理的正则化方案。在CoNLL数据集上训练模型并在TAC-KBP 2010数据集上测试的英语数据集上的实验表明，我们的模型比基线模型的精度高出12个百分点。与之前的工作不同，我们的方法还允许无缝组合多个训练数据集。我们通过添加完全不同的数据集（Wikia）以及增加TAC-KBP 2010培训集中的培训数据量来测试这一能力。我们的模特在各方面都表现出色。