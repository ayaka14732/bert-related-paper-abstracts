我们提出了压缩变压器，一个专注的序列模型，压缩过去的记忆，用于远程序列学习。我们发现Compression Transformer在WikiText-103和Enwik8基准测试中获得了最先进的语言建模结果，分别达到17.1 ppl和0.97 bpc。我们还发现，它可以有效地模拟高频语音，并且可以作为RL的记忆机制，在一个对象匹配任务中进行了演示。为了促进远程序列学习领域的发展，我们提出了一个新的开放词汇语言建模基准，该基准源于书籍PG-19。