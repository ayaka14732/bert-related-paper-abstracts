自然语言推理（NLI）数据在基准测试中被证明是有用的，尤其是作为需要语言理解的任务的预训练数据。然而，用于收集这些数据的众包协议存在已知问题，并且没有针对这两个目的进行明确优化，因此它可能远远不够理想。我们提出了四个备选方案，每个方案的目的是提高注释员制作声音训练示例的容易程度，或者提高这些示例的质量和多样性。使用这些替代方案和第五个基线协议，我们收集并比较了五个新的8.5k示例训练集。在以迁移学习应用为重点的评估中，我们的结果完全是负面的，在我们的基线数据集上训练的模型产生了良好的下游任务迁移性能，但我们的四种新方法（以及最近的ANLI）都没有显示出比基线有任何改进。有一点值得庆幸的是，我们发现所有四个新协议，特别是注释者编辑预填充文本框的协议，都减少了以前观察到的注释工件问题。