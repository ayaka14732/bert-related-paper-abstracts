基于深度神经网络的有监督关系抽取方法在当前信息抽取领域发挥着重要作用。但是，由于复杂关系的存在，目前他们的表现仍未能达到良好水平。另一方面，最近提出的预训练语言模型（pre-trained language models，plm）通过与下游任务模型相结合的微调，在自然语言处理的多个任务中取得了巨大的成功。然而，PLM的原始标准任务还不包括关系提取任务。我们认为PLMs也可以用来解决关系抽取问题，但需要建立一个专门设计的下游任务模型，甚至损失函数来处理复杂的关系。本文设计了一种具有特殊损失函数的新型网络结构，作为PLMs的下游模型，用于监督关系提取。实验表明，我们的方法在多个公共关系提取数据集中显著超过了当前的最佳基线模型。