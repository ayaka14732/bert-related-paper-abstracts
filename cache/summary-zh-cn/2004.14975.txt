语言模式训练前如何帮助迁移学习？我们考虑一个简单的消融技术来确定每个预训练层对传输任务性能的影响。这种方法，即部分重新初始化，包括用随机权重替换预训练模型的不同层，然后在转移任务上微调整个模型，并观察性能的变化。这项技术表明，在BERT中，对下游胶水任务具有高探测性能的层对于这些任务的高精度既不必要也不充分。此外，对层使用预训练参数的好处随着数据集大小的微调而显著不同：在数据丰富时提供巨大性能改进的参数在数据稀缺的环境中可能提供微不足道的好处。这些结果揭示了迁移学习过程的复杂性，突出了对冻结模型或单个数据样本进行操作的方法的局限性。