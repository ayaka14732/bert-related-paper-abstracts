我们通过研究基于BERT的NLP模型对输入中相同类型类的替换的鲁棒性，来评估基于BERT的NLP模型的命名实体表示。我们强调，在一些任务中，虽然这种扰动是自然的，但经过最先进训练的模型却异常脆弱。即使使用最新的实体感知的BERT模型，脆性仍然存在。考虑到标记化和出现频率等因素，我们还试图找出这种非稳健性的原因。然后，我们提供了一种简单的方法，该方法集成来自多个替换的预测，同时联合建模类型注释和标签预测的不确定性。在三个NLP任务上的实验表明，我们的方法在自然数据集和对抗数据集上都增强了鲁棒性并提高了准确性。