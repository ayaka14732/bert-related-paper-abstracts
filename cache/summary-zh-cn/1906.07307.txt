现代文本到语音（TTS）系统能够生成声音几乎与人类语音一样自然的音频。然而，开发高质量的TTS系统的门槛仍然很高，因为通常需要一组相当大的演播室质量<text，audio>对。与用于开发最先进系统的商业数据相比，公开可用的数据通常在质量和规模方面都较差。根据公开数据训练的TTS系统生成的音频不仅听起来不那么自然，而且还表现出更多的背景噪声。在这项工作中，我们的目标是降低TTS系统对高质量数据的依赖性，通过在训练过程中为它们提供由深度预训练语言模型提取的文本知识。特别是，我们研究了使用BERT辅助训练Tacotron-2，这是一种由编码器和基于注意的解码器组成的最先进的TTS。从大量未标记文本数据中学习到的BERT表示包含关于输入文本的非常丰富的语义和句法信息，并且有可能被TTS系统用来弥补高质量数据的不足。我们将BERT作为一个平行分支合并到Tacotron-2编码器中，该编码器具有自己的注意头。对于输入文本，它同时被传递到BERT和Tacotron-2编码器。由两个分支提取的表示被连接起来，然后馈送到解码器。作为一项初步研究，虽然我们还没有发现将BERT纳入Tacotron-2能够在人类可感知水平上产生更自然或更干净的语音，我们观察到其他方面的改进，例如模型在知道何时停止解码方面明显更好，这样在合成音频结束时就不会有太多的胡言乱语，并且在训练期间会更快地收敛。