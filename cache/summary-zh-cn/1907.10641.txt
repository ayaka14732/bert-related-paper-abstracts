Winograd Schema Challenge（WSC）（Levesque、Davis和Morgenstern，2011）是常识推理的基准，是一组273个专家精心设计的代词解析问题，最初设计用于依赖选择偏好或单词关联的统计模型无法解决。然而，神经语言模型的最新进展已经达到了WSC变体的90%左右的准确率。这就提出了一个重要的问题：这些模型是否真正获得了强大的常识能力，或者它们是否依赖于数据集中的虚假偏差，从而导致高估机器常识的真实能力。为了研究这个问题，我们引入了WinoGrande，这是一个由44k个问题组成的大规模数据集，其灵感来自原始WSC设计，但经过调整以提高数据集的规模和硬度。数据集构建的关键步骤包括：（1）精心设计的众包程序，然后（2）使用一种新的AfLite算法系统地减少偏差，该算法将人类可检测的单词关联推广到机器可检测的嵌入关联。WinoGrande最先进的方法达到59.4-79.1%，比94.0%的人类绩效低15-35%，具体取决于允许的培训数据量。此外，我们在五个相关基准上建立了最新的最新结果——WSC（90.1%）、DPR（93.1%）、COPA（90.6%）、KnowRef（85.6%）和Winogener（97.1%）。这些结果具有双重含义：一方面，它们证明了WinoGrande作为迁移学习资源的有效性。另一方面，他们提出了一个担忧，即我们可能高估了所有这些基准中机器常识的真实能力。我们强调在现有和未来基准中减少算法偏差的重要性，以减轻这种高估。