Transformer是一种主要基于自我注意机制的深层神经网络，首次应用于自然语言处理领域。由于其强大的表示能力，研究人员正在寻找将transformer应用于计算机视觉任务的方法。在各种可视化基准测试中，基于变压器的模型的性能与其他类型的网络（如卷积网络和递归网络）相似或更好。由于它的高性能和较少的视觉特定的电感偏置需要，变压器正受到越来越多的关注，从计算机视觉界。在本文中，我们回顾了这些视觉转换器模型，将它们分为不同的任务，并分析了它们的优缺点。我们探讨的主要类别包括主干网络、高/中级视觉、低级视觉和视频处理。我们还包括有效的变压器方法，用于将变压器推进基于设备的实际应用。此外，我们还简要介绍了计算机视觉中的自我注意机制，因为它是变压器的基本组成部分。在本文的最后，我们讨论了视觉转换器面临的挑战，并提供了几个进一步的研究方向。