我们提出了Visual伯特，一个简单而灵活的框架，用于建模广泛的视觉和语言任务。VisualBERT由一堆转换器层组成，这些层隐式地将输入文本的元素和关联输入图像中的区域与自我注意对齐。我们进一步提出了两个视觉基础语言模型目标，用于图像字幕数据的预训练。在包括VQA、VCR、NLVR2和Flickr30K在内的四项视觉和语言任务上的实验表明，VisualBERT在显著简化的同时，优于或与最先进的模型相抗衡。进一步的分析表明，Visual伯特可以在没有任何明确监督的情况下将语言的元素固定到图像区域，甚至对句法关系非常敏感，例如，跟踪动词和对应于其参数的图像区域之间的关联。