自然语言推理（NLI）是自然语言理解中一项越来越重要的任务，它要求一个人推断一个句子是否包含另一个句子。然而，NLI模型进行语用推理的能力仍有待研究。我们创建了一个含义和预设诊断数据集（IMPPRES），该数据集由>25k个半自动生成的句子对组成，说明了经过充分研究的语用推理类型。我们使用IMPPRES来评估在多重NLI（Williams等人，2018年）上接受培训的BERT、Inferesent和BOW NLI模型是否学习进行语用推理。虽然MultiNLI似乎包含很少的对来说明这些推理类型，但我们发现BERT学习绘制语用推理。它可靠地将“某些”触发的标量含义视为蕴涵。对于某些预设触发器，如“only”，BERT可靠地将预设识别为蕴涵，即使触发器嵌入了蕴涵取消运算符（如否定）下。BOW和InferSent的语用推理证据较弱。我们的结论是NLI培训鼓励模型学习一些但不是全部的语用推理。