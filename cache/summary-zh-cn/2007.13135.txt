最近提出了几种多模态表示学习方法，如LXMERT和ViLBERT。由于在大规模多模态预训练过程中捕获了高级语义信息，因此这种方法可以获得优异的性能。然而，由于ViLBERT和LXMERT采用视觉区域回归和分类损失，基于视觉基因组数据集上预先训练的视觉特征，他们经常遇到域间隙和噪声标签问题。为了克服这些问题，我们提出了无偏对比视觉语言预训练（CVLP），它构建了一个基于对比学习的视觉自我监督损失。我们在几个下游任务（包括VQA、GQA和NLVR2）上评估了CVLP，以验证对比学习在多模态表征学习中的优势。我们的代码可从以下网址获得：https://github.com/ArcherYunDong/CVLP-.