最近，为各种NMT任务开发大型预训练模型获得了很多关注。在这项工作中，我们研究如何伯特预训练模型可以利用监督神经机器翻译。我们比较了各种将预训练的BERT模型与NMT模型相结合的方法，并研究了用于BERT训练的单语数据对最终翻译质量的影响。我们使用WMT-14英语德语、IWSLT15英语德语和IWSLT14英语俄语数据集进行这些实验。除了标准任务测试集评估外，我们还对域外测试集和噪声注入测试集进行评估，以评估伯特预训练表示如何影响模型鲁棒性。