诸如在大型语料库上预训练的BERT等深层语言模型极大地提高了最先进的信息检索排名系统的性能。嵌入在这些模型中的知识使他们能够拾取段落和查询之间的复杂匹配信号。然而，推理过程中的高计算成本限制了它们在现实搜索场景中的部署。在本文中，我们研究了是否以及如何通过蒸馏将BERT中的搜索知识转移到较小的ranker。我们的实验表明，使用适当的蒸馏程序至关重要，该程序在保持最先进性能的同时，可产生高达九倍的加速。