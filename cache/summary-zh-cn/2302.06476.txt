在规模进步的推动下，大型语言模型（LLM）已经证明了执行各种自然语言处理（NLP）任务的能力——零样本，即不需要对下游数据进行调整。最近，ChatGPT的首次亮相引起了自然语言处理（NLP）社区的极大关注，因为它可以对人类输入产生高质量的响应，并根据随后的对话自我纠正之前的错误。然而，尚不清楚ChatGPT是否可以作为一个通用模型来执行许多NLP任务零样本。在这项工作中，我们通过对涵盖7个代表性任务类别的20个流行NLP数据集的评估，实证分析了ChatGPT的零样本学习能力。通过广泛的实证研究，我们证明了当前版本的ChatGPT的有效性和局限性。我们发现，ChatGPT在许多有利于推理能力的任务（如算术推理）上表现良好，但在解决序列标记等特定任务时仍面临挑战。此外，我们还通过定性案例研究提供深入分析。