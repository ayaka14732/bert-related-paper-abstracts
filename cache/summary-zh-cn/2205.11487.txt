我们提出了Imagen，这是一种文本到图像的扩散模型，具有前所未有的照片真实感和深度的语言理解。Imagen建立在大型transformer语言模型在理解文本方面的能力之上，并取决于扩散模型在高保真图像生成方面的强度。我们的关键发现是，在纯文本语料库上预训练的通用大型语言模型（例如T5）在编码用于图像合成的文本方面出人意料地有效：在Imagen中增加语言模型的大小比增加图像扩散模型的大小更能提高样本保真度和图像文本对齐。Imagen在COCO数据集上实现了新的最先进的FID分数7.27，而没有对COCO进行任何培训，人类评分员发现Imagen样本在图像文本对齐方面与COCO数据本身相当。为了更深入地评估文本到图像模型，我们引入了DrawBench，这是一个全面且具有挑战性的文本到图像模型基准。通过DrawBench，我们将Imagen与最近的方法（包括VQ-GAN+CLIP、潜在扩散模型和DALL-E 2）进行了比较，发现在并行比较中，无论是在样本质量还是图像文本对齐方面，人类评分者都更喜欢Imagen。看见https://imagen.research.google/了解结果概述。