归纳迁移学习已经席卷了整个自然语言处理领域，伯特和巴特等模型为无数自然语言处理任务创造了新的技术水平。然而，大多数可用的模型和研究都是针对英语进行的。在这项工作中，我们介绍了BARThez，法国第一个大规模预训练seq2seq模型。基于BART，BARThez特别适合于生成性任务。我们评估了BARThez在烟道基准测试中的五项区别性任务和我们为本研究创建的一个新的摘要数据集OrangeSum中的两项生成性任务。我们展示了BARThez与最先进的基于BERT的法语模型（如CamemBERT和FlauBERT）的竞争力。我们还继续在BARThez的语料库上进行多语言BART的预训练，并展示我们的结果模型mBARThez，以显著提高BARThez的生成性能。代码、数据和模型是公开的。