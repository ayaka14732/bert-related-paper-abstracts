密集视频字幕旨在定位和描述未剪辑视频中的重要事件。现有的方法主要通过只利用视觉特征来解决这一问题，而完全忽略了音频轨迹。只有少数先前的工作使用了这两种模式，但它们显示了较差的结果，或者显示了具有特定领域的数据集的重要性。在本文中，我们介绍了双模变压器，它概括了双模输入的变压器结构。我们展示了所提出的音频和视频模式模型在密集视频字幕任务中的有效性，但该模块能够在序列到序列任务中消化任何两种模式。我们还表明，作为双模转换器的一部分，预先训练的双模编码器可以用作简单提案生成模块的特征提取器。该性能在一个具有挑战性的ActivityNet字幕数据集上进行了演示，我们的模型在该数据集上实现了出色的性能。代码可用：v-iashin.github.io/bmt