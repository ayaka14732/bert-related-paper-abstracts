最近的GPT-3模型（Brown et al.，2020）仅通过利用自然语言提示和一些任务演示作为输入上下文，就实现了显著的少镜头性能。受他们发现的启发，我们在更实际的场景中研究了少数镜头学习，在这种场景中，我们使用更小的语言模型，微调在计算上是有效的。我们介绍了LM-BFF——更好的语言模型微调——这是一套简单且互补的技术，用于在少量带注释的示例上微调语言模型。我们的方法包括：（1）基于提示的微调，以及一种用于自动生成提示的新管道；（2）一种改进的策略，用于动态地、有选择地将演示合并到每个上下文中。最后，我们提出了一个系统的评估，用于分析一系列NLP任务的少数镜头性能，包括分类和回归。我们的实验表明，在这种低资源环境下，我们的方法组合起来显著优于标准微调过程，实现了高达30%的绝对改善，所有任务的平均改善率为11%。我们的方法对任务资源和领域专业知识进行了最少的假设，因此构成了一种用于少量镜头学习的强大的任务不可知方法。