我们提出了一种对抗性的常识推理训练算法（ALICE）。我们将小扰动应用于单词嵌入，并最小化由此产生的对抗风险以规范化模型。我们利用两种不同方法的新组合来估计这些扰动：1）使用真标签，2）使用模型预测。我们的模型不依赖任何人工构建的功能、知识库或目标数据集以外的其他数据集，提高了RoBERTa的微调性能，在需要常识推理的多个阅读理解数据集上取得了竞争性的结果。