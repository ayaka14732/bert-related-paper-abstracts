在这项工作中，我们提供了一个系统和全面的经验比较，预训练的多语言语言模型与他们的单语对应的单语任务性能。我们在一组五种不同的单语下游任务上研究了一组九种类型多样的语言，以及现成的预训练单语模型。首先，我们的目标是通过公平和受控的比较，确定该语言的多种语言和相应的单语表达之间是否存在差距，然后调查任何表现差异的原因。为了解开融合因素，我们在相同的数据上训练新的单语模型，使用单语和多语言训练的标记化器。我们发现，虽然预训练数据大小是一个重要因素，但指定的单语标记器在下游性能中起着同样重要的作用。我们的结果表明，在多语言模型的词汇表中充分表达的语言与单语对应的语言相比，表现出微不足道的性能下降。我们进一步发现，将原来的多语言标记器替换为专门的单语标记器可以提高几乎所有任务和语言的多语言模型的下游性能。