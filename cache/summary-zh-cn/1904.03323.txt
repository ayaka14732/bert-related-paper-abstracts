最近几个月，ELMo（Peters et al.，2018）和BERT（Devlin et al.，2018）等上下文单词嵌入模型极大地提高了许多自然语言处理（NLP）任务的性能。然而，这些模型在专业语料库上的探索很少，例如临床文本；此外，在临床领域，还不存在公开的预训练BERT模型。在这项工作中，我们通过探索和发布临床文本的BERT模型来解决这一需求：一个用于一般临床文本，另一个用于出院总结。我们证明，与非特异性嵌入相比，使用领域特定模型在三种常见的临床NLP任务上产生性能改进。这些领域特定的模型在两项临床去识别任务中表现不佳，并认为这是去识别源文本和综合性非去识别任务文本之间差异的自然结果。