最近的研究使用预先训练好的语言模型（PLM）作为回答开放性问题的知识库来研究这个有趣的问题。然而，现有的工作在使用具有高测试序列重叠的小型基准方面受到限制。我们使用团队构建了一个新的闭卷QA数据集，并研究了BART的性能。实验表明，高精度记忆训练事实对BART来说是一个挑战，即使保留了相关知识，回答闭卷问题也是一个挑战。发现了一些有希望的方向，包括解耦知识记忆过程和QA微调过程，迫使模型在回答问题时回忆相关知识。