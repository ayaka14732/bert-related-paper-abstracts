多跳问答要求模型从文本的不同部分收集信息来回答问题。目前大多数方法都是通过神经网络以端到端的方式学习处理这项任务，而不需要保持推理过程的显式表示。我们提出了一种在文本上提取离散推理链的方法，该推理链由一系列导致答案的句子组成。然后，我们将提取的链反馈给基于BERT的QA模型，以进行最终答案预测。关键是，我们不依赖黄金注释链或“支持事实”：在训练时，我们使用基于命名实体识别和共指解析的启发式方法推导伪黄金推理链。我们在测试时也不依赖这些注释，因为我们的模型学习仅从原始文本中提取链。我们在最近提出的两个大型多跳问答数据集上测试了我们的方法：WikiHop和HotpotQA，并在WikiHop上实现了最先进的性能，在HotpotQA上实现了强大的性能。我们的分析显示了对高性能至关重要的链的特性：特别是，顺序建模提取很重要，以上下文感知的方式处理每个候选句子也很重要。此外，人类评估表明，我们提取的链允许人类高度自信地给出答案，这表明这些是该任务的一个强大的中间抽象。