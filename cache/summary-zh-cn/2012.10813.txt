条件文本生成一直是一项具有挑战性的任务，目前尚未从最先进的模型中看到人类水平的性能。在这项工作中，我们特别关注Commongen基准测试，其目的是为给定的输入概念集生成一个合理的句子。尽管在其他任务方面取得了进展，但在此数据集上进行微调的大型预训练语言模型通常会生成语法正确但质量上偏离人类对常识理解的句子。此外，生成的序列无法满足匹配词性和完整概念覆盖等词汇要求。在本文中，我们探讨了常识知识图如何在常识推理和词汇约束解码方面提高模型性能。我们提出了增强生成文本语义正确性的策略，我们通过以下方式实现：从概念网中提取常识关系，通过注意机制将这些关系注入统一语言模型（UniLM），并通过输出约束强制执行上述词汇要求。通过几次删减，我们发现常识注入能够生成更符合人类理解的句子，同时仍然符合词汇要求。