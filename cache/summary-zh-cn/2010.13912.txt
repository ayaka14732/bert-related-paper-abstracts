本文研究了预先训练的语言模型，以找出哪种模型在本质上对面向任务的对话任务具有最丰富的信息。我们从有监督的分类器探测和无监督的互信息探测两个方面来研究这个问题。我们在一个固定的预训练语言模型上以有监督的方式微调前馈层作为分类器探针，该模型带有带注释的标签。同时，我们提出了一种无监督的互信息探针来评估真实聚类和表示聚类之间的相互依赖性。本实证研究的目的是1）调查探究技术，特别是从无监督的互信息方面，2）为对话研究社区提供预培训语言模式选择指南，3）发现对话应用的预培训因素，这可能是成功的关键。