现有的预训练方法要么侧重于单一模态任务，要么侧重于多模态任务，不能有效地相互适应。它们只能使用单一模式数据（即文本或图像）或有限的多模式数据（即图像-文本对）。在这项工作中，我们提出了一个统一的模态预训练体系结构，即UNIMO，它可以有效地适应单模态和多模态的理解和生成任务。大规模的自由文本语料库和图像集合可用于提高视觉和文本理解能力，跨模态对比学习（CMCL）可用于在图像-文本对语料库上将文本和视觉信息对齐到统一的语义空间。由于非配对的单模态数据非常丰富，我们的模型可以利用更大的数据规模来学习更多的广义表示。此外，文本知识和视觉知识可以在统一的语义空间中相互增强。实验结果表明，UNIMO显著提高了多个单峰和多峰下游任务的性能。我们的代码和预先培训的模型在https://github.com/PaddlePaddle/Research/tree/master/NLP/UNIMO