可视化对话是一项具有挑战性的视觉语言任务，对话代理需要通过对图像内容和对话历史的推理来回答一系列问题。以前的工作主要集中在各种注意机制来模拟这种复杂的互动。相比之下，在这项工作中，我们提出了VD-BERT，一个简单而有效的统一视觉对话转换器框架，它利用预先训练的BERT语言模型来完成视觉对话任务。该模型的统一之处在于：（1）它使用单个流转换器编码器捕获图像和多回合对话之间的所有交互；（2）它通过相同的体系结构无缝地支持答案排序和答案生成。更重要的是，我们通过基于视觉的培训使BERT能够有效地融合视觉和对话内容。无需对外部视觉语言数据进行预培训，我们的模型产生了新的技术状态，在视觉对话排行榜上的单模型和集成设置（74.54和75.35 NDCG分数）中均达到最高位置。我们的代码和预训练模型发布于https://github.com/salesforce/VD-BERT.