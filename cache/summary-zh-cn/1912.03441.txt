大型自然语言推理（NLI）数据集（如SNLI和MNLI）的发布导致了该任务的完全神经系统的快速发展和改进。最近，经过大量预训练的基于变压器的模型（如BERT和MT-DNN）在这些数据集上达到了接近人类的性能。然而，这些标准数据集已被证明包含许多注释工件，允许模型使用简单易出错的启发式方法来简化理解，并且在测试集上仍然表现良好。因此，毫不奇怪，许多对抗性（挑战性）数据集的创建导致在标准数据集上训练的模型显著失败。尽管对这些数据进行额外的培训通常可以提高该类型数据的模型性能，但将这种学习转化为看不见的示例充其量只是部分。这项工作评估了现有对抗性数据集上测试不同语言现象的最新模型的失败，并发现即使这些模型在MNLI上表现相似，它们对这些攻击的鲁棒性也有很大差异。特别是，我们发现与语法相关的攻击在所有模型中都特别有效，因此我们对这些示例提供了模型性能的细粒度分析和比较。我们得出关于模型大小和多任务学习的价值的结论（除了比较它们的标准测试集性能之外），并为更有效的训练数据提供建议。