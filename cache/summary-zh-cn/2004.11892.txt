随着在线信息量的增加以及对快速访问这些内容的需求的增长，问答（QA）的需求也在不断增加。QA的一种常见方法是在特定于任务的标记数据集上微调预先训练的语言模型。然而，这种范式依赖于稀缺且成本高昂的大规模人类标记数据。我们提出了一种无监督的方法来使用生成的伪训练数据训练QA模型。我们表明，通过在相关检索句子而不是原始上下文句子上应用简单模板来生成用于QA培训的问题，通过允许模型学习更复杂的上下文-问题关系来提高下游QA性能。在该数据上训练QA模型比以前的无监督模型在班数据集上的F1分数相对提高了14%左右，当答案是命名实体时，相对提高了20%，在班上实现了最先进的无监督QA性能。