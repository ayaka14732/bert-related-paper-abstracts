现有的视觉和语言学习方法通常需要为每个任务设计特定于任务的体系结构和目标。例如，用于视觉问答的多标签答案分类器、用于引用表达式理解的区域记分器和用于图像字幕的语言解码器等。为了减轻这些麻烦，在这项工作中，我们提出了一个统一的框架，该框架在同一语言建模目标的单个体系结构中学习不同的任务，即，多模式条件文本生成，其中我们的模型学习基于视觉和文本输入生成文本标签。在7个流行的视觉和语言基准上，包括视觉问答、参考表达理解、视觉常识推理（其中大部分以前被建模为区别性任务），我们的生成方法（具有单一的统一架构）达到与最近任务特定的最先进的愿景和语言模型相当的性能。此外，我们的生成性方法在答案很少的问题上表现出更好的泛化能力。此外，我们还表明，我们的框架允许在单个体系结构中使用单个参数集进行多任务学习，实现了与单独优化的单个任务模型类似的性能。我们的代码可在以下网站公开获取：https://github.com/j-min/VL-T5