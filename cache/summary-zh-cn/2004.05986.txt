自然语言理解（NLU）英语基准（如GLUE和SuperGLUE）的出现，使新的NLU模型能够在不同的任务集上进行评估。这些综合基准促进了自然语言处理（NLP）领域的广泛研究和应用。然而，问题是，大多数此类基准仅限于英语，这使得很难将英语NLU中的许多成功应用于其他语言。为了解决这个问题，我们引入了第一个大规模汉语理解评估（CLUE）基准。CLUE是一个开放式、社区驱动的项目，包含9项任务，涵盖多个成熟的单句/句子对分类任务，以及机器阅读理解，所有这些任务都基于原始中文文本。为了确定这些任务的结果，我们使用一组最先进的预先训练过的中国模型（总共9个）来报告分数。我们还介绍了一些补充数据集和其他工具，以帮助促进中国NLU的进一步进展。我们的基准发布于https://www.CLUEbenchmarks.com