很少有镜头NLP研究是高度活跃的，但在不相交的研究线程中进行，评估套件缺乏具有挑战性但现实的测试设置，并且未能采用仔细的实验设计。因此，社区不知道哪种技术表现最好，甚至不知道它们是否优于简单的基线。我们为一个理想的少镜头NLP基准制定了desiderata，并展示了FLEX，第一个基准，公共排行榜，以及为少镜头NLP技术提供统一、全面测量的框架。FLEX整合并引入了新的少镜头评估最佳实践，包括四种传输设置的测量、零镜头评估的文本标签，以及优化统计准确性的基准设计原则性方法，同时使研究人员无需大量计算资源即可获得评估成本。此外，我们还提出了UniFew，这是一个简单但强大的基于提示的少镜头学习模型，它统一了预训练和微调提示格式，避免了最近基于提示的方法在使下游任务格式适应语言模型预训练目标方面的复杂机制。我们证明，尽管简单，但UniFew取得的结果与流行的元学习和基于提示的方法具有竞争力。