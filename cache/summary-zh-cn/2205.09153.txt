基于预训练语言模型（PLM）的神经检索器，如双编码器，在开放域问答（QA）任务中取得了良好的性能。通过整合跨架构的知识提炼，它们的有效性可以进一步达到新的水平。然而，现有的大多数研究只是直接应用传统的蒸馏方法。他们没有考虑到教师和学生结构不同的特殊情况。在本文中，我们提出了一种新的蒸馏方法，该方法显著提高了双编码器的跨架构蒸馏。我们的方法1）引入了一种自我实时蒸馏方法，可以有效地将后期交互（即科尔伯特）蒸馏到vanilla双编码器，2）采用级联蒸馏过程，通过交叉编码器教师进一步提高性能。我们进行了大量的实验，以验证我们提出的解决方案优于强基线，并在开放域QA基准上建立了一个新的最先进水平。