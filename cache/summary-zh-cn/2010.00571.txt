表蕴涵是一项二元分类任务，用于发现一个句子是否受到表内容的支持或反驳，它需要解析语言和表结构以及数值和离散推理。虽然有大量关于文本蕴涵的研究，但表蕴涵的研究较少。我们采用TAPAS（Herzig et al.，2020），一种基于表格的BERT模型来识别蕴涵。基于数据扩充的好处，我们创建了一个由数百万个自动创建的训练示例组成的平衡数据集，这些示例在微调之前的中间步骤中学习。这一新数据不仅对表蕴涵有用，而且对序列表QA任务SQA（Iyyer等人，2017）也有用。为了能够使用较长的示例作为BERT模型的输入，我们将表修剪技术作为预处理步骤进行评估，以在精度适度下降的情况下大幅提高训练和预测效率。不同的方法在TabFact（Chen等人，2020）和SQA数据集上建立了新的最新技术。