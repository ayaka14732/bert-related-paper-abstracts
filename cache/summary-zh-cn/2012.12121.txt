有几个领域拥有相应的广泛使用的特征提取器，如ResNet、BERT和GPT-x。这些模型通常通过自我监督对大量未标记数据进行预训练，可以有效地应用于下游任务。在语音领域，wav2vec2.0开始在有声读物领域的Librispeech语料库上展示其强大的表示能力和超低资源语音识别的可行性。然而，除了英语之外，wav2vec2.0还没有在真实的口语场景和语言中进行过测试。为了验证它在语言上的普遍性，我们应用预先训练好的模型来解决各种口语中的低资源语音识别任务。与以前的工作相比，我们在六种语言方面实现了20%以上的相对改进。在这些语言中，英语增长了52.4%。此外，使用粗粒度的建模单元（如子词或字符）比使用细粒度的建模单元（如电话或信件）获得更好的结果。