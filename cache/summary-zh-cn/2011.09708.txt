我们用预先训练好的语言模型来研究基于知识的对话生成。我们不是在基准上追求新的技术水平，而是试图了解存储在预先训练的模型参数中的知识是否已经足以进行开放领域的对话，从而使我们在生成过程中摆脱对外部知识源的依赖。通过大量的基准测试实验，我们发现，通过微调包含知识的对话，预先训练的语言模型可以优于在自动评估和人类判断方面需要外部知识的最先进模型，这表明我们提出的问题得到了肯定的答案。