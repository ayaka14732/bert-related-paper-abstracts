对话状态跟踪（DST）中一个重要但很少解决的问题是动态本体（如电影、餐厅）和不可见的时隙值的可伸缩性。我们关注一个特定的情况，其中本体对于状态跟踪器是未知的，但是目标时隙值（除了none和dontcare）在训练期间可能是不可见的，可以在对话上下文中作为词段找到。以前的方法通常依赖于从n-gram枚举或时隙标记器输出生成候选项，这可能是低效的或受到错误传播的影响。我们提出了BERT-DST，一种端到端对话状态跟踪器，它直接从对话上下文中提取时隙值。我们使用BERT作为对话上下文编码器，其上下文化语言表示适用于可伸缩DST，以从其语义上下文中识别时隙值。此外，我们在所有时隙中使用编码器参数共享，具有两个优点：（1）参数数量不会随本体线性增长。（2） 语言表示知识可以在插槽之间传递。实证评估表明，具有跨时隙参数共享的BERT-DST在基准可扩展DST数据集Sim-M和Sim-R上的性能优于先前的工作，并在标准DSTC2和WOZ 2.0数据集上实现了具有竞争力的性能。