在答案排序这样的精确任务中，对许多相关答案进行高度排序比检索所有相关答案更为重要。因此，一个好的排名策略是先学习如何识别最简单的正确答案（即，将高排名分数分配给具有通常表明相关性的特征的答案，将低排名分数分配给不具有相关性的特征的答案），然后再结合更复杂的逻辑来处理困难的案例（例如，语义匹配或推理）.在这项工作中，我们将这一思想应用到使用课程学习的神经回答等级的训练中。我们提出了几种启发式方法来估计给定训练样本的难度。我们表明，所提出的启发式方法可用于构建训练课程，在训练过程的早期降低难度样本的权重。作为随着时间的推移，我们的方法逐渐转向平均加权所有样本，而不考虑难度。我们在三个答案排序数据集上对我们提出的想法进行了综合评估。结果表明，我们的方法使两种领先的神经排序架构（即BERT和ConvKNRM）在使用p当应用于一个基于伯特的ranker时，我们的方法在MRR上提高了4%，在ranker上提高了9%P@1（与未经课程培训的模型相比）。这使得模型可以实现与更昂贵的最新技术相当的性能。