基于Transformer的语言模型在NLP中占据了很多领域。由于能够捕捉上下文敏感的语义细微差别，BERT及其衍生物主导了大多数现有的评估基准，包括词义消歧（WSD）基准。然而，关于它们在编码和恢复词义方面的能力和潜在局限性，人们仍然知之甚少。在这篇文章中，我们对著名的BERT模型进行了深入的定量和定性分析。我们分析的一个主要结论是，即使每个词的词义只有有限的例子，BERT也能准确地捕捉到高级意义上的区别。我们的分析还表明，在某些情况下，从训练数据和计算资源的可用性来看，语言模型接近于在理想条件下解决粗粒度名词消歧问题。然而，这种情况在现实环境中很少发生，因此，即使在粗粒度环境中也存在许多实际挑战。我们还对两种主要的基于语言模型的WSD策略（即微调和特征提取）进行了深入比较，发现后一种方法在感知偏差方面更为稳健，并且可以更好地利用有限的可用训练数据。事实上，即使每个词义只使用三个训练句子，平均上下文嵌入的简单特征提取策略也被证明是稳健的，通过增加训练数据的大小可以获得最小的改进。