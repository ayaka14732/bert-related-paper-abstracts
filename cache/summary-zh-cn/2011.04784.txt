本文介绍了EstBERT，一个针对爱沙尼亚语的基于大型预训练转换器的语言特定的BERT模型。最近的工作评估了爱沙尼亚任务的多语言BERT模型，发现它们优于基线。然而，基于对其他语言的现有研究，语言特定的BERT模型有望比多语言模型有所改进。我们首先描述了EstBERT预训练过程，然后给出了基于微调EstBERT的多NLP任务模型的结果，包括词性和形态标记、命名实体识别和文本分类。评估结果表明，基于EstBERT的模型在六项任务中的五项任务上优于多语言BERT模型，这进一步证明了训练特定语言的BERT模型仍然有用，即使多语言模型可用。