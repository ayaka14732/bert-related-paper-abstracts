先前关于桥接回指识别的工作（Hou等人，2013a）将该问题视为学习细粒度信息状态（IS）的子任务。然而，这些系统严重依赖于许多手工制作的语言特征。在本文中，我们提出了一个用于细粒度IS分类的语篇上下文感知自我注意神经网络模型。在ISNotes语料库（Markert等人，2012年）上，我们使用上下文编码单词表示法（BERT）的模型（Devlin等人，2018年）在细粒度IS分类方面取得了新的最先进的性能，与Hou等人（2013a）相比，获得了4.1%的绝对整体准确度改进。更重要的是，我们还展示了桥接回指识别的3.9%F1改进，而不使用任何复杂的手工制作的语义特征来捕捉桥接现象。