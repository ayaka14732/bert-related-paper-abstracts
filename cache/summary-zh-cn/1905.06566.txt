神经提取摘要模型通常采用分层编码器进行文档编码，并使用基于规则的启发式方法创建的句子级标签进行训练。使用这些\emph{不准确}标签训练分层编码器是一项挑战。受最近关于变压器句子编码器预训练工作的启发，我们提出了{\sc-Hibert}（作为{\bf-HI}erachical{\bf-B}方向{\bf-E}ncoder{\bf-R}表示来自{\bf-T}变压器的缩写）用于文档编码，并提出了一种使用未标记数据对其进行预训练的方法。我们将预先训练好的{\sc Hibert}应用到我们的摘要模型中，它在CNN/Dailymail数据集上的性能比随机初始化的模型好1.25个ROUGE，在纽约时报数据集上的性能比随机初始化的模型好2.0个ROUGE。我们还在这两个数据集上实现了最先进的性能。