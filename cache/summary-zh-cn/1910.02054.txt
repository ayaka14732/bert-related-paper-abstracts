大型深度学习模型可以显著提高精度，但训练数十亿到数万亿的参数是一项挑战。现有的解决方案，如数据和模型并行，在将这些模型放入有限的设备内存中，同时获得计算、通信和开发效率方面存在根本性的限制。我们开发了一种新的解决方案，零冗余优化器（Zero），用于优化内存，极大地提高了训练速度，同时增加了可以有效训练的模型大小。ZeRO消除了数据和模型并行训练中的内存冗余，同时保持了较低的通信量和较高的计算粒度，使我们能够以持续的高效率按设备数量比例调整模型大小。我们对内存需求和通信量的分析表明：使用当今的硬件，ZeRO有可能扩展超过1万亿个参数。我们实现并评估ZeRO：它在400 GPU上以超线性加速比训练超过100B参数的大型模型，实现15 PB的吞吐量。这意味着与最先进的技术相比，模型尺寸增加了8倍，可实现的性能提高了10倍。就可用性而言，ZeRO可以训练高达13B参数的大型模型（例如，大于威震天GPT 8.3B和T5 11B），而无需模型并行性，这对科学家来说是很难应用的。最后但并非最不重要的一点是，研究人员利用零的系统突破创造了世界上最大的语言模型（图灵NLG，17B参数），其精确度打破了记录。