GPT-3等大规模语言模型是优秀的少数镜头学习者，可以通过自然文本提示进行控制。最近的研究报告称，基于提示的直接分类消除了微调的需要，但缺乏数据和推理的可伸缩性。本文提出了一种新的数据增强技术，该技术利用大规模语言模型从真实样本的混合中生成真实的文本样本。我们还建议利用语言模型预测的软标签，有效地从大规模语言模型中提取知识，同时创建文本扰动。我们在不同的分类任务上进行了数据增强实验，结果表明我们的方法比现有的文本增强方法有很大的优越性。消融研究和定性分析为我们的方法提供了更多的见解。