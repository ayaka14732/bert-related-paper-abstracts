最近的文本无监督表征学习模型采用了许多技术来改善语境词表征，但很少关注语篇层面的表征。我们提出了CONPONO，一个用于训练前语言模型的句间目标，它模拟了语篇连贯和句子之间的距离。在给定锚定句的情况下，我们的模型使用一个抽样的softmax目标训练预测文本k句，其中候选句子由相邻句子和从语料库中随机抽样的句子组成。在话语表征基准DiscoEval上，我们的模型在7项任务中比之前的最新水平提高了13%，平均绝对值提高了4%。我们的模型与BERT-Base的大小相同，但优于更大的BERT-Large模型和其他更新的包含语篇的方法。我们还表明，即使对于没有明确评估语篇的任务：文本蕴涵（RTE）、常识推理（COPA）和阅读理解（ReCoRD），CONPONO也能产生2%-6%的绝对增益。