最近，基于变换器的方法（如RoBERTa和GPT-3）在自然语言处理任务（如问答和常识推理）方面取得了重大的实验进展。后者通常通过多个基准进行评估，作为前者的多项选择实例。根据艾伦研究所（Allen Institute）主持的有影响力的排行榜（在常识推理基准上评估最先进的性能），基于这种转换方法的模型正在接近人类的性能，在许多基准上的平均准确率远远超过80%。由于这些都是常识性基准测试，因此在常识性推理基础上进行概括的模型在多个常识性基准测试中不会出现太多性能损失。在本文中，我们通过设计和进行严格的科学研究，详细研究了泛化问题。通过使用五种常见的基准测试、多重控制和统计分析，我们发现了明确的证据，即即使实验设置有适度的变化，经过微调的常识语言模型仍然不能很好地概括，事实上，可能容易受到数据集偏差的影响。我们还进行选择性研究，包括定性和一致性分析，以深入了解问题。