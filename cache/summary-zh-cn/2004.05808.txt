多准则汉语分词（MCCWS）的目的是在多准则分词的情况下，在由连续字符组成的汉语句子中寻找词的边界。该统一框架已在MCCWS中得到广泛应用，并显示了其有效性。此外，在多任务学习框架下，将预先训练好的BERT语言模型引入到MCCWS任务中。本文结合统一框架和预训练语言模型的优点，提出了一种基于BERT的统一MCCWS模型。此外，我们还利用二元图特征和辅助准则分类任务对统一的基于BERT的MCCWS模型进行了扩充。在八个具有不同标准的数据集上进行的实验表明，我们的方法可以实现针对MCCW的最新结果。