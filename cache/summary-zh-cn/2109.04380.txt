对比学习在无监督句子嵌入的学习中一直备受关注。当前最先进的无监督方法是无监督SimCSE（unsupervised SimCSE）。Unsup SimCSE将dropout作为一种最小的数据扩充方法，并将相同的输入语句传递给经过预训练的Transformer编码器（打开dropout）两次，以获得两个相应的嵌入以构建正对。由于在变换器中使用位置嵌入，句子的长度信息通常会被编码到句子嵌入中，因此unsup SimCSE中的每个正对实际上包含相同的长度信息。因此，用这些正对训练的unsup SimCSE可能有偏差，这会倾向于认为相同或相似长度的句子在语义上更相似。通过统计观察，我们发现unsup SimCSE确实存在这样的问题。为了缓解这种情况，我们使用一个简单的重复操作来修改输入句子，然后将输入句子及其修改后的对应句子分别传递给预先训练好的Transformer编码器，以获得正对。此外，我们从计算机视觉社区中汲取灵感，引入动量对比，在不进行额外计算的情况下扩大负对的数量。将所提出的两种修改分别应用于正对和负对，并构建了一种新的句子嵌入方法，称为增强型unsp-SimCSE（ESimCSE）。我们通过语义文本相似度（STS）任务在多个基准数据集上对所提出的ESimCSE进行了评估。实验结果表明，ESimCSE在BERT基础上的平均Spearman相关性为2.02%，优于最先进的unsup SimCSE。