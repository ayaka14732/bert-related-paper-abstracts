各种各样的NLP应用程序，如机器翻译、摘要和对话，都涉及文本生成。这些应用程序面临的一个主要挑战是如何评估生成的文本是否真正流畅、准确或有效。在这项工作中，我们将生成文本的评估概念化为一个文本生成问题，使用预先训练的序列到序列模型进行建模。一般的想法是，当生成的文本更好时，经过训练将生成的文本转换成参考输出或源文本的模型将获得更高的分数。我们使用基于编码器-解码器的预训练模型BART将这一想法付诸实施，并提出了一种具有多种变体的度量BARTScore，可在无监督的情况下灵活应用于从不同角度（例如信息性、流利性或真实性）评估文本。BARTScore在概念上简单，在经验上有效。它可以在22个测试设置中的16个测试设置中超越现有的最高评分指标，涵盖16个数据集（例如，机器翻译、文本摘要）和7个不同角度（例如，信息性、真实性）的评估。计算BARTScore的代码可在https://github.com/neulab/BARTScore，我们已经发布了一个交互式的元评估排行榜http://explainaboard.nlpedia.ai/leaderboard/task-meval/ 在ExplainOnboard平台上，它允许我们以交互方式了解每个指标的优势、劣势和互补性。