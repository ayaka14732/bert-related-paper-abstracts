在本文中，我们探讨了多任务学习（MTL）作为第二个预训练步骤来学习变压器语言模型的增强通用语言表示。我们在几个自然语言理解任务中使用MTL增强表示来提高性能和泛化能力。此外，我们将知识提炼（KD）纳入MTL中，以进一步提高绩效，并设计了一种KD变体，该变体可以有效地从多名教师那里学习。通过将MTL和KD相结合，我们提出了稳健优化和提炼（ROaD）的建模框架。我们使用ROaD和ELECTRA模型来获得机器阅读理解和自然语言推理的最新结果。