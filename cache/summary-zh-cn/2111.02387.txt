视觉和语言（VL）预培训已被证明对各种VL下游任务非常有效。虽然最近的研究表明，完全基于变压器的VL模型比以前基于区域特征的方法更有效，但它们在下游任务中的性能往往会显著下降。在本文中，我们介绍了一种多模式端到端变压器框架METER，通过它我们研究了如何以端到端的方式设计和预训练一个完全基于变压器的VL模型。具体来说，我们从多个维度剖析了模型设计：视觉编码器（例如，CLIP-ViT、Swin transformer）、文本编码器（例如，RoBERTa、DeBERTa）、多模式融合模块（例如，合并注意与共同注意）、架构设计（例如，仅编码器与编码器-解码器）和预训练目标（例如，蒙面图像建模）。我们进行了全面的实验，并就如何培训高性能VL变压器提供了见解。在VQAv2测试标准集上，仅使用4M图像进行预训练，METER的准确率达到77.64%，比最先进的基于区域特征的模型高出1.04%，比之前最好的完全基于变压器的模型高出1.6%。值得注意的是，进一步放大后，我们最好的VQA模型的准确率达到了80.54%。代码和预先训练的模型在https://github.com/zdou0830/METER.