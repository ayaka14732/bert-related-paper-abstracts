在本文中，我们提出了一种新的基于预训练的编码器-解码器框架，它能够以两级方式基于输入序列生成输出序列。对于我们模型的编码器，我们使用BERT将输入序列编码为上下文表示。对于解码器，在我们的模型中有两个阶段，第一阶段，我们使用基于转换器的解码器来生成草稿输出序列。在第二阶段，我们屏蔽草稿序列中的每个单词并将其提供给BERT，然后通过组合输入序列和BERT生成的草稿表示，我们使用基于转换器的解码器来预测每个屏蔽位置的细化单词。据我们所知，我们的方法是第一种将BERT应用于文本生成任务的方法。作为这一方向的第一步，我们在文本摘要任务中评估了我们提出的方法。实验结果表明，我们的模型在CNN/每日邮报和纽约时报的数据集上都达到了最新的水平。