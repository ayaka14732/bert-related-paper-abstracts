以往对深度学习模型句法能力的研究并没有针对语法泛化的强度与模型在训练过程中暴露的证据数量之间的关系。我们通过部署一种新的词汇学习范式来测试BERT在英语动词的两个方面的少量学习能力：交替和选择偏好。对于前者，我们在动词交替对中的单个框架上微调BERT，并询问模型是否期望新动词出现在其姊妹框架中。对于后者，我们在动词宾语的不完全选择网络上微调BERT，并询问它是否期望未经测试但似乎合理的动词/宾语对。我们发现，BERT在对一个新词进行微调后，仅在一两个实例之后就做出了强有力的语法概括。对于动词交替测试，我们发现该模型表现出与及物性偏见一致的行为：很少看到的动词预期会使用直接宾语，但看到直接宾语的动词预期不会出现不及物性。