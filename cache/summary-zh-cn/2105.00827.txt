基于转换器的预训练语言模型（PLM）开创了现代自然语言处理（NLP）的新纪元。这些模型结合了变压器、转移学习和自监督学习（SSL）的功能。随着这些模型在一般领域的成功，生物医学研究界开发了各种领域内PLM，从BioBERT到最新的BioELECTRA和BioALBERT模型。我们坚信有必要编写一份调查报告，对各种基于转换器的生物医学预训练语言模型（BPLM）进行全面调查。在本次调查中，我们首先简要概述了自监督学习、嵌入层和变压器编码器层等基本概念。我们讨论了基于变压器的PLM的核心概念，如预训练方法、预训练任务、微调方法以及生物医学领域特有的各种嵌入类型。我们介绍了基于transformer的BPLMs的分类，然后讨论了所有模型。我们讨论各种挑战并提出可能的解决方案。最后，我们强调了一些有待解决的问题，这些问题将推动研究界进一步改进基于变压器的BPLM。