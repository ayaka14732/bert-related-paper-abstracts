最近在语言建模方面的工作表明，训练大型转换器模型提高了自然语言处理应用程序的技术水平。然而，由于内存限制，非常大的模型可能很难训练。在这项工作中，我们介绍了我们用于训练大型变压器模型的技术，并实现了一种简单、高效的层内模型并行方法，该方法能够训练具有数十亿参数的变压器模型。我们的方法不需要新的编译器或库更改，与管道模型并行性是正交的和互补的，并且可以通过在本机PyTorch中插入一些通信操作来完全实现。我们通过使用512 GPU将基于变压器的模型聚合到83亿个参数来说明这种方法。我们在整个应用程序中维持15.1万亿次，扩展效率为76%，而强大的单一GPU基线维持39万亿次，是峰值浮点的30%。为了证明大型语言模型可以进一步提升技术水平（SOTA），我们训练了一个类似于GPT-2的83亿参数转换器语言模型和一个类似于BERT的39亿参数模型。我们表明，随着模型尺寸的增长，仔细关注类BERT模型中层规范化的放置对于提高性能至关重要。使用GPT-2模型，我们在WikiText103（10.8，SOTA复杂度为15.8）和LAMBADA（66.5%，SOTA准确度为63.2%）数据集上获得了SOTA结果。我们的BERT模型在RACE数据集上实现了SOTA结果（90.9%，而SOTA准确率为89.4%）。