我们对对抗性NLI（ANLI）进行了深入的错误分析，ANLI是最近引入的大规模人与模型在环自然语言推理数据集，收集了多轮数据。我们对负责黄金分类标签的推理的不同方面提出了一个细粒度注释方案，并使用它手动编码所有三个ANLI开发集。我们使用这些注释来回答各种有趣的问题：哪种推理类型最常见，哪种模型在每种推理类型上的性能最高，哪种类型对最先进的模型来说最具挑战性？我们希望我们的注释能够对在ANLI上训练的模型进行更细粒度的评估，让我们更深入地理解模型的失败和成功之处，并帮助我们确定未来如何训练更好的模型。