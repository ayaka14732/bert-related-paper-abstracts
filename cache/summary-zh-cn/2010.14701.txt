我们在四个领域确定了交叉熵损失的经验标度律：生成图像建模、视频建模、多模态图像$\leftrightarrow$文本模型和数学问题解决。在所有情况下，随着模型尺寸和计算预算的增加，自回归变压器的性能都会随着幂律和常数比例律的增加而平稳提高。最佳模型大小还取决于通过幂律计算的预算，指数几乎在所有数据域中都是通用的。交叉熵损失的信息论解释为$S（$True$）+D_{\mathrm{KL}（$True$| |$Model$）$，经验标度定律表明预测了真实数据分布的熵以及真实分布和模型分布之间的KL差异。根据这种解释，十亿参数变压器几乎是YFCC100M图像分布的完美模型，其采样分辨率为8美元乘以8美元，我们可以预测实现nats/图像中任何给定可减少损失（即其他分辨率的$D{\mathrm{KL}}$）所需的模型大小。我们在特定领域中发现了一些额外的缩放定律：（a）我们确定了多模态模型中字幕和图像之间互信息的缩放关系，并展示了如何回答“一张图片值一千个单词吗？”；（b） 在数学问题解决的情况下，当外推超出训练分布时，我们确定了模型性能的标度律；（c） 我们对用于ImageNet分类的生成图像模型进行了微调，发现分类损失和错误率的平滑缩放，即使生成损失趋于平稳。综上所述，这些结果加强了这样一种情况，即标度律对神经网络性能具有重要影响，包括对下游任务的影响。