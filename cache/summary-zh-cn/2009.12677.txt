生成性常识推理（generativecommonsense reasoning，简称generativecommonsense，简称generativecommonsense，简称generativecommonsense，简称generativecommonsense，简称generativecommonsense，简称generativecommonsense，简称generativecommonsense）是文本生成的一。即使是最先进的预先训练过的语言生成模型也难以完成这项任务，并且常常会产生令人难以置信的异常句子。一个原因是，他们很少考虑结合知识图，可以提供丰富的关系信息之间的常识概念。为了提高文本生成的常识推理能力，我们提出了一种新的知识图增强预训练语言生成模型KG-BART，该模型通过知识图包含概念之间的复杂关系，并生成更多逻辑和自然的句子作为输出。此外，KG-BART可以利用图形注意来聚合丰富的概念语义，从而增强模型对不可见概念集的泛化。在基准CommonGen数据集上的实验通过与几个强大的预训练语言生成模型的比较，验证了我们提出的方法的有效性，特别是KG-BART在BLEU-3,4方面的性能比BART好5.80,4.60。此外，我们还表明，由我们的模型生成的上下文可以作为背景场景，以利于下游常识QA任务。