多任务学习（MTL）在自然语言处理应用中取得了显著的成功。在这项工作中，我们针对各种生物医学和临床自然语言处理任务（如文本相似性、关系提取、命名实体识别和文本推理）研究了一个具有多个解码器的多任务学习模型。我们的实证结果表明，MTL微调模型在生物医学和临床领域的表现分别比最先进的变压器模型（例如，BERT及其变体）好2.0%和1.3%。成对MTL进一步展示了关于哪些任务可以改善或减少其他任务的更多细节。这在研究人员为新问题选择合适模型的过程中尤其有用。代码和模型可在https://github.com/ncbi-nlp/bluebert