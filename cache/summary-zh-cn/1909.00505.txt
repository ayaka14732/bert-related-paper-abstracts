推理常识知识是自然语言处理中的一个关键挑战，但由于训练数据的稀疏性，以前的工作表明，有监督的常识知识挖掘方法在对新数据进行评估时表现不佳。在这项工作中，我们开发了一种使用预先训练的大型双向语言模型生成常识知识的方法。通过将关系三元组转换为掩蔽句，我们可以使用该模型根据估计的两个实体之间的逐点互信息对三元组的有效性进行排序。由于我们不更新双向模型的权重，因此我们的方法不受任何常识知识库覆盖范围的影响。虽然该方法在测试集上的性能比在相应的训练集上明确训练的模型差，但在从新的来源挖掘常识知识时，它的性能优于这些方法，这表明无监督技术可能比现有的有监督方法具有更好的泛化能力。