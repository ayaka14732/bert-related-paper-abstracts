Zellers等人（2018年）最近的工作引入了一项新的常识自然语言推理任务：给定一个事件描述，如“一个女人坐在钢琴前”，机器必须选择最可能的后续事件：“她将手指放在键上。”随着BERT的引入，达到了接近人类水平的性能。这是否意味着机器可以执行人类水平的常识推理？在本文中，我们展示了一个新的挑战数据集HellaSwag，证明即使是最先进的模型也难以进行常识推理。尽管它的问题对人类来说微不足道（>95%的准确率），但最先进的模型却难以解决（<48%）。我们通过对抗性过滤（AF）实现这一点，这是一种数据收集范式，其中一系列鉴别器迭代选择一组机器生成的错误答案。事实证明，AF具有惊人的健壮性。关键的洞察是将数据集示例的长度和复杂性扩展到一个关键的“金发”区域，其中生成的文本对人类来说是荒谬的，但往往被最先进的模型错误分类。我们对HellaSwag的构造及其带来的困难，揭示了深层预训练模型的内部工作原理。更广泛地说，它为NLP研究提供了一条新的前进道路，基准与不断发展的最新技术以对抗的方式共同发展，从而提出更严峻的挑战。