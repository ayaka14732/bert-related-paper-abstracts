我们提出了一种知识增强的方法，ERNIE ViL，它结合了从场景图中获得的结构化知识来学习视觉语言的联合表示。ERNIE ViL试图在视觉和语言之间建立详细的语义联系（对象、对象属性和对象之间的关系），这对于视觉语言跨模态任务至关重要。ERNIE ViL利用视觉场景的场景图，在预训练阶段构造场景图预测任务，即对象预测、属性预测和关系预测任务。具体来说，这些预测任务是通过预测从句子解析的场景图中不同类型的节点来实现的。因此，ERNIE ViL可以学习描述跨视觉和语言的详细语义对齐的联合表示。在对大规模图像-文本对齐数据集进行预训练后，我们验证了ERNIE ViL在5个跨模式下游任务中的有效性。厄尼·维尔在所有这些任务上都取得了最先进的表现，在录像机排行榜上排名第一，绝对提高了3.7%。