预训练语言模型在许多自然语言处理任务中都取得了成功。许多作品探索将知识整合到语言模型中。在生物医学领域，专家们花费了几十年的努力来建立大规模的知识库。例如，统一医学语言系统（UMLS）包含数百万个实体及其同义词，并定义了数百个实体之间的关系。利用这些知识可以使各种下游任务受益，例如命名实体识别和关系提取。为此，我们提出了KeBioLM，这是一个生物医学预训练语言模型，它明确地利用了UMLS知识库中的知识。具体来说，我们从PubMed摘要中提取实体并将它们链接到UMLS。然后，我们训练一个知识感知语言模型，该模型首先应用纯文本编码层来学习实体表示，然后应用文本实体融合编码来聚合实体表示。此外，我们还增加了实体检测和实体链接两个训练目标。在BLURB基准中的命名实体识别和关系提取实验证明了该方法的有效性。对收集的探测数据集的进一步分析表明，我们的模型具有更好的医学知识建模能力。