本文介绍了一种新的视觉语言预训练模型——ImageBERT，用于图像-文本联合嵌入。我们的模型是一个基于变压器的模型，它以不同的模态作为输入，并对它们之间的关系进行建模。该模型同时在四个任务上进行预训练：蒙蔽语言建模（MLM）、蒙蔽对象分类（MOC）、蒙蔽区域特征回归（MRFR）和图像文本匹配（ITM）。为了进一步提高预训练质量，我们从Web上收集了一个大规模的弱监督图像文本（LAIT）数据集。我们首先在此数据集上预训练模型，然后对概念标题和SBU标题进行第二阶段预训练。我们的实验表明，多阶段预训练策略优于单阶段预训练策略。我们还针对图像检索和文本检索任务对预先训练好的ImageBERT模型进行了微调和评估，并在MSCOCO和Flickr30k数据集上取得了最新成果。