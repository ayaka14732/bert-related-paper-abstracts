在面向任务的对话系统中，对话状态跟踪（DST）的目标是从对话历史记录中监控对话的状态。最近，许多基于深度学习的方法被提出用于此任务。尽管DST的当前神经架构具有令人印象深刻的性能，但它们通常都经过了大量的工程设计，而且概念复杂，因此很难在生产环境中实现、调试和维护它们。在这项工作中，我们提出了一个简单而有效的基于BERT的DST模型。除了简单之外，我们的方法还具有许多其他优点：（a）参数的数量不随本体大小而增长（b）模型可以在领域本体可能动态变化的情况下运行。实验结果表明，我们的基于伯特的模型在很大程度上优于以前的方法，在标准WoZ 2.0数据集上获得了最新的结果。最后，为了使模型对于资源受限的系统足够小和快速，我们应用了知识提取方法来压缩我们的模型。最终的压缩模型可获得与原始模型相当的结果，同时更小8倍，更快7倍。