大规模多标签文本分类（LMTC）有着广泛的自然语言处理（NLP）应用，并提出了有趣的挑战。首先，由于LMTC数据集的标签集非常大，且标签分布不均匀，因此并非所有标签都能很好地表示在训练集中。此外，标签层次结构和人类标签指南的差异可能会影响图形感知注释接近度。最后，标签层次结构会定期更新，要求LMTC模型能够进行零炮概括。当前最先进的LMTC模型采用标签式注意网络（LWAN），其（1）通常将LMTC视为平面多标签分类；（2） 可以使用标签层次结构来改进零镜头学习，尽管这一实践尚未得到充分研究；和（3）未与预先培训的变压器（如BERT）结合，这导致了几个NLP基准的最新结果。在这里，我们首次对一组LMTC方法进行了实证评估，从普通LWANs到分层分类方法和转移学习，对来自不同领域的三个数据集的频繁、少量和零炮学习进行了评估。我们证明了基于概率标签树（PLT）的分层方法优于LWAN。此外，我们还证明了基于变压器的方法在两个数据集中的性能优于最先进的方法，并且我们提出了一种结合BERT和LWAN的最先进方法。最后，我们提出了利用标签层次结构改进少镜头和零镜头学习的新模型，在每个数据集上考虑了我们引入的图形感知注释邻近度量。