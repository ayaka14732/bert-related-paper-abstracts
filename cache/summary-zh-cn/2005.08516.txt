数字推理对于准确地理解世界通常很重要。最近，一些特定格式的数据集被提出，例如自然语言推理（NLI）、阅读理解（RC）和问答（QA）环境中的数字推理。针对这些数据集，还提出了几种特定于格式的模型和体系结构。然而，在执行与问题格式无关的数值推理时，非常需要一个能够评估模型能力的基准，因为（i）我们想要教授的数值推理能力不受问题格式的控制，（ii）数值推理技术具有最佳可能的应用，它必须能够以一种非单一格式、任务、数据集或域独有的方式处理语言和推理。为了实现这一目标，我们引入了NUMBERGAME，这是一个多方面的基准，用于评估八种不同格式的数值推理任务的模型性能。我们在汇编中添加了四种现有的问题类型。我们添加的两种新类型是关于需要外部数字知识、常识知识和领域知识的问题。为了构建一个更实用的数值推理系统，NUMBERGAME要求除数值推理之外的四种能力：（i）直接从数据中检测问题格式（ii）找到每种格式都可以转换为的中间通用格式（iii）结合常识知识（iv）处理跨格式的数据不平衡。我们建立了几个基线，包括一个基于知识搜索的新模型。然而，与人类基线相比，所有基线的表现都很差，这表明我们的基准很硬。我们的工作推进了通用系统开发的最新进展，展示了这些未充分探索的任务的范围。