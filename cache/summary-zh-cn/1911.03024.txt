目前，语境化的单词表示是通过复杂的神经网络模型来学习的，如蒙面神经语言模型（MNLMs）。新的表示法通过阅读段落显著提高了自动问答的性能。然而，由于参数众多且混杂，识别在MNLMs中训练的详细知识是困难的。本文从常识知识的角度对预先培训的MNLMs进行了实证分析。首先，我们提出了一个测试来衡量接受过训练的MNLMs理解哪些类型的常识知识。通过测试，我们观察到MNLMs部分理解各种类型的常识知识，但不能准确理解关系的语义。此外，基于问答任务问题的难度，我们观察到基于传销的预训练模型仍然容易受到需要常识知识的问题的影响。我们还通过实验证明，我们可以通过组合来自外部常识库的知识来提升现有的基于MNLM的模型。