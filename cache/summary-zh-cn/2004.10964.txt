在各种来源的文本上预先训练的语言模型是当今NLP的基础。鉴于这些广泛覆盖模型的成功，我们研究了根据目标任务领域定制预训练模型是否仍然有用。我们提出了一项跨四个领域（生物医学和计算机科学出版物、新闻和评论）和八项分类任务的研究，表明在高资源和低资源环境下，领域预培训的第二阶段（领域自适应预培训）会带来性能提升。此外，即使在域自适应预训练之后，适应任务的未标记数据（任务自适应预训练）也可以提高性能。最后，我们表明，适应使用简单数据选择策略扩充的任务语料库是一种有效的选择，尤其是在领域自适应预训练资源可能不可用的情况下。总的来说，我们一致发现多阶段自适应预训练在任务绩效方面有很大的提高。