由于BERT带来的引人注目的改进，许多最近的表示模型采用Transformer架构作为其主要构建块，因此继承了文字标记化系统，尽管它与Transformer的概念没有本质联系。虽然该系统被认为能够在字符的灵活性和完整单词的效率之间实现良好的平衡，但使用来自一般领域的预定义词条词汇并不总是合适的，尤其是在为专门领域（例如，医学领域）构建模型时。此外，采用词条标记化将焦点从词级转移到子词级，这使得模型在概念上更复杂，在实践中可能更不方便。基于这些原因，我们提出了CharacterBERT，这是BERT的一个新变体，它完全放弃了词条系统，而是使用字符CNN模块通过查询字符来表示整个单词。我们表明，这种新模型提高了BERT在各种医学领域任务上的性能，同时产生了健壮的、单词级的和开放的词汇表示。