在这项工作中，我们探索了“提示调优”，这是一种简单而有效的学习“软提示”的机制，用于调节冻结的语言模型以执行特定的下游任务。与GPT-3使用的离散文本提示不同，软提示是通过反向传播学习的，可以调整为包含来自任意数量标记示例的信号。我们的端到端学习方法大大优于GPT-3的“少量”学习。更值得注意的是，通过使用T5对模型大小进行烧蚀，我们表明快速调整与缩放更具竞争力：当模型超过数十亿个参数时，我们的方法“缩小了差距”，并与模型调整的强大性能相匹配（所有模型权重都进行了调整）。这一发现尤其重要，因为大型模型的共享和服务成本很高，而将一个冻结的模型重新用于多个下游任务的能力可以减轻这一负担。我们的方法可以被看作是Li和Liang（2021）最近提出的“前缀调整”的简化，我们提供了与此和其他类似方法的比较。最后，我们表明，与完全模型调整相比，使用软提示调整冻结模型在域转移鲁棒性方面具有优势。