知识提取（KD）已被证明是压缩大规模预训练语言模型的有效方法。然而，现有方法静态地进行KD，例如，学生模型将其输出分布与预定义培训数据集上选定教师模型的输出分布对齐。在这篇论文中，我们探讨了一种动态的知识提炼是否能够使学生根据自己的能力调整学习过程，并考虑到学生的表现和学习效率。我们从教师模式采用、数据选择和KD目标适应三个方面探讨了动态调整。实验结果表明：（1）选择合适的教师模式可以提高学生模式的学习效果；（2） 使用10%的信息量实例进行KD，在大大加快培训速度的同时，取得了相当的绩效；（3） 通过调整不同对齐目标的监督贡献，可以提高学生的成绩。我们发现动态知识提取是有希望的，并讨论了未来更有效的知识发现方法的潜在方向。我们的代码可在https://github.com/lancopku/DynamicKD.