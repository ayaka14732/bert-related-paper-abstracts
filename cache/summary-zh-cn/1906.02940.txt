我们介绍了一种称为Selfie的预训练技术，它代表Selfie监督的图像嵌入。Selfie利用对比预测编码损失（Oord et al.，2018），将伯特的蒙面语言建模概念（Devlin et al.，2019）推广到连续数据，如图像。给定输入图像中的遮罩面片，我们的方法学习从同一图像中采样的其他“干扰”面片中选择正确的面片来填充遮罩位置。这种分类目标避免了预测目标面片的精确像素值的需要。自拍的预训练体系结构包括一个卷积块网络，用于处理补丁，然后是一个注意池网络，用于在预测遮罩补丁之前总结未遮罩补丁的内容。在微调过程中，我们重用通过预训练找到的卷积权重。我们在三个基准（CIFAR-10、ImageNet 32 x 32和ImageNet 224 x 224）上使用不同数量的标记数据（从5%到100%的训练集）评估自拍。与同一网络的标准监督训练相比，我们的预训练方法在所有设置中对ResNet-50提供了一致的改进。值得注意的是，在ImageNet 224 x 224上，每类60个示例（5%），我们的方法将ResNet-50的平均精度从35.6%提高到46.7%，绝对精度提高了11.1个点。我们的预训练方法还提高了ResNet-50训练稳定性，特别是在低数据状态下，通过显著降低不同运行测试精度的标准偏差。