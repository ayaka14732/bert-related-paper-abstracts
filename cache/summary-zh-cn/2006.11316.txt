人类每天读写数千亿条信息。此外，由于大型数据集、大型计算系统和更好的神经网络模型的可用性，自然语言处理（NLP）技术在理解、校对和组织这些信息方面取得了重大进展。因此，在众多应用程序中部署NLP以帮助web用户、社交网络和企业是一个巨大的机会。特别是，我们认为智能手机和其他移动设备作为关键平台部署NLP模型的规模。然而，如今的高精度NLP神经网络模型（如BERT和RoBERTa）在计算上非常昂贵，在Pixel 3智能手机上对文本片段进行分类需要1.7秒。在这项工作中，我们观察到分组卷积等方法已经为计算机视觉网络带来了显著的加速，但其中许多技术尚未被NLP神经网络设计者采用。我们演示了如何用分组卷积替换自我注意层中的若干操作，并将此技术用于一种称为SqueezeBERT的新型网络体系结构中，该网络体系结构的运行速度比基于像素3的BERT快4.3倍，同时在粘合测试集上实现了具有竞争力的准确性。压缩码将被释放。