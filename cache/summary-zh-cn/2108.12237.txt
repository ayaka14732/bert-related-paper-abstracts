高性能神经语言模型已经在广泛的自然语言处理（NLP）任务中获得了最新的结果。然而，当应用于嘈杂的真实数据时，通用基准数据集的结果通常不能反映模型的可靠性和鲁棒性。在这项研究中，我们设计并实现了各种类型的字符级和单词级扰动方法，以模拟输入文本可能有轻微噪声或与NLP系统训练的数据分布不同的真实场景。通过对不同NLP任务的综合实验，我们研究了高性能语言模型（如BERT、XLNet、RoBERTa和ELMo）处理不同类型输入扰动的能力。结果表明，语言模型对输入扰动非常敏感，即使引入微小的变化，其性能也会下降。我们强调模型需要进一步改进，当前的基准没有很好地反映模型的稳健性。我们认为，对扰动输入的评估应该常规地补充广泛使用的基准，以便更现实地理解NLP系统的鲁棒性。