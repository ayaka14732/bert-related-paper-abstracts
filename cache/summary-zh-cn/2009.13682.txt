生成能够描述在标题标记的训练数据中看不到的新对象的图像标题是非常理想的，但也具有挑战性，这一能力在“新对象字幕挑战”（nocaps）中进行了评估。在这个挑战中，除了Coco字幕之外，不允许为模型训练提供额外的图像字幕训练数据。因此，传统的视觉语言预训练（VLP）方法无法应用。本文介绍了在没有字幕注释的情况下进行预训练的视觉词汇预训练（VIVO）。通过打破VLP中成对图像字幕训练数据的依赖性，维梧可以利用大量成对图像标签数据来学习视觉词汇。这是通过预先训练多层变换器模型来完成的，该模型学习将图像级别标记与其相应的图像区域特征对齐。为了解决图像标签的无序性，维梧使用匈牙利匹配损失和蒙面标签预测来进行预训练。我们通过微调预训练的图像字幕模型来验证VIVO的有效性。此外，我们还对我们的模型推断出的视觉文本对齐进行了分析。结果表明，我们的模型不仅可以生成描述新对象的流畅的图像字幕，还可以识别这些对象的位置。我们的单一模式在nocaps上取得了最新的先进成果，并超过了人类苹果酒评分。