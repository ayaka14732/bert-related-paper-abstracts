本文提出了两个直观的量度，歪斜和刻板印象，量化和分析了在处理WinoBias代词解析任务时上下文语言模型中存在的性别偏见。我们发现，在开箱即用的模型中，性别刻板印象与性别倾斜大致呈负相关，这表明这两种形式的偏见之间存在权衡。我们研究了两种方法来缓解偏差。第一种方法是一种在线方法，它可以有效地以牺牲刻板印象为代价消除歪斜。第二个是受以前关于ELMo的工作的启发，涉及到使用增强的性别平衡数据集对BERT进行微调。我们表明，相对于未经整理的微调对应项，这减少了歪斜和刻板印象。然而，我们发现现有的性别偏见基准并没有完全探究职业偏见，因为代词消解可能会被性别偏见其他表现形式的相互关联所混淆。我们的代码可在线获取，网址为https://github.com/12kleingordon34/NLP_masters_project.