当在足够大的范围内进行训练时，自回归语言模型表现出显著的能力，即在仅用几个例子提示后学习新的语言任务。在这里，我们提出了一种简单而有效的方法，将这种少镜头的学习能力转移到多模式环境（视觉和语言）。使用对齐的图像和字幕数据，我们训练一个视觉编码器，将每个图像表示为一系列连续的嵌入，这样一个预先训练过的、用这个前缀提示的冻结语言模型就会生成适当的字幕。由此产生的系统是一个多模式的少数镜头学习者，当以示例为条件时，具有学习各种新任务的惊人能力，表现为多个交错图像和文本嵌入序列。我们证明，通过在各种已建立和新的基准上测量单个模型，它可以快速学习新对象和新视觉类别的单词，仅使用少数示例进行视觉问答，并利用外部知识。