基于Transformer体系结构的语言模型在广泛的NLP任务（如文本分类、问答和令牌分类）上取得了最先进的性能。但是，这种性能通常在高资源语言（如英语、法语、西班牙语和德语）上进行测试和报告。另一方面，印度语言在这些基准中的代表性不足。尽管多语言变压器模型培训中包含了一些印度语言，但这些语言并不是此类工作的主要重点。为了具体评估印度语言的性能，我们通过大量的印地语、孟加拉语和泰卢固语下游任务的实验来分析这些语言模型。在这里，我们比较了微调预训练模型的模型参数与从头开始训练语言模型的效果。此外，我们从经验上反对数据集大小和模型性能之间的严格依赖关系，而是鼓励任务特定的模型和方法选择。对于文本分类任务，我们在印地语和孟加拉语上实现了最先进的性能。最后，我们提出了处理印度语言建模的有效策略，并为社区发布了模型检查点：https://huggingface.co/neuralspace-reverie.