最近有人观察到，在非结构化文本上训练的神经语言模型可以使用自然语言查询隐式地存储和检索知识。在这篇短文中，我们通过微调预先训练的模型来回答问题，而无需接触任何外部环境或知识，从而衡量这种方法的实际效用。我们表明，这种方法随着模型的大小而扩展，并且在回答问题时能够与从外部知识源显式检索答案的开放域系统进行竞争。为了促进再现性和未来的工作，我们在https://goo.gle/t5-cbqa.