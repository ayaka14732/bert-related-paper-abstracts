尽管生成性预训练语言模型在一系列文本生成任务中取得了成功，但在生成过程中需要对基本常识知识进行推理的情况下，它们仍然会受到影响。现有的将常识知识整合到生成性预先训练的语言模型中的方法只是通过对单个知识三元组的后训练来传递关系知识，而忽略了知识图中丰富的联系。我们认为，利用知识图的结构和语义信息有助于常识感知文本生成。在本文中，我们提出了基于多跳推理流（GRF）的生成方法，该方法能够在从外部常识知识图中提取的多关系路径上实现具有动态多跳推理的预训练模型。我们的经验表明，我们的模型在三个文本生成任务上优于现有的基线，这三个任务需要对常识知识进行推理。我们还证明了动态多跳推理模块的有效性，该模型推理出的推理路径为生成提供了理论依据。