为了将神经语音合成扩展到各种实际语言，我们提出了一个多语言端到端框架，将字节输入映射到频谱图，从而允许任意输入脚本。除了对40多种语言的强大结果外，该框架还展示了在极低资源、甚至只有40秒转录记录的少数镜头场景下适应新语言的能力，而不需要词汇、额外语料库、辅助模型或语言专业知识等每种语言资源，从而确保可扩展性。虽然它保留了令人满意的清晰度和自然匹配丰富的资源模型。进行了详尽的对比研究，以揭示该框架对低资源语言的潜力。此外，为了更好地理解其机制，我们提出了一种在多语言模型中提取特定于语言的子网络的新方法。