开放领域问答（QA）的最新机器阅读理解（MRC）模型通常使用远程监督的正面示例和启发式检索的负面示例来训练跨度选择。该培训计划可能解释了经验观察结果，即这些模型在其前几项预测中实现了较高的召回率，但总体准确率较低，因此需要对答案重新排序。我们为跨度提取任务开发了一种简单有效的重新排序方法（重新考虑），该方法改进了大型预训练MRC模型的性能。Reinvision根据从MRC模型的高置信度预测中提取的正面和负面示例进行训练，并使用段落中的跨度注释在较小的候选集上执行以跨度为中心的重新排序。因此，Reinvision学会了消除封闭的假阳性段落，并在四项QA任务上达到了新的水平，包括自然问题与真实用户问题的精确匹配准确率为45.5%，TriviaQA的准确匹配准确率为61.7%。