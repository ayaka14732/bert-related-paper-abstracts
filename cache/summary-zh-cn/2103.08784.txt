多模态预训练推动了视觉和语言研究的巨大进步。这些大规模的预训练模型虽然成功，但由于变压器结构中的跨模态注意造成的巨大计算成本，其推理速度很慢。当应用于实际应用时，这种延迟和计算需求严重阻碍了预训练模型的实际使用。在本文中，我们研究了图像文本检索（ITR），这是V+L应用程序中最成熟的场景，甚至在最近的预训练模型出现之前就已经得到了广泛的研究。我们提出了一种简单而高效的方法LightningDOT，它在不牺牲准确性的情况下，将ITR的推理时间加快了数千倍。LightningDOT通过对三个新的学习目标进行预训练，离线提取特征索引，并采用即时点积匹配和进一步重新排序，消除了耗时的跨模式注意，从而显著加快了检索过程。事实上，LightningDOT在Flickr30k、COCO和Multi30K等多个ITR基准测试中达到了新的技术水平，优于现有的预训练模型，这些模型消耗的计算时间是现有模型的1000倍。代码和培训前检查点位于https://github.com/intersun/LightningDOT.