最近关于机器阅读理解的研究主要集中在文本层面的理解，但还没有达到人类对真实世界文档的视觉布局和内容的理解水平。在本研究中，我们引入了一个新的视觉机器阅读理解数据集VisualMRC，其中给定一个问题和一个文档图像，机器阅读并理解图像中的文本以自然语言回答问题。与现有的以图像形式包含文本的可视化问答（VQA）数据集相比，VisualMRC更注重发展自然语言理解和生成能力。它包含30000多对来自多个网页领域的10000多个文档图像的问题和抽象答案。我们还引入了一个新的模型，将现有的序列扩展到序列模型，并使用大规模文本语料库进行预训练，以考虑文档的视觉布局和内容。使用VisualMRC进行的实验表明，该模型优于基本序列对序列模型和最先进的VQA模型。然而，在大多数自动评估指标上，它的性能仍然低于人类。该数据集将促进旨在连接视觉和语言理解的研究。