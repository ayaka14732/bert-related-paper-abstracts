本文详细研究了视觉语言（VL）任务中改进的视觉表示，并开发了一种改进的目标检测模型，以提供以对象为中心的图像表示。与最广泛使用的\emph{bottom-up and top-down}模型\cite{Anderson 2018bottom}相比，新模型更大，更好地设计用于VL任务，并且在结合多个公共注释对象检测数据集的更大训练语料库上预训练。因此，它可以生成更丰富的视觉对象和概念集合的表示。虽然以前的VL研究主要集中在改进视觉语言融合模型上，而不涉及目标检测模型的改进，但我们发现视觉特征在VL模型中非常重要。在我们的实验中，我们将新的目标检测模型生成的视觉特征输入基于转换器的VL融合模型\oscar\cite{li2020oscar}，并利用改进的方法\short\对VL模型进行预训练，并在广泛的下游VL任务中对其进行微调。我们的结果表明，新的视觉功能显著提高了所有VL任务的性能，在七个公共基准上创造了最新的结果。我们将向公众发布新的目标检测模型。