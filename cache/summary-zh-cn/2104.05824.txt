显著性方法被广泛用于解释神经网络预测，但显著性方法的不同变体甚至在同一模型对同一预测的解释上常常存在分歧。在这些情况下，我们如何确定这些解释何时值得在分析中使用？为了解决这个问题，我们对NLP模型的一个基本类别：神经语言模型的显著性方法进行了全面和定量的评估。我们从两个角度评估预测解释的质量，每个角度都代表了这些解释的一个可取属性：合理性和忠实性。我们的评估是在四个不同的数据集上进行的，这四个数据集是根据现有的人类对句法和语义协议的注释构建的，包括句子层面和文档层面。通过我们的评估，我们确定了显著性方法产生低质量解释的各种方式。我们建议，未来将这些方法应用于神经语言模型的工作应该在得出见解之前仔细验证它们的解释。