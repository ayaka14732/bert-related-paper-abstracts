现代文本分类模型容易受到对抗性示例的影响，这些示例是人类无法识别的原始文本的扰动版本，这些文本被模型误分类。NLP中最近的工作使用基于规则的同义词替换策略生成对抗性示例。这些策略可能导致上下文之外和非自然复杂的代币替换，这很容易被人类识别。我们介绍了BAE，一种黑盒攻击，用于使用来自伯特蒙面语言模型的上下文干扰生成对抗性示例。BAE通过屏蔽部分文本并利用BET-MLM生成屏蔽令牌的替代方案，在原始文本中替换和插入令牌。通过自动和人工评估，我们发现BAE除了生成语法性和语义连贯性比以前的工作有所提高的对抗性示例外，还具有更强的攻击能力。