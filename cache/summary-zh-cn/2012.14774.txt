大规模数据集的可用性推动了神经模型的发展，神经模型可以从单个或多个文档中创建通用摘要。在这项工作中，我们考虑查询聚焦总结（QFS），一个任务，以查询，文档和摘要的形式训练数据是不容易获得的。我们建议将QFS分解为（1）查询建模（即在一组文档中查找支持查询的证据）和（2）条件语言建模（即摘要生成）。我们引入了MaRGE，一个用于证据估计和排序的蒙面ROUGE回归框架，它依赖于摘要和查询的统一表示，因此通用数据中的摘要可以转换为代理查询，以学习查询模型。跨QFS基准测试和查询类型的实验表明，我们的模型实现了最先进的性能，尽管从薄弱的监督中学习。