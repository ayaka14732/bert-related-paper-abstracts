基于变压器的大规模预培训最近彻底改变了视觉和语言（V+L）研究。LXMERT、ViLBERT和UNITER等模型极大地提升了各种V+L任务的最新水平。然而，这些模型中的大量参数阻碍了它们在实际中的应用。并行地，对彩票假设的研究表明，深度神经网络包含小匹配子网络，在隔离训练时，它可以实现比密集网络更高的性能。在这项工作中，我们进行了第一次实证研究，以评估这种可训练的子网络是否也存在于预先训练的V+L模型中。我们使用性能最好的V+L模型之一UNITER作为实验平台，并整合了7个具有代表性的V+L任务进行实验，包括视觉问答、视觉常识推理、视觉蕴涵、引用表达理解、图像文本检索、GQA和NLVR$^2$。通过综合分析，我们将主要发现总结如下。（$i$）很难找到与完整单元模型的性能完全匹配的子网络（即票证）。然而，令人鼓舞的是，我们可以找到50%-70%稀疏度的“轻松”中奖彩票，保持99%的准确率。通过特定任务修剪发现的（$ii$）子网络可以很好地转移到其他任务，而在训练前任务中发现的稀疏度为60%/70%的子网络可以普遍转移，在所有任务中平均匹配98%/96%的完全准确度。（$iii$）对抗性训练可进一步用于提高所发现彩票的性能。