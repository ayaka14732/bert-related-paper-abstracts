我们提出了递归非自回归图到图转换器架构（RNGTr），通过递归应用非自回归图到图转换器，对任意图进行迭代细化，并将其应用于语法依赖分析。我们通过使用BERT预先训练的细化模型，在几个依赖语料库上展示了RNGTr的威力和有效性。我们还介绍了语法转换器（SynTr），一种类似于我们的细化模型的非递归解析器。RNGTr可以提高来自Universal Dependencies Treebanks、英语和汉语Penn Treebanks以及德语CoNLL2009语料库的13种语言上的各种初始解析器的准确性，甚至比SynTr取得的最新成果还要高，显著提高了所有测试语料库的最新水平。