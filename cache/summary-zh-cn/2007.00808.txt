与稀疏检索相比，在密集的学习表示空间中进行文本检索具有许多有趣的优点。然而，密集检索（DR）的有效性通常需要与稀疏检索相结合。在本文中，我们发现主要的瓶颈在于训练机制，其中训练中使用的否定实例不能代表测试中的无关文档。本文提出了近似最近邻否定对比估计（ANCE），这是一种训练机制，它从语料库的近似最近邻（ANN）索引中构造否定，并随学习过程并行更新，以选择更真实的否定训练实例。这从根本上解决了DR训练和测试中使用的数据分布之间的差异。在我们的实验中，ANCE增强了BERT-Siamese DR模型，使其优于所有竞争密集和稀疏检索基线。它几乎与稀疏检索和使用点积在表示空间中重新排序的精度相匹配，并提供了近100倍的加速。