最近，预训练语言模型（LMs）的成功激发了人们对其语言能力的广泛兴趣。然而，了解LM表示是否对符号推理任务有用的努力是有限和分散的。在这项工作中，我们提出了八个推理任务，这些任务在概念上需要诸如比较、连接和组合之类的操作。一个基本的挑战是理解LM在任务上的性能是应该归因于预先训练的表示还是任务数据的微调过程。为了解决这个问题，我们提出了一个评估协议，该协议包括零炮评估（无微调），以及将微调LM的学习曲线与多个控件的学习曲线进行比较，从而描绘出LM能力的丰富画面。我们的主要发现是：（a）不同的LMs表现出质的不同推理能力，例如，RoBERTa成功地完成了BERT完全失败的推理任务；（b） LMs不以抽象的方式进行推理，并且依赖于上下文，例如，虽然RoBERTa可以比较年龄，但它只能在年龄在人类年龄的典型范围内时进行比较；（c） 在一半的推理任务中，所有模型都完全失败。我们的发现和基础设施可以帮助未来设计新的数据集、模型和培训前目标函数。