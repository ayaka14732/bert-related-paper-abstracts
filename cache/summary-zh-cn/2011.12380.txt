关系抽取（RE）包括从文本中自动识别和构造感兴趣的关系。最近，BERT改进了几个NLP任务的顶级性能，包括RE。然而，在机器学习体系结构和迁移学习策略中使用BERT的最佳方法仍然是一个悬而未决的问题，因为它高度依赖于每个特定的任务和领域。在这里，我们探讨了各种基于BERT的架构和迁移学习策略（即冻结或微调），用于在两个语料库上执行生物医学RE任务。在经过测试的体系结构和策略中，我们的*BERT segMCNN（具有微调功能）在两个语料库上达到了比最先进水平更高的性能（ChemProt和PGxCorpus语料库的绝对改善率分别为1.73%和32.77%）。更一般地说，我们的实验说明了使用BERT进行微调的预期兴趣，但也说明了除了BERT经典利用的上下文之外，使用结构信息（带有句子切分）的未开发优势。