文本排序的目标是生成从语料库中检索的文本的有序列表，以响应查询。尽管文本排序最常见的公式是搜索，但在许多自然语言处理应用程序中也可以找到该任务的实例。这项调查提供了一个文本排名与神经网络结构称为变压器概述，其中伯特是最著名的例子。变形金刚和自我监督预训练的结合导致了自然语言处理（NLP）、信息检索（IR）等领域的范式转变。在这项调查中，我们提供了现有工作的综合，作为希望更好地了解如何将变形金刚应用于文本排序问题的从业者和希望从事这一领域工作的研究人员的单一切入点。我们涵盖了广泛的现代技术，分为两个高级类别：在多阶段体系结构中执行重新排序的变压器模型和直接执行排序的密集检索技术。在我们的调查中有两个主题：处理长文档的技术（NLP中的典型逐句处理除外），以及处理有效性（即结果质量）和效率（例如查询延迟、模型和索引大小）之间权衡的技术。虽然transformer体系结构和预训练技术是最近的创新，但它们如何应用于文本排序的许多方面都得到了比较好的理解，并代表了成熟的技术。然而，仍然存在许多开放性的研究问题，因此，除了为文本排名奠定预训练变形金刚的基础外，本次调查还试图预测该领域的发展方向。