我们解决了生成紧凑模型的问题，最大限度地提高了给定模型大小的精度。标准解决方案是使用量化感知训练训练网络，其中权重在训练期间量化，梯度用直通估计器近似。在本文中，我们将此方法扩展到int8定点量化之外的工作，使用极端压缩方法，其中STE引入的近似是严重的，例如乘积量化。我们的建议是在每次前进过程中仅量化不同的随机权重子集，允许无偏梯度流过其他权重。控制噪声的数量及其形式可以在保持原始模型性能的同时实现极高的压缩率。因此，在自然语言处理和图像分类中，我们在准确性和模型大小之间建立了新的最先进的折衷方案。例如，将我们的方法应用于最先进的Transformer和ConvNet体系结构，通过将RoBERTa压缩到14MB，我们可以在MNLI上实现82.5%的精度，通过将EfficientNet-B3压缩到3.3MB，我们可以在ImageNet上实现80.0 top-1精度。