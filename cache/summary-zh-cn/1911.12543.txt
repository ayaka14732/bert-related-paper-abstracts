最近的工作通过让语言模型（LM）填补诸如“Obama是一个职业”等提示的空白，对语言模型（LM）中包含的知识进行了研究，得出了有趣的结果。这些提示通常是手动创建的，很可能是次优的；另一个提示，如“奥巴马作为一个![3]”可能会导致更准确地预测正确的职业。因此，如果给出不适当的提示，我们可能无法检索LM确实知道的事实，因此任何给定的提示都只能提供LM中包含的知识的下限估计。在本文中，我们试图通过自动发现在查询过程中使用的更好提示来更准确地估计LMs中包含的知识。具体来说，我们提出了基于挖掘和基于解释的方法来自动生成高质量和多样的提示，以及集成方法来组合来自不同提示的答案。在用于从LMs中提取关系知识的LAMA基准上进行的大量实验表明，我们的方法可以将准确率从31.1%提高到39.6%，从而为LMs的知识提供更严格的下限。我们已经在发布了代码和生成的LM提示符和查询归档（LPAQA）https://github.com/jzbjyb/LPAQA.