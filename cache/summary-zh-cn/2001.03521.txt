当前的语法错误校正（GEC）模型通常将任务视为序列生成，这需要大量注释的数据并限制应用在数据受限的设置中。我们试图结合来自预先训练的语言模型的上下文信息，以利用注释并使多语言场景受益。结果表明，双向编码器表示从变压器（伯特）在语法错误纠正任务的强大潜力。