由于推理过程中的大量计算负载和内存开销，特别是当目标设备的计算资源（如移动设备或边缘设备）有限时，广泛使用的Transformer架构的部署具有挑战性。量化是解决这些挑战的有效技术。我们的分析表明，对于给定数量的量化比特，每个转换器块以不同的方式对翻译质量和推理计算作出贡献。此外，即使在嵌入块中，每个单词的贡献也大不相同。相应地，我们提出了一种混合精度量化策略，以极低的比特数（例如，低于3比特）表示变压器权重。例如，对于嵌入块中的每个字，我们根据统计特性分配不同的量化位。我们的量化变压器模型比基线模型小11.8$\倍，BLEU小于-0.5。我们实现了8.3$\倍的运行时内存占用减少和3.5$\倍的加速（Galaxy N10+），因此我们提出的压缩策略能够有效地实现设备上的NMT。