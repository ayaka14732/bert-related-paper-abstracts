跨语言词义消歧（WSD）解决了在给定语境下跨语言消除歧义词的挑战。经过预训练的BERT嵌入模型已被证明能有效地提取单词的上下文信息，并已作为特征融入到许多最先进的WSD系统中。为了研究如何将语法信息添加到BERT嵌入中，从而产生语义和语法结合的单词嵌入，本项目通过生成依赖解析树并将单词的相对关系编码到输入嵌入中，提出了串联嵌入。还提出了两种方法来减小级联嵌入的大小。实验结果表明，语法嵌入的高维性对分类任务构成了障碍，需要在未来的研究中进一步解决。