最近关于口语理解（SLU）的许多工作至少局限于以下三种方式中的一种：模型是在oracle文本输入上训练的，忽略了ASR错误；模型是在没有时隙值的情况下仅预测意图；或者模型是在大量内部数据上训练的。在本文中，我们提出了一个干净和通用的框架，从转录或未翻译的语音中直接通过半监督从语音中学习语义，以解决这些问题。我们的框架建立在预训练的端到端（E2E）ASR和自监督语言模型（如BERT）的基础上，并在有限数量的目标SLU数据上进行微调。我们研究了ASR组件的两种半监督设置：转录语音的监督预训练，以及用自监督语音表示（如wav2vec）替换ASR编码器的无监督预训练。同时，我们确定了评估SLU模型的两个基本标准：环境噪声鲁棒性和E2E语义评估。ATIS的实验表明，我们的SLU框架与语音作为输入可以执行与那些使用Oracle文本作为语义理解的输入，即使环境噪声存在，并且有限数量的标记语义数据可用于训练。