我们介绍了一种自监督视觉表示模型BEiT，它代表来自图像转换器的双向编码器表示。继自然语言处理领域的BERT之后，我们提出了一个蒙面图像建模任务来预训练视觉变换器。具体来说，在我们的预训练中，每个图像都有两个视图，即图像块（如16x16像素）和视觉标记（即离散标记）。我们首先将原始图像“标记化”为视觉标记。然后我们随机屏蔽一些图像块，并将它们输入主干变压器。预训练的目标是基于损坏的图像补丁恢复原始视觉标记。在预训练BEiT之后，我们通过在预训练编码器上附加任务层，直接微调下游任务上的模型参数。在图像分类和语义分割方面的实验结果表明，该模型与以前的预训练方法相比取得了较好的效果。例如，基本尺寸BEiT在ImageNet-1K上达到83.2%的top-1精度，在相同设置下显著优于从头开始的DeiT训练（81.8%）。此外，大型BEiT仅使用ImageNet-1K就获得了86.3%，甚至在ImageNet-22K的监督预训练中也超过了ViT-L（85.2%）。代码和预训练模型可在https://aka.ms/beit.