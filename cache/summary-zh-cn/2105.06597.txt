GPT-3等大规模预培训的最新进展允许从给定提示生成看似高质量的文本。然而，这类生成系统通常会遇到幻觉事实的问题，并且其固有设计不是为了包含有用的外部信息。扎根生成模型似乎提供了补救措施，但它们的培训通常依赖于很少可用的并行数据，其中为上下文提供了相应的信息相关文档。我们提出了一个框架，通过在语言模型信号上联合训练接地生成器和文档检索器来缓解这种数据约束。该模型学习如何奖励在生成过程中具有最高效用的文档检索，并使用混合专家（MoE）集成将其仔细组合，生成后续文本。我们证明，生成器和检索器都可以利用这种联合训练，协同工作，在散文和对话生成中生成更多信息和相关的文本。