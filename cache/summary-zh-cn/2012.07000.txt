推理是实现完全视觉理解的关键能力。为了开发具有认知水平的视觉理解和推理能力的机器，引入了视觉常识推理（VCR）任务。在VCR中，给定一个关于图像的具有挑战性的问题，机器必须正确回答，然后提供一个理由来证明其答案。采用强大的BERT模型作为主干学习图像内容和自然语言的联合表示的方法在VCR上显示了良好的改进。然而，现有的方法都没有在视觉常识推理中使用常识知识，我们相信这将对这项任务有很大帮助。在常识知识的支持下，即使图像中没有描述所需的信息，复杂的问题也可以通过认知推理来回答。因此，我们将常识知识融入到跨模态的BERT中，并提出了一种新的知识增强的视觉和语言BERT（简称KVL-BERT）模型。除了以视觉和语言内容为输入外，从概念网中提取的外部常识知识被集成到多层转换器中。为了保留原始句子的结构信息和语义表示，我们提出使用相对位置嵌入和掩蔽自我注意来削弱注入的常识知识与输入序列中其他无关成分之间的影响。与其他任务特定模型和一般任务不可知预训练模型相比，我们的KVL-BERT的性能大大优于它们。