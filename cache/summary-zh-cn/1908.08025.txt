代词分解是自然语言理解的一个主要领域。然而，大规模的训练集仍然很少，因为手动标记数据的成本很高。在这项工作中，我们介绍了WikiCREM（WikipediaCoreferencesMasked），这是一个大规模但准确的代词消歧实例数据集。我们结合WikiCREM数据集使用基于语言模型的代词解析方法。我们在一系列不同且具有挑战性的共指消解问题上比较了一系列模型，其中我们在7个数据集中的6个数据集（如GAP、DPR、WNLI、PDP、WinoBias和WinGender）上匹配或优于先前的最先进方法。我们发布了我们的模型，用于解决代词消歧问题。