预训练语言模型（PLM）在自然语言理解任务中取得了巨大的成功。尽管针对英语等语言的不同学习方案——微调、零次学习和少次学习——已经得到了广泛的探索和比较，但在汉语中，公平、全面地评估和比较这些方法的工作相对较少，因此阻碍了累积的进步。本文介绍了中国第一个综合性少数镜头学习评价基准——汉语少数镜头学习评价基准（FewCLUE）。它包括九个任务，从单句和句子对分类任务到机器阅读理解任务。我们系统地评估了五种最先进的（SOTA）少数镜头学习方法（包括PET、ADAPET、LM-BFF、P-tuning和EFL），并在新构建的FewCLUE基准上比较了它们与微调和零镜头学习方案的性能。实验结果表明：1）不同的少镜头学习方法的效果对所应用的预训练模型敏感；2） PET和P-tuning分别与RoBERTa和ERNIE一起实现最佳的整体性能。我们的基准用于NLPCC 2021的少数镜头学习竞赛。此外，我们还提供了一个用户友好的工具包，以及一个在线排行榜，以帮助促进汉语学习的进一步进展。我们提供了不同学习方法的基线性能，为今后的研究提供参考。