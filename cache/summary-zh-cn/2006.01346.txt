预先训练的模型为许多NLP任务带来了显著的改进，并得到了广泛的分析。但对于微调对特定任务的影响知之甚少。直觉上，人们可能同意，预先训练的模型已经学习了单词的语义表示（例如，同义词彼此更接近），而微调进一步提高了其需要更复杂推理（例如，共指解析、实体边界检测等）的能力。然而，如何分析和定量地验证这些论点是一项具有挑战性的任务，很少有人关注这一主题。在本文中，受大多数探测任务涉及识别匹配的短语对（例如，共指需要匹配实体和代词）的观察的启发，我们提出了一种成对探测来理解机器阅读理解（MRC）任务中的伯特微调。具体来说，我们确定了MRC中的五种现象。根据成对探测任务，我们比较了预训练和微调的BERT的每一层隐藏表示的性能。所提出的成对探测缓解了不准确模型训练的干扰问题，并进行了稳健的定量比较。我们的实验分析得出了非常有信心的结论：（1）微调对基本信息、低级信息和一般语义任务的影响很小。（2） 对于下游任务所需的特定能力，微调的BERT优于预先训练的BERT，并且在第五层之后，这种差距是明显的。