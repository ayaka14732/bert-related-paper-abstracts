尽管使用基于BERT的编码器对视觉语言（VL）进行了令人印象深刻的预训练，用于VL理解和生成的通用编码器-解码器的预训练仍然具有挑战性。困难源于两个学科固有的不同特性，例如，VL理解任务利用跨模式的无限制消息传递，而生成任务仅采用视觉到文本的消息传递。在本文中，我们从编码器-解码器结构的两流解耦设计开始，其中两个解耦的跨模式编码器和解码器分别执行每种类型的代理任务，以同时理解VL和生成预训练。此外，对于VL预训练，主要的方法是用掩码令牌替换一些输入的视觉/文字令牌，并强制使用多模式编码器/解码器重建原始令牌，但在对下游任务进行微调时不涉及掩码令牌。作为替代方案，我们提出了一种主要的定时采样策略，该策略通过预训练编码器-解码器以两次通过的方式优雅地缓解这种差异。大量的实验表明，通过对四个VL理解和生成下游任务进行微调，我们的预训练编码器-解码器具有令人信服的通用性。源代码位于\url{https://github.com/YehLi/TDEN}.