时隙填充、翻译、意图分类和语言识别（STIL）是一项新提出的多语言自然语言理解（NLU）任务。通过同时执行插槽填充和翻译为单一输出语言（本例中为英语），下游系统组件的某些部分可以是单语的，从而降低开发和维护成本。使用多语言BART模型（Liu等人，2020）给出了结果，该模型使用MultiATIS++数据集对7种语言进行了微调。在未进行翻译的情况下，对于测试的语言，mBART的性能与当前最先进的系统（Xu等人（2020年）的跨语言BERT）相当，具有更好的平均意图分类准确率（96.07%对95.50%），但较差的平均时隙F1（89.87%对90.81%）。当执行同声翻译时，平均意图分类精度相对仅降低1.7%，平均时隙F1相对仅降低1.2%。