我们用预先训练好的语言模型来研究基于知识的对话生成。为了在容量约束下利用冗余的外部知识，我们建议在预先训练的语言模型定义的响应生成中配备一个知识选择模块，以及一种无监督的方法来联合优化知识选择和响应生成，并使用未标记的对话。在两个基准上的实证结果表明，我们的模型在自动评估和人类判断方面都显著优于最先进的方法。