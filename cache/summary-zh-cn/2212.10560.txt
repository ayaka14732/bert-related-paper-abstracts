大型“指令调整”语言模型（经过微调以响应指令）已经证明了将零样本推广到新任务的非凡能力。然而，它们在很大程度上依赖于数量、多样性和创造性有限的人工书面指令数据，因此阻碍了调优模型的通用性。我们引入了Self instruction，这是一个框架，用于通过自举自己的几代来提高预训练语言模型的指令跟随能力。我们的流水线从语言模型中生成指令、输入和输出样本，然后在使用它们来微调原始模型之前对它们进行修剪。将我们的方法应用于普通GPT3，我们在Super NaturalInstructions上比原始模型有33%的绝对改进，与使用私人用户数据和人工注释训练的InstructGPT_001的性能不相上下。为了进一步评估，我们为新任务策划了一组专家书面指令，并通过人工评估表明，使用Self instruction调整GPT3的性能大大优于使用现有公共指令数据集，仅与InstructionGPT_001相差5%的绝对差距。Self instruction提供了一种几乎无注释的方法，用于将预先训练的语言模型与指令对齐，我们发布了大型合成数据集，以促进未来对指令调优的研究。