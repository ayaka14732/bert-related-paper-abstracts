预先训练的语言模型（LMs）可能会使其训练语料库中产生的对下游模型的偏见永久化。我们关注与给定名称（例如，Donald）表示相关的工件，根据语料库，这些工件可能与特定实体相关，如下一个标记预测（例如，Trump）所示。虽然在某些情况下有帮助，但在不明确或不适当的情况下也会发生根植。例如，为“Donald is a”生成的结尾与其他名字的结尾有很大的不同，并且通常具有超过平均水平的负面情绪。我们用阅读理解探针展示了名字扰动改变模型答案对下游任务的潜在影响。作为一线希望，我们的实验表明，对不同语料库进行额外的预训练可能会减轻这种偏见。