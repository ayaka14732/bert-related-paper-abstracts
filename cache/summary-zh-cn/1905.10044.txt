在本文中，我们研究了自然出现的是/否问题——也就是说，它们是在无提示和无约束的环境中产生的。我们建立了一个阅读理解的数据集，BoolQ，这些问题，并表明他们出乎意料地具有挑战性。他们经常查询复杂的、非因素信息，并且需要复杂的推论来解决。我们还探讨了一系列迁移学习基线的有效性。我们发现，从蕴涵数据传输比从释义或提取QA数据传输更有效，而且令人惊讶的是，即使从大量预先训练的语言模型（如BERT）开始，它仍然非常有益。我们最好的方法是在MultiNLI上训练BERT，然后在我们的训练集上重新训练它。它实现了80.4%的准确率，而人工注释器的准确率为90%（和62%的多数基线），为未来的工作留下了巨大的差距。