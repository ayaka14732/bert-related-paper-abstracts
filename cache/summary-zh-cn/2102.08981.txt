大规模图像字幕和视觉答疑数据集的可用性极大地促进了最近在视觉和语言预培训方面取得的成功。然而，收集这些数据集时，通常会有从其原始目标任务（例如，图像标题生成）继承的过度限制性需求，这限制了结果数据集的规模和多样性。我们通过放松概念说明3M（CC3M）[Sharma等人，2018]中使用的数据收集管道，进一步推动视觉和语言训练前数据的限制，并引入概念说明12M（CC12M），这是一个具有1200万图像-文本对的数据集，专门用于视觉和语言训练前。我们对该数据集进行了分析，并针对CC3M在多个下游任务中的有效性进行了基准测试，重点是长尾视觉识别。我们的结果清楚地说明了扩大视觉和语言任务的训练前数据的好处，正如nocaps和概念性字幕基准的最新结果所表明的那样。