模型体系结构和模型预训练的发展推动了自然语言处理的最新进展。变压器结构有助于构建更高容量的模型，而预培训使其能够有效地将此容量用于各种任务\textit{Transformers}是一个开源库，目标是向更广泛的机器学习社区开放这些进步。该库包含在统一API下精心设计的最先进的Transformer架构。支持这个图书馆的是一个由社区制作并可供社区使用的预训练模型的策展收藏\textit{Transformers}被设计为可由研究人员扩展，对从业者来说简单，并且在工业部署中快速而健壮。该库位于\url{https://github.com/huggingface/transformers}.