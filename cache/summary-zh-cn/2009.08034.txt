8位整数推理作为减少深度神经网络延迟和存储的一个有前途的方向，近年来取得了很大的进展。另一方面，以前的系统在复杂模型中的某些函数（例如，Transformer中的Softmax）仍然依赖32位浮点，并且大量使用量化和反量化。在这项工作中，我们表明，在对转换器结构进行了原则性修改（称为Integer Transformer）后，可以导出（几乎）完全8位整数推断算法，即规模传播。必要时采用去量化，使网络更加高效。我们在WMT16 En<->Ro、WMT14 En<->De和En->Fr翻译任务以及WikiText-103语言建模任务上的实验表明，全8位转换器系统实现了与浮点基线相当的性能，但需要的内存占用量减少了近4倍。