通过引入一小部分附加参数，探针可以学习使用特征表示（例如，上下文嵌入）以有监督的方式解决特定的语言任务（例如，依赖项解析）。这种探测任务的有效性被视为预先训练的模型编码语言知识的证据。然而，这种评估语言模型的方法由于探针本身所学知识量的不确定性而受到影响。作为对这些工作的补充，我们提出了一种无参数探测技术，用于分析预先训练的语言模型（例如，BERT）。我们的方法不需要探测任务的直接监督，也不需要在探测过程中引入额外的参数。我们在BERT上的实验表明，使用我们的方法从BERT中恢复的语法树明显优于语言上未提供信息的基线。我们进一步将经验诱导的依赖结构输入到下游情绪分类任务中，发现其改进与人类设计的依赖模式兼容，甚至优于人类设计的依赖模式。