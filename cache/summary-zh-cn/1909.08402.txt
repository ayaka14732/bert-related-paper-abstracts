在本文中，我们重点讨论使用简短描述性文本（封面简介）和附加元数据对书籍进行分类。基于深层神经语言模型BERT，我们演示了如何将文本表示与元数据和知识图嵌入相结合，从而对作者信息进行编码。与标准的BERT方法相比，我们在分类任务中获得了更好的结果。对于使用八个标签的更粗粒度分类，我们的F1分数为87.20，而使用343个标签的详细分类的F1分数为64.70。我们公开实验的源代码和经过训练的模型