多头注意在变压器模型最近的成功中起着至关重要的作用，这导致在各种应用中，与传统注意相比，性能得到了一致的改进。人们普遍认为，这种有效性源于共同参与多个职位的能力。在本文中，我们首先证明了联合注意多个位置并不是多头注意的一个独特特征，因为多层单头注意也注意多个位置并且更有效。然后，我们认为多头注意的主要优点是训练的稳定性，因为当参加相同数量的位置时，多头注意的层数比单头注意的层数少。例如，24层16头变压器（BERT large）和384层单头变压器具有相同的总注意头数量和大致相同的模型尺寸，而多头变压器则明显较浅。同时，我们表明，随着深度学习的最新进展，我们可以成功地稳定384层变压器的培训。由于培训难度不再是一个瓶颈，因此，在不调整超参数的情况下，单头变压器可实现持续的性能改进。