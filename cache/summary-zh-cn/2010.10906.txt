在这项工作中，我们介绍了创建基于伯特和伊莱克特拉的德语模型GBERT和GELECTRA的实验。通过改变输入训练数据、模型大小和全词掩蔽（WWM）的存在，我们能够在一组文档分类和命名实体识别（NER）任务中实现SoTA性能，适用于基本和大型模型。我们采用评估驱动的方法来训练这些模型，我们的结果表明，添加更多数据和利用WWM都可以提高模型性能。通过对现有德国模型的基准测试，我们表明这些模型是迄今为止最好的德国模型。我们经过培训的模型将向研究界公开。