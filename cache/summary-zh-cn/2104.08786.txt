当仅使用少量训练样本进行预训练时，与完全监督微调的大型预训练语言模型相比，GPT-3等大型预训练语言模型显示出了具有竞争力的结果。我们证明了样本提供的顺序可能是接近最先进水平和随机猜测性能之间的差异：本质上，一些排列是“奇妙的”，而另一些则不是。我们详细分析了这一现象，确定：它存在于不同的模型大小（即使是最大的当前模型），它与特定的样本子集无关，并且一个模型的给定良好排列不能转移到另一个模型。虽然可以使用开发集来确定执行哪些排列，但这将与少数镜头设置不同，因为它需要额外的注释数据。相反，我们使用语言模型的生成性来构建一个人工开发集，并基于该集合中候选排列的熵统计信息来识别性能提示。我们的方法改进了GPT族模型，在11个不同的文本分类任务中平均提高了13%。