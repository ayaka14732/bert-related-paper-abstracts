从自然语言任务的变换模型中得到的惊人结果引起了视觉界的兴趣，他们开始研究它们在计算机视觉问题中的应用。在其显著的优点中，变压器能够对输入序列元素之间的长期依赖性进行建模，并支持序列的并行处理，与循环网络（如长短时记忆（LSTM））相比。与卷积网络不同，变压器的设计需要最小的电感偏置，并且自然适合作为设定函数。此外，变压器的简单设计允许使用类似的处理块处理多种模式（例如，图像、视频、文本和语音），并展示了对超大容量网络和大型数据集的极好可扩展性。这些优势使得使用Transformer networks的许多愿景任务取得了令人振奋的进展。本调查旨在全面概述计算机视觉学科中的变压器模型。我们首先介绍变压器成功背后的基本概念，即自我关注、大规模预培训和双向编码。然后，我们介绍了变形金刚在视觉中的广泛应用，包括流行的识别任务（例如，图像分类、对象检测、动作识别和分割）、生成建模、多模式任务（例如，视觉问答、视觉推理和视觉接地）、视频处理（例如，活动识别、视频预测）、低级视觉（例如，图像超分辨率、图像增强和彩色化）和3D分析（例如，点云分类和分割）我们比较了流行技术在建筑设计和实验价值方面各自的优势和局限性。最后，我们对开放的研究方向和未来可能的工作进行了分析。