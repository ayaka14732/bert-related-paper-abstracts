大型预训练语言模型（LMs）不仅能够恢复语言知识，而且能够恢复事实和常识知识。为了访问存储在基于掩模的LMS中的知识，我们可以使用完形风格的问题，并让模型填入空白。与结构化知识库相比，它具有灵活性优势，但缺点是无法为特定的信息需求找到正确的查询。受人类消除歧义行为的启发，我们建议通过示例查询LMs。为了澄清矛盾的问题“诺伊尔为谁效力？”，一个成功的策略是使用另一个主题来证明这种关系，例如，“罗纳尔多为葡萄牙效力。诺伊尔为谁效力？”。我们将这种通过示例查询的方法应用于LAMA探针，在仅提供10个演示的情况下，T-REx数据上的BERT large获得了高达37.8%的实质性改进，甚至超过了使用多达40个问题复述查询模型的基线。示例是通过模型的上下文提供的，因此既不需要微调，也不需要额外的前向传递。这表明，如果我们以正确的方式查询模型，LMs比以前假设的包含更多的事实和常识知识。