问答（QA）模型显示了快速的进步，这得益于大型、高质量基准数据集的可用性。这种带注释的数据集收集起来既困难又昂贵，而且很少以英语以外的其他语言存在，这使得其他语言的培训QA系统具有挑战性。构建大型单语训练数据集的另一种方法是开发跨语言系统，该系统可以转换为目标语言，而不需要该语言的训练数据。为了发展这种系统，必须投资于高质量的多语文评价基准，以衡量进展情况。我们提出了MLQA，一个多方向一致的采掘QA评估基准，旨在促进这一领域的研究。MLQA包含7种语言的QA实例，即英语、阿拉伯语、德语、西班牙语、印地语、越南语和简体中文。它由超过12K个英语QA实例和5K个其他语言QA实例组成，每个QA实例平均在4种语言之间并行。MLQA是在维基百科文章中使用一种新的对齐上下文策略构建的，并作为现有抽取QA数据集的跨语言扩展。我们在MLQA上评估了当前最先进的跨语言表示，并提供了基于机器翻译的基线。在所有情况下，迁移结果都明显落后于培训语言表现。