由于Transformer能够以高效的方式捕获序列信息，因此得到了广泛的应用。然而，最近的开发，如BERT和GPT-2，只提供了注重有效性的重型体系结构。在本文中，我们探讨了三种精心设计的光变压器结构，以确定变压器是否能够以较少的计算产生具有竞争力的结果。在语言模型基准数据集上的实验结果表明，这种折衷是有希望的，光变压器最多可以减少70%的参数，同时与标准变压器相比，获得了竞争性的困惑。源代码是公开的。