在本文中，我们提出了一种新的模型压缩方法，通过渐进模块替换来有效地压缩BERT。我们的方法首先将原始的BERT划分为几个模块，并构建它们的紧凑替代品。然后，我们用它们的替代品随机替换原始模块，以训练紧凑模块模仿原始模块的行为。我们通过培训逐步增加更换的可能性。通过这种方式，我们的方法在原始模型和紧凑模型之间带来了更深层次的交互。与以前的知识提取方法相比，我们的方法没有引入任何额外的损失函数。我们的方法在GLUE基准上优于现有的知识提取方法，显示了模型压缩的新视角。