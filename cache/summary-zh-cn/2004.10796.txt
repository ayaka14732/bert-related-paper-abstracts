即使是从静止图像的单个帧，人们也可以对图像在帧之前、之后和帧之外的动态故事进行推理。例如，如果有一个人在水中挣扎着漂浮，我们可以推断他是在过去某个时候掉进水里的，他现在的目的是为了活下去，他在不久的将来需要帮助，否则他会被冲走。我们提出了VisualMet，这是视觉常识推理任务的新框架，用于预测之前可能发生的事件、接下来可能发生的事件以及当前人们的意图。为了支持对视觉常识推理的研究，我们介绍了第一个大规模的视觉常识图存储库，该存储库由超过140万个视觉常识推理的文本描述组成，这些文本描述在60000个不同的图像集上仔细注释，每个图像与之前和之后的简短视频摘要配对。此外，我们在图像中出现的人和文本常识描述中提到的人之间提供了人员基础（即共同参考链接），允许图像和文本之间更紧密的集成。我们在这项任务上建立了强大的基线性能，并证明了视觉和文本常识推理之间的整合是关键，并战胜了非整合方案。