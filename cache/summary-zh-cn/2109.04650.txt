GPT-3显示了在数千亿规模数据上训练的大规模语言模型（LMs）显著的上下文学习能力。在这里，我们讨论了GPT-3论文中较少报道的一些遗留问题，如非英语LM、不同大小模型的性能以及最近引入的即时优化对上下文学习的影响。为了实现这一点，我们引入HyperCLOVA，一种82B GPT-3的韩国语变体，在以韩国人为中心的560B标记语料库上进行训练。通过韩语特有的标记化，HyperCLOVA和我们的培训配置在韩语的各种下游任务中显示了最先进的零射击和少量射击学习性能。此外，我们还展示了基于即时学习的性能优势，并演示了如何将其集成到即时工程管道中。然后，我们讨论了通过引入HyperCLOVA studio（一种交互式即时工程界面），向非ML专家提供AI原型功能，实现无代码AI范式的可能性。最后，我们通过三个成功的内部应用展示了我们方法的潜力。