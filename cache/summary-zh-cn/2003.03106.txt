海量数字数据处理提供了广泛的机会和好处，但代价是危及个人数据隐私。匿名化包括从数据中删除或替换敏感信息，使其能够用于不同目的，同时保护个人隐私。多年来，人们提出了许多自动匿名系统；然而，根据数据类型、目标语言或培训文件的可用性，这项任务仍然具有挑战性。在过去的两年中，新的深度学习模型的出现为自然语言处理领域的最新发展带来了巨大的进步。这些进步最引人注目的是由BERT（谷歌在2018年提出的一种模型）和在数百万文档上预先训练的共享语言模型。在本文中，我们使用基于BERT的序列标记模型对几个西班牙语临床数据集进行了一系列匿名实验。我们还将BERT算法与其他算法进行了比较。实验表明，一个简单的基于BERT的通用领域预训练模型在没有任何特定领域特征工程的情况下获得了具有竞争力的结果。