基于转换器的体系结构已经成为一系列自然语言处理任务的事实模型。特别是，基于伯特的模型在胶水任务、CoNLL-03和小队中取得了显著的准确性提高。然而，基于BERT的模型具有令人望而却步的内存占用和延迟。因此，在资源受限的环境中部署基于BERT的模型已成为一项具有挑战性的任务。在这项工作中，我们使用二阶Hessian信息对微调的BERT模型进行了广泛的分析，并利用我们的结果提出了一种将BERT模型量化到超低精度的新方法。特别是，我们提出了一种新的分组量化方案，并使用基于Hessian的混合精度方法进一步压缩模型。我们在SST-2、MNLI、CoNLL-03和STAND的BERT下游任务上广泛测试了我们提出的方法。我们可以实现与基线相当的性能，性能降低最多2.3\%$，即使是超低精度量化到2位，对应的模型参数压缩高达13美元倍，嵌入表压缩和激活高达4美元倍。在所有的任务中，我们观察到贝特的表现损失最高。通过探讨基于Hessian的分析和可视化，我们发现这与当前的训练/微调策略不适用于全队这一事实有关。