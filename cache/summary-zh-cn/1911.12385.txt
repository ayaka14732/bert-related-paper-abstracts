对于具有大型词汇表的序列模型，大多数网络参数位于输入和输出层。在这项工作中，我们描述了一种新的方法DeFINE，用于有效地学习深层令牌表示。我们的体系结构使用具有新颖跳跃连接的分层结构，允许使用低维输入和输出层，减少总参数和训练时间，同时提供与现有方法类似或更好的性能。定义可以很容易地合并到新的或现有的序列模型中。与包括自适应输入表示在内的最新方法相比，该技术的复杂度降低了6%到20%。在WikiText-103上，DeFINE将Transformer XL的总参数减少一半，对性能的影响最小。在Penn Treebank上，DeFINE将AWD-LSTM提高了4个点，参数减少了17%，实现了与具有较少参数的最先进方法相当的性能。对于机器翻译，DeFINE将Transformer模型的效率提高了约1.4倍，同时提供了类似的性能。