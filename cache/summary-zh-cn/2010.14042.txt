使用类似转换器的体系结构（如BERT）利用大量未标记的数据在最近得到了广泛的应用，这是因为它们在学习通用表示方面的有效性，然后可以针对下游任务进行进一步的微调，以获得更大的成功。然而，从经济和环境的角度来看，培训这些模型可能成本高昂。在这项工作中，我们研究了如何有效地使用未标记的数据：通过探索任务特定的半监督方法，交叉视图训练（CVT），并将其与任务不可知的BERT在多个环境中进行比较，包括领域和任务相关的英语数据。CVT使用了更轻的模型体系结构，我们证明了它在一组序列标记任务上实现了与BERT类似的性能，对财务和环境的影响较小。